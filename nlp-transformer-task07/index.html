<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset="utf-8">
    
    <title>Task07 ‰ΩøÁî®TransformersËß£ÂÜ≥ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä° | Memex</title>
    
    
        <meta name="keywords" content="Á¨îËÆ∞,NLP,ÁªÑÈòüÂ≠¶‰π†,È¢ÑËÆ≠ÁªÉÊ®°Âûã,BERT,transfomer,ÊñáÊú¨ÂàÜÁ±ª" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="ËØ•ÈÉ®ÂàÜÁöÑÂÜÖÂÆπÁøªËØëËá™ü§óHuggingFace&#x2F;notebooks https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;notebooks&#x2F;tree&#x2F;master&#x2F;examples‰∏≠ÊñáÁøªËØëÔºöDatawhale&#x2F;learn-nlp-with-transformers&#x2F;4.1-ÊñáÊú¨ÂàÜÁ±ª Datawhale&#x2F;learn-nlp-with-transformers&#x2F;4.1-ÊñáÊú¨ÂàÜÁ±ª ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°Âûã">
<meta property="og:type" content="article">
<meta property="og:title" content="Task07 ‰ΩøÁî®TransformersËß£ÂÜ≥ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°">
<meta property="og:url" content="http://example.com/nlp-transformer-task07/index.html">
<meta property="og:site_name" content="Memex">
<meta property="og:description" content="ËØ•ÈÉ®ÂàÜÁöÑÂÜÖÂÆπÁøªËØëËá™ü§óHuggingFace&#x2F;notebooks https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;notebooks&#x2F;tree&#x2F;master&#x2F;examples‰∏≠ÊñáÁøªËØëÔºöDatawhale&#x2F;learn-nlp-with-transformers&#x2F;4.1-ÊñáÊú¨ÂàÜÁ±ª Datawhale&#x2F;learn-nlp-with-transformers&#x2F;4.1-ÊñáÊú¨ÂàÜÁ±ª ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°Âûã">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/00_bg.png?raw=true">
<meta property="article:published_time" content="2021-09-25T08:57:45.000Z">
<meta property="article:modified_time" content="2021-10-02T09:21:50.190Z">
<meta property="article:author" content="Xiaoyu CHU">
<meta property="article:tag" content="Á¨îËÆ∞">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="ÁªÑÈòüÂ≠¶‰π†">
<meta property="article:tag" content="È¢ÑËÆ≠ÁªÉÊ®°Âûã">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="transfomer">
<meta property="article:tag" content="ÊñáÊú¨ÂàÜÁ±ª">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/00_bg.png?raw=true">
    

    
        <link rel="alternate" href="/atom.xml" title="Memex" type="application/atom+xml" />
    

    
        <link rel="icon" href="/logo.jpg" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Memex</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">È¶ñÈ°µ</a>
                
                    <a class="main-nav-link" href="/archives">ÂΩíÊ°£</a>
                
                    <a class="main-nav-link" href="/categories">ÂàÜÁ±ª</a>
                
                    <a class="main-nav-link" href="/tags">Ê†áÁ≠æ</a>
                
                    <a class="main-nav-link" href="/about">ÂÖ≥‰∫é</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">È¶ñÈ°µ</a></td>
                
                    <td><a class="main-nav-link" href="/archives">ÂΩíÊ°£</a></td>
                
                    <td><a class="main-nav-link" href="/categories">ÂàÜÁ±ª</a></td>
                
                    <td><a class="main-nav-link" href="/tags">Ê†áÁ≠æ</a></td>
                
                    <td><a class="main-nav-link" href="/about">ÂÖ≥‰∫é</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>categories</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-up fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" style="display: block;"> 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            01 ËÆ°ÁÆóÊú∫Âü∫Á°Ä
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;"> 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            CS61A ËÆ°ÁÆóÊú∫Á®ãÂ∫èÁöÑÊûÑÈÄ†‰∏éËß£Èáä
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/cs61a-week1/">CS61A Week1 Comupter_Science, Functions</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            CSAPP Ê∑±ÂÖ•ÁêÜËß£ËÆ°ÁÆóÊú∫Á≥ªÁªü
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/csapp-chap01/">CSAPP Chap01 ËÆ°ÁÆóÊú∫Á≥ªÁªüÊº´Ê∏∏</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            02 ‰∫∫Â∑•Êô∫ËÉΩ
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;"> 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            CS224n Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/cs224n-lec01/">CS224n Lec01 Introduction and Word Vectors</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Êï∞ÊçÆÂàÜÊûê
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/">Ê¶ÇÁéáËÆ∫‰∏éÊï∞ÁêÜÁªüËÆ°</a></li>  <li class="file"><a href="/SQL%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/">SQLÂ≠¶‰π†ËµÑÊñô</a></li>  <li class="file"><a href="/SQL%E9%87%8D%E7%82%B9/">SQLË°®ËøûÊé•&ËÅöÂêàÂáΩÊï∞&Á™óÂè£ÂáΩÊï∞</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            ÊùéÂÆèÊØÖÊú∫Âô®Â≠¶‰π†
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/leeml-lec01-introduction/">Lecture01 Êú∫Âô®Â≠¶‰π†ÂíåÊ∑±Â∫¶Â≠¶‰π†ÁÆÄ‰ªã</a></li>  <li class="file"><a href="/leeml-lec01-bp/">Lecture01(elective) ÂèçÂêë‰º†Êí≠ÁÆóÊ≥ï</a></li>  <li class="file"><a href="/leeml-rnn/">Âæ™ÁéØÁ•ûÁªèÁΩëÁªú</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/nlp-text-representation/">NLP‰πãÊñáÊú¨Ë°®Á§∫</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            03 Â∑•ÂÖ∑ÁÆ±
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%AD%E8%8B%B1%E6%96%87LaTeX%E7%AE%80%E5%8E%86%E6%A8%A1%E6%9D%BF/">‰∏Ä‰∫õÂ•ΩÁî®ÁöÑ‰∏≠Ëã±ÊñáLaTeXÁÆÄÂéÜÊ®°Êùø</a></li>  <li class="file"><a href="/git/">5hÊâìÈÄöGitÂÖ®Â•óÊïôÁ®ã</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            04 ÁªÑÈòüÂ≠¶‰π†
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;"> 
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Á¨¨29Êúü Âü∫‰∫étransformerÁöÑNLP
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/nlp-transformer-task01/">Task01 NLPÂ≠¶‰π†Ê¶ÇËßà</a></li>  <li class="file"><a href="/nlp-transformer-task02/">Task02 Â≠¶‰π†AttentioinÂíåTransformer</a></li>  <li class="file"><a href="/nlp-transformer-task03/">Task03 Â≠¶‰π†BERT</a></li>  <li class="file"><a href="/nlp-transformer-task04/">Task04 Â≠¶‰π†GPT</a></li>  <li class="file"><a href="/nlp-transformer-task05/">Task05 ÁºñÂÜôBERTÊ®°Âûã</a></li>  <li class="file"><a href="/nlp-transformer-task06/">Task06 BERTÂ∫îÁî®„ÄÅËÆ≠ÁªÉÂíå‰ºòÂåñ</a></li>  <li class="file active"><a href="/nlp-transformer-task07/">Task07 ‰ΩøÁî®TransformersËß£ÂÜ≥ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°</a></li>  <li class="file"><a href="/nlp-transformer-summary/">Summary TransformerËØæÁ®ãÊÄªÁªì</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Á¨¨30Êúü Ê∑±ÂÖ•ÊµÖÂá∫PyTorch
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/pytorch-chap01-02/">Chapter01-02 PyTorchÁöÑÁÆÄ‰ªãÂíåÂÆâË£Ö„ÄÅPyTorchÂü∫Á°ÄÁü•ËØÜ</a></li>  <li class="file"><a href="/pytorch-chap03/">Chapter03 PyTorchÁöÑ‰∏ªË¶ÅÁªÑÊàêÊ®°Âùó</a></li>  <li class="file"><a href="/pytorch-chap04/">Chapter04 PyTorchÂü∫Á°ÄÂÆûÊàò‚Äî‚ÄîFashionMNISTÂõæÂÉèÂàÜÁ±ª</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            Ê≤âÊÄùÂΩï
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/%E5%A4%A7%E7%90%86/">Â§ßÁêÜÔºåÂú®Ê∞ëÂÆøÊâìÂ∑•ÁöÑÊó•Â≠ê</a></li>  <li class="file"><a href="/formula/">ÂÖ¨Âºè‰πãÁæéÔºåEVERYTHING IS EPHEMERAL BUT FORMULA IS ETERNAL</a></li>  <li class="file"><a href="/feynman-quotes/">Ë¥πÊõºËØ≠ÂΩïÔºàÁøªËØëËá™TwitterÔºâ</a></li>  </ul> 
                    </li> 
                     </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // Â∑¶ÈîÆÂçïÁã¨Â±ïÂºÄÁõÆÂΩï
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // Âè≥ÈîÆÂ±ïÂºÄ‰∏ãÂ±ûÊâÄÊúâÁõÆÂΩï
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // Â±ïÂºÄÂÖ≥Èó≠ÊâÄÊúâÁõÆÂΩïÊåâÈíÆ
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>recent</span></h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/feynman-quotes/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/feynman.jpg?raw=true)" alt="Ë¥πÊõºËØ≠ÂΩïÔºàÁøªËØëËá™TwitterÔºâ" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%B2%89%E6%80%9D%E5%BD%95/">Ê≤âÊÄùÂΩï</a></p>
                            <p class="item-title"><a href="/feynman-quotes/" class="title">Ë¥πÊõºËØ≠ÂΩïÔºàÁøªËØëËá™TwitterÔºâ</a></p>
                            <p class="item-date"><time datetime="2021-12-02T05:38:38.000Z" itemprop="datePublished">2021-12-02</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/cs224n-lec01/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/nlp.jpg?raw=true)" alt="CS224n Lec01 Introduction and Word Vectors" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">02 ‰∫∫Â∑•Êô∫ËÉΩ</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/CS224n-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">CS224n Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ</a></p>
                            <p class="item-title"><a href="/cs224n-lec01/" class="title">CS224n Lec01 Introduction and Word Vectors</a></p>
                            <p class="item-date"><time datetime="2021-11-28T11:37:51.000Z" itemprop="datePublished">2021-11-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/csapp-chap01/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/csapp/00.jpg?raw=true)" alt="CSAPP Chap01 ËÆ°ÁÆóÊú∫Á≥ªÁªüÊº´Ê∏∏" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/">01 ËÆ°ÁÆóÊú∫Âü∫Á°Ä</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/CSAPP-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/">CSAPP Ê∑±ÂÖ•ÁêÜËß£ËÆ°ÁÆóÊú∫Á≥ªÁªü</a></p>
                            <p class="item-title"><a href="/csapp-chap01/" class="title">CSAPP Chap01 ËÆ°ÁÆóÊú∫Á≥ªÁªüÊº´Ê∏∏</a></p>
                            <p class="item-date"><time datetime="2021-10-26T02:26:30.000Z" itemprop="datePublished">2021-10-26</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/leeml-rnn/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/00_logo.jpeg?raw=true)" alt="Âæ™ÁéØÁ•ûÁªèÁΩëÁªú" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">02 ‰∫∫Â∑•Êô∫ËÉΩ</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">ÊùéÂÆèÊØÖÊú∫Âô®Â≠¶‰π†</a></p>
                            <p class="item-title"><a href="/leeml-rnn/" class="title">Âæ™ÁéØÁ•ûÁªèÁΩëÁªú</a></p>
                            <p class="item-date"><time datetime="2021-10-24T08:15:10.000Z" itemprop="datePublished">2021-10-24</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/leeml-lec01-bp/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/00_logo.jpeg?raw=true)" alt="Lecture01(elective) ÂèçÂêë‰º†Êí≠ÁÆóÊ≥ï" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">02 ‰∫∫Â∑•Êô∫ËÉΩ</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">ÊùéÂÆèÊØÖÊú∫Âô®Â≠¶‰π†</a></p>
                            <p class="item-title"><a href="/leeml-lec01-bp/" class="title">Lecture01(elective) ÂèçÂêë‰º†Êí≠ÁÆóÊ≥ï</a></p>
                            <p class="item-date"><time datetime="2021-10-15T06:55:13.000Z" itemprop="datePublished">2021-10-15</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>archives</span></h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a><span class="archive-list-count">7</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>tag cloud</span></h3>
        <div class="widget tagcloud">
            <a href="/tags/BERT/" style="font-size: 14.29px;">BERT</a> <a href="/tags/CS%E5%85%AC%E5%BC%80%E8%AF%BE/" style="font-size: 11.43px;">CSÂÖ¨ÂºÄËØæ</a> <a href="/tags/GPT/" style="font-size: 10px;">GPT</a> <a href="/tags/NLP/" style="font-size: 18.57px;">NLP</a> <a href="/tags/PyTorch/" style="font-size: 12.86px;">PyTorch</a> <a href="/tags/SQL/" style="font-size: 11.43px;">SQL</a> <a href="/tags/attention/" style="font-size: 10px;">attention</a> <a href="/tags/back-propagation/" style="font-size: 10px;">back propagation</a> <a href="/tags/computer-system/" style="font-size: 10px;">computer system</a> <a href="/tags/csapp/" style="font-size: 10px;">csapp</a> <a href="/tags/feynman/" style="font-size: 10px;">feynman</a> <a href="/tags/function/" style="font-size: 10px;">function</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/laTeX/" style="font-size: 10px;">laTeX</a> <a href="/tags/machine-learning/" style="font-size: 12.86px;">machine learning</a> <a href="/tags/math/" style="font-size: 10px;">math</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/quote/" style="font-size: 10px;">quote</a> <a href="/tags/regression/" style="font-size: 10px;">regression</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/team-leaning/" style="font-size: 10px;">team leaning</a> <a href="/tags/team-learning/" style="font-size: 10px;">team learning</a> <a href="/tags/transfomer/" style="font-size: 15.71px;">transfomer</a> <a href="/tags/%E5%A4%A7%E7%90%86/" style="font-size: 10px;">Â§ßÁêÜ</a> <a href="/tags/%E6%80%BB%E7%BB%93/" style="font-size: 10px;">ÊÄªÁªì</a> <a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" style="font-size: 10px;">ÊñáÊú¨ÂàÜÁ±ª</a> <a href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/" style="font-size: 10px;">ÊñáÊú¨Ë°®Á§∫</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 20px;">Á¨îËÆ∞</a> <a href="/tags/%E7%AE%80%E5%8E%86/" style="font-size: 10px;">ÁÆÄÂéÜ</a> <a href="/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">ÁªÑÈòüÂ≠¶‰π†</a> <a href="/tags/%E7%BB%9F%E8%AE%A1/" style="font-size: 10px;">ÁªüËÆ°</a> <a href="/tags/%E9%98%85%E8%AF%BB/" style="font-size: 10px;">ÈòÖËØª</a> <a href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" style="font-size: 17.14px;">È¢ÑËÆ≠ÁªÉÊ®°Âûã</a>
        </div>
    </div>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-nlp-transformer-task07" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/">04 ÁªÑÈòüÂ≠¶‰π†</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/">Á¨¨29Êúü Âü∫‰∫étransformerÁöÑNLP</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/BERT/" rel="tag">BERT</a>, <a class="tag-link-link" href="/tags/NLP/" rel="tag">NLP</a>, <a class="tag-link-link" href="/tags/transfomer/" rel="tag">transfomer</a>, <a class="tag-link-link" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" rel="tag">ÊñáÊú¨ÂàÜÁ±ª</a>, <a class="tag-link-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">Á¨îËÆ∞</a>, <a class="tag-link-link" href="/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/" rel="tag">ÁªÑÈòüÂ≠¶‰π†</a>, <a class="tag-link-link" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" rel="tag">È¢ÑËÆ≠ÁªÉÊ®°Âûã</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/nlp-transformer-task07/">
            <time datetime="2021-09-25T08:57:45.000Z" itemprop="datePublished">2021-09-25</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            Task07 ‰ΩøÁî®TransformersËß£ÂÜ≥ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">Catalogue</strong>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB"><span class="toc-number">1.</span> <span class="toc-text">ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÊñáÊú¨ÂàÜÁ±ª</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.</span> <span class="toc-text">Âä†ËΩΩÊï∞ÊçÆÈõÜ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">ÂæÆË∞ÉÊ®°Âûã</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%90%9C%E7%B4%A2"><span class="toc-number">5.</span> <span class="toc-text">Ë∂ÖÂèÇÊêúÁ¥¢</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">6.</span> <span class="toc-text">ÂèÇËÄÉËµÑÊñô</span></a></li></ol>
                </div>
            
        
        
            <p><em>ËØ•ÈÉ®ÂàÜÁöÑÂÜÖÂÆπÁøªËØëËá™ü§óHuggingFace/notebooks <a target="_blank" rel="noopener" href="https://github.com/huggingface/notebooks/tree/master/examples">https://github.com/huggingface/notebooks/tree/master/examples</a></em><br><em>‰∏≠ÊñáÁøªËØëÔºöDatawhale/learn-nlp-with-transformers/4.1-ÊñáÊú¨ÂàÜÁ±ª <a target="_blank" rel="noopener" href="https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1/4.1-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.md">Datawhale/learn-nlp-with-transformers/4.1-ÊñáÊú¨ÂàÜÁ±ª</a></em></p>
<h1 id="ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÊñáÊú¨ÂàÜÁ±ª"><a href="#ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÊñáÊú¨ÂàÜÁ±ª" class="headerlink" title="ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÊñáÊú¨ÂàÜÁ±ª"></a>ÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÊñáÊú¨ÂàÜÁ±ª</h1><p>Êàë‰ª¨Â∞Ü‰ΩøÁî® ü§ó Transformers‰ª£Á†ÅÂ∫ì‰∏≠ÁöÑÊ®°ÂûãÊù•Ëß£ÂÜ≥ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°Ôºå‰ªªÂä°Êù•Ê∫ê‰∫éGLUE Benchmark.<br>GLUEÊ¶úÂçïÂåÖÂê´‰∫Ü9‰∏™Âè•Â≠êÁ∫ßÂà´ÁöÑÂàÜÁ±ª‰ªªÂä°ÔºåÂàÜÂà´ÊòØÔºö</p>
<ul>
<li>CoLA (Corpus of Linguistic Acceptability) Èâ¥Âà´‰∏Ä‰∏™Âè•Â≠êÊòØÂê¶ËØ≠Ê≥ïÊ≠£Á°Æ.</li>
<li>MNLI (Multi-Genre Natural Language Inference) ÁªôÂÆö‰∏Ä‰∏™ÂÅáËÆæÔºåÂà§Êñ≠Âè¶‰∏Ä‰∏™Âè•Â≠ê‰∏éËØ•ÂÅáËÆæÁöÑÂÖ≥Á≥ªÔºöentails, contradicts ÊàñËÄÖ unrelated„ÄÇ</li>
<li>MRPC (Microsoft Research Paraphrase Corpus) Âà§Êñ≠‰∏§‰∏™Âè•Â≠êÊòØÂê¶‰∫í‰∏∫paraphrases.</li>
<li>QNLI (Question-answering Natural Language Inference) Âà§Êñ≠Á¨¨2Âè•ÊòØÂê¶ÂåÖÂê´Á¨¨1Âè•ÈóÆÈ¢òÁöÑÁ≠îÊ°à„ÄÇ</li>
<li>QQP (Quora Question Pairs2) Âà§Êñ≠‰∏§‰∏™ÈóÆÂè•ÊòØÂê¶ËØ≠‰πâÁõ∏Âêå„ÄÇ</li>
<li>RTE (Recognizing Textual Entailment)Âà§Êñ≠‰∏Ä‰∏™Âè•Â≠êÊòØÂê¶‰∏éÂÅáËÆæÊàêentailÂÖ≥Á≥ª„ÄÇ</li>
<li>SST-2 (Stanford Sentiment Treebank) Âà§Êñ≠‰∏Ä‰∏™Âè•Â≠êÁöÑÊÉÖÊÑüÊ≠£Ë¥üÂêë.</li>
<li>STS-B (Semantic Textual Similarity Benchmark) Âà§Êñ≠‰∏§‰∏™Âè•Â≠êÁöÑÁõ∏‰ººÊÄßÔºàÂàÜÊï∞‰∏∫1-5ÂàÜÔºâ„ÄÇ</li>
<li>WNLI (Winograd Natural Language Inference) Determine if a sentence with an anonymous pronoun and a sentence with this pronoun replaced are entailed or not.</li>
</ul>
<p>ÂØπ‰∫é‰ª•‰∏ä‰ªªÂä°ÔºåÊàë‰ª¨Â∞ÜÂ±ïÁ§∫Â¶Ç‰Ωï‰ΩøÁî®ÁÆÄÂçïÁöÑDatasetÂ∫ìÂä†ËΩΩÊï∞ÊçÆÈõÜÔºåÂêåÊó∂‰ΩøÁî®transformer‰∏≠ÁöÑTrainerÊé•Âè£ÂØπÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GLUE_TASKS = [<span class="string">&quot;cola&quot;</span>, <span class="string">&quot;mnli&quot;</span>, <span class="string">&quot;mnli-mm&quot;</span>, <span class="string">&quot;mrpc&quot;</span>, <span class="string">&quot;qnli&quot;</span>, <span class="string">&quot;qqp&quot;</span>, <span class="string">&quot;rte&quot;</span>, <span class="string">&quot;sst2&quot;</span>, <span class="string">&quot;stsb&quot;</span>, <span class="string">&quot;wnli&quot;</span>]</span><br></pre></td></tr></table></figure>

<p>This notebook is built to run on any of the tasks in the list above, with any model checkpoint from the Model Hub as long as that model has a version with a classification head. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:<br>Êú¨notebookÁêÜËÆ∫‰∏äÂèØ‰ª•‰ΩøÁî®ÂêÑÁßçÂêÑÊ†∑ÁöÑtransformerÊ®°ÂûãÔºàÊ®°ÂûãÈù¢ÊùøÔºâÔºåËß£ÂÜ≥‰ªª‰ΩïÊñáÊú¨ÂàÜÁ±ªÂàÜÁ±ª‰ªªÂä°„ÄÇÂ¶ÇÊûúÊÇ®ÊâÄÂ§ÑÁêÜÁöÑ‰ªªÂä°ÊúâÊâÄ‰∏çÂêåÔºåÂ§ßÊ¶ÇÁéáÂè™ÈúÄË¶ÅÂæàÂ∞èÁöÑÊîπÂä®‰æøÂèØ‰ª•‰ΩøÁî®Êú¨notebookËøõË°åÂ§ÑÁêÜ„ÄÇÂêåÊó∂ÔºåÊÇ®Â∫îËØ•Ê†πÊçÆÊÇ®ÁöÑGPUÊòæÂ≠òÊù•Ë∞ÉÊï¥ÂæÆË∞ÉËÆ≠ÁªÉÊâÄÈúÄË¶ÅÁöÑbtach sizeÂ§ßÂ∞èÔºåÈÅøÂÖçÊòæÂ≠òÊ∫¢Âá∫„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">task = <span class="string">&quot;cola&quot;</span></span><br><span class="line">model_checkpoint = <span class="string">&quot;distilbert-base-uncased&quot;</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br></pre></td></tr></table></figure>

<h1 id="Âä†ËΩΩÊï∞ÊçÆÈõÜ"><a href="#Âä†ËΩΩÊï∞ÊçÆÈõÜ" class="headerlink" title="Âä†ËΩΩÊï∞ÊçÆÈõÜ"></a>Âä†ËΩΩÊï∞ÊçÆÈõÜ</h1><p>We will use the ü§ó Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions <code>load_dataset</code> and <code>load_metric</code>.<br>Êàë‰ª¨Â∞Ü‰ºö‰ΩøÁî®ü§ó DatasetsÂ∫ìÊù•Âä†ËΩΩÊï∞ÊçÆÂíåÂØπÂ∫îÁöÑËØÑÊµãÊñπÂºè„ÄÇÊï∞ÊçÆÂä†ËΩΩÂíåËØÑÊµãÊñπÂºèÂä†ËΩΩÂè™ÈúÄË¶ÅÁÆÄÂçï‰ΩøÁî®load_datasetÂíåload_metricÂç≥ÂèØ„ÄÇ</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from datasets import load_dataset, load_metric</span><br></pre></td></tr></table></figure>

<p>Apart from mnli-mm being a special code, we can directly pass our task name to those functions. <code>load_dataset</code> will cache the dataset to avoid downloading it again the next time you run this cell.<br>Èô§‰∫Ümnli-mm‰ª•Â§ñÔºåÂÖ∂‰ªñ‰ªªÂä°ÈÉΩÂèØ‰ª•Áõ¥Êé•ÈÄöËøá‰ªªÂä°ÂêçÂ≠óËøõË°åÂä†ËΩΩ„ÄÇÊï∞ÊçÆÂä†ËΩΩ‰πãÂêé‰ºöËá™Âä®ÁºìÂ≠ò„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">actual_task = <span class="string">&quot;mnli&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> task</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;glue&quot;</span>, actual_task)</span><br><span class="line">metric = load_metric(<span class="string">&#x27;glue&#x27;</span>, actual_task)</span><br></pre></td></tr></table></figure>
<p><em>‰∏äËäÇËÆ≤ËøáÔºåËøôÈáåÔºåÊúÄÂ•ΩÊâãÂä®‰∏ãËΩΩglue.pyÂíågule_metric.pyÔºå‰∏ç‰∏ãËΩΩÂà∞Êú¨Âú∞ÁöÑËØùÔºåÂÆπÊòìÂá∫Áé∞ËøûÊé•ÈîôËØØ„ÄÇ</em></p>
<p>The dataset object itself is DatasetDict, which contains one key for the training, validation and test set (with more keys for the mismatched validation and test set in the special case of mnli).<br>Ëøô‰∏™datasetsÂØπË±°Êú¨Ë∫´ÊòØ‰∏ÄÁßçDatasetDictÊï∞ÊçÆÁªìÊûÑ.ÂØπ‰∫éËÆ≠ÁªÉÈõÜ„ÄÅÈ™åËØÅÈõÜÂíåÊµãËØïÈõÜÔºåÂè™ÈúÄË¶Å‰ΩøÁî®ÂØπÂ∫îÁöÑkeyÔºàtrainÔºåvalidationÔºåtestÔºâÂç≥ÂèØÂæóÂà∞Áõ∏Â∫îÁöÑÊï∞ÊçÆ„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataset</span><br><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">8551</span></span><br><span class="line">    &#125;)</span><br><span class="line">    validation: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1043</span></span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1063</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataset[<span class="string">&quot;train&quot;</span>][<span class="number">0</span>]</span><br><span class="line">&#123;<span class="string">&#x27;sentence&#x27;</span>: <span class="string">&quot;Our friends won&#x27;t buy this analysis, let alone the next one we propose.&quot;</span>,</span><br><span class="line"><span class="string">&#x27;label&#x27;</span>: <span class="number">1</span>, </span><br><span class="line"><span class="string">&#x27;idx&#x27;</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure>

<p>To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset.<br>‰∏∫‰∫ÜËÉΩÂ§üËøõ‰∏ÄÊ≠•ÁêÜËß£Êï∞ÊçÆÈïø‰ªÄ‰πàÊ†∑Â≠êÔºå‰∏ãÈù¢ÁöÑÂáΩÊï∞Â∞Ü‰ªéÊï∞ÊçÆÈõÜÈáåÈöèÊú∫ÈÄâÊã©Âá†‰∏™‰æãÂ≠êËøõË°åÂ±ïÁ§∫„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, HTML</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_random_elements</span>(<span class="params">dataset, num_examples=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">assert</span> num_examples &lt;= <span class="built_in">len</span>(dataset), <span class="string">&quot;Can&#x27;t pick more elements than there are in the dataset.&quot;</span></span><br><span class="line">    picks = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_examples):</span><br><span class="line">        pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">while</span> pick <span class="keyword">in</span> picks:</span><br><span class="line">            pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        picks.append(pick)</span><br><span class="line">    </span><br><span class="line">    df = pd.DataFrame(dataset[picks])</span><br><span class="line">    <span class="keyword">for</span> column, typ <span class="keyword">in</span> dataset.features.items():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(typ, datasets.ClassLabel):</span><br><span class="line">            df[column] = df[column].transform(<span class="keyword">lambda</span> i: typ.names[i])</span><br><span class="line">    display(HTML(df.to_html()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_random_elements(dataset[<span class="string">&quot;train&quot;</span>])</span><br></pre></td></tr></table></figure>

<p>The metric is an instance of datasets.Metric:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>You can call its <code>compute</code> method with your predictions and labels directly and it will return a dictionary with the metric(s) value:<br>Áõ¥Êé•Ë∞ÉÁî®metricÁöÑcomputeÊñπÊ≥ïÔºå‰º†ÂÖ•labelsÂíåpredictionsÂç≥ÂèØÂæóÂà∞metricÁöÑÂÄºÔºö</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">fake_preds = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(<span class="number">64</span>,))</span><br><span class="line">fake_labels = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(<span class="number">64</span>,))</span><br><span class="line">metric.compute(predictions=fake_preds, references=fake_labels)</span><br></pre></td></tr></table></figure>
<p>Note that load_metric has loaded the proper metric associated to your task, which is:<br>ÊØè‰∏Ä‰∏™ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°ÊâÄÂØπÂ∫îÁöÑmeticÊúâÊâÄ‰∏çÂêåÔºåÂÖ∑‰ΩìÂ¶Ç‰∏ã:</p>
<ul>
<li>for CoLA: Matthews Correlation Coefficient</li>
<li>for MNLI (matched or mismatched): Accuracy</li>
<li>for MRPC: Accuracy and F1 score</li>
<li>for QNLI: Accuracy</li>
<li>for QQP: Accuracy and F1 score</li>
<li>for RTE: Accuracy</li>
<li>for SST-2: Accuracy</li>
<li>for STS-B: Pearson Correlation Coefficient and Spearman‚Äôs_Rank_Correlation_Coefficient</li>
<li>for WNLI: Accuracy</li>
</ul>
<p>so the metric object only computes the one(s) needed for your task.</p>
<h1 id="Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ"><a href="#Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ" class="headerlink" title="Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ"></a>Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ</h1><p>Before we can feed those texts to our model, we need to preprocess them. This is done by a ü§ó Transformers <code>Tokenizer</code> which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.<br>Âú®Â∞ÜÊï∞ÊçÆÂñÇÂÖ•Ê®°Âûã‰πãÂâçÔºåÊàë‰ª¨ÈúÄË¶ÅÂØπÊï∞ÊçÆËøõË°åÈ¢ÑÂ§ÑÁêÜ„ÄÇÈ¢ÑÂ§ÑÁêÜÁöÑÂ∑•ÂÖ∑Âè´Tokenizer„ÄÇTokenizerÈ¶ñÂÖàÂØπËæìÂÖ•ËøõË°åtokenizeÔºåÁÑ∂ÂêéÂ∞ÜtokensËΩ¨Âåñ‰∏∫È¢ÑÊ®°Âûã‰∏≠ÈúÄË¶ÅÂØπÂ∫îÁöÑtoken IDÔºåÂÜçËΩ¨Âåñ‰∏∫Ê®°ÂûãÈúÄË¶ÅÁöÑËæìÂÖ•Ê†ºÂºè„ÄÇ</p>
<p>To do all of this, we instantiate our tokenizer with the <code>AutoTokenizer.from_pretrained</code> method, which will ensure:</p>
<ul>
<li>we get a tokenizer that corresponds to the model architecture we want to use,</li>
<li>we download the vocabulary used when pretraining this specific checkpoint.</li>
</ul>
<p>‰∏∫‰∫ÜËææÂà∞Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁöÑÁõÆÁöÑÔºåÊàë‰ª¨‰ΩøÁî®AutoTokenizer.from_pretrainedÊñπÊ≥ïÂÆû‰æãÂåñÊàë‰ª¨ÁöÑtokenizerÔºåËøôÊ†∑ÂèØ‰ª•Á°Æ‰øùÔºö</p>
<ul>
<li>Êàë‰ª¨ÂæóÂà∞‰∏Ä‰∏™‰∏éÈ¢ÑËÆ≠ÁªÉÊ®°Âûã‰∏Ä‰∏ÄÂØπÂ∫îÁöÑtokenizer„ÄÇ</li>
<li>‰ΩøÁî®ÊåáÂÆöÁöÑÊ®°ÂûãcheckpointÂØπÂ∫îÁöÑtokenizerÁöÑÊó∂ÂÄôÔºåÊàë‰ª¨‰πü‰∏ãËΩΩ‰∫ÜÊ®°ÂûãÈúÄË¶ÅÁöÑËØçË°®Â∫ìvocabularyÔºåÂáÜÁ°ÆÊù•ËØ¥ÊòØtokens vocabulary„ÄÇ</li>
</ul>
<p>That vocabulary will be cached, so it‚Äôs not downloaded again the next time we run the cell.<br>Ëøô‰∏™Ë¢´‰∏ãËΩΩÁöÑtokens vocabulary‰ºöË¢´ÁºìÂ≠òËµ∑Êù•Ôºå‰ªéËÄåÂÜçÊ¨°‰ΩøÁî®ÁöÑÊó∂ÂÄô‰∏ç‰ºöÈáçÊñ∞‰∏ãËΩΩ„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">    </span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>You can directly call this tokenizer on one sentence or a pair of sentences:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer(<span class="string">&quot;Hello, this one sentence!&quot;</span>, <span class="string">&quot;And this sentence goes with it.&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>ËæìÂá∫‰∏∫Ôºö<br>pass</p>
<p>To preprocess our dataset, we will thus need the names of the columns containing the sentence(s). The following dictionary keeps track of the correspondence task to column names:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">task_to_keys = &#123;</span><br><span class="line">    <span class="string">&quot;cola&quot;</span>: (<span class="string">&quot;sentence&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    <span class="string">&quot;mnli&quot;</span>: (<span class="string">&quot;premise&quot;</span>, <span class="string">&quot;hypothesis&quot;</span>),</span><br><span class="line">    <span class="string">&quot;mnli-mm&quot;</span>: (<span class="string">&quot;premise&quot;</span>, <span class="string">&quot;hypothesis&quot;</span>),</span><br><span class="line">    <span class="string">&quot;mrpc&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;qnli&quot;</span>: (<span class="string">&quot;question&quot;</span>, <span class="string">&quot;sentence&quot;</span>),</span><br><span class="line">    <span class="string">&quot;qqp&quot;</span>: (<span class="string">&quot;question1&quot;</span>, <span class="string">&quot;question2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;rte&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;sst2&quot;</span>: (<span class="string">&quot;sentence&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    <span class="string">&quot;stsb&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;wnli&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>We can double check it does work on our current dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sentence1_key, sentence2_key = task_to_keys[task]</span><br><span class="line"><span class="keyword">if</span> sentence2_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence1_key]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence 1: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence1_key]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence 2: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence2_key]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>ËæìÂá∫‰∏∫Ôºö</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sentence: Our friends won&#x27;t buy this analysis, let alone the next one we propose.</span><br></pre></td></tr></table></figure>

<p>We can them write the function that will preprocess our samples. We just feed them to the <code>tokenizer</code> with the argument <code>truncation=True</code>. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_function</span>(<span class="params">examples</span>):</span></span><br><span class="line">    <span class="keyword">if</span> sentence2_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> tokenizer(examples[sentence1_key], truncation=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>preprocess_function(dataset[<span class="string">&#x27;train&#x27;</span>][:<span class="number">5</span>])</span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [[<span class="number">101</span>, <span class="number">2256</span>, <span class="number">2814</span>, <span class="number">2180</span>, <span class="number">1005</span>, <span class="number">1056</span>, <span class="number">4965</span>, <span class="number">2023</span>, <span class="number">4106</span>, <span class="number">1010</span>, <span class="number">2292</span>, <span class="number">2894</span>, <span class="number">1996</span>, <span class="number">2279</span>, <span class="number">2028</span>, <span class="number">2057</span>, <span class="number">16599</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2028</span>, <span class="number">2062</span>, <span class="number">18404</span>, <span class="number">2236</span>, <span class="number">3989</span>, <span class="number">1998</span>, <span class="number">1045</span>, <span class="number">1005</span>, <span class="number">1049</span>, <span class="number">3228</span>, <span class="number">2039</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2028</span>, <span class="number">2062</span>, <span class="number">18404</span>, <span class="number">2236</span>, <span class="number">3989</span>, <span class="number">2030</span>, <span class="number">1045</span>, <span class="number">1005</span>, <span class="number">1049</span>, <span class="number">3228</span>, <span class="number">2039</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">1996</span>, <span class="number">2062</span>, <span class="number">2057</span>, <span class="number">2817</span>, <span class="number">16025</span>, <span class="number">1010</span>, <span class="number">1996</span>, <span class="number">13675</span>, <span class="number">16103</span>, <span class="number">2121</span>, <span class="number">2027</span>, <span class="number">2131</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2154</span>, <span class="number">2011</span>, <span class="number">2154</span>, <span class="number">1996</span>, <span class="number">8866</span>, <span class="number">2024</span>, <span class="number">2893</span>, <span class="number">14163</span>, <span class="number">8024</span>, <span class="number">3771</span>, <span class="number">1012</span>, <span class="number">102</span>]], <span class="string">&#x27;attention_mask&#x27;</span>: [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]&#125;</span><br></pre></td></tr></table></figure>

<p>To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the <code>map</code> method of our <code>dataset</code> object we created earlier. This will apply the function on all the elements of all the splits in <code>dataset</code>, so our training, validation and testing data will be preprocessed in one single command.<br>Êé•‰∏ãÊù•ÂØπÊï∞ÊçÆÈõÜdatasetsÈáåÈù¢ÁöÑÊâÄÊúâÊ†∑Êú¨ËøõË°åÈ¢ÑÂ§ÑÁêÜÔºåÂ§ÑÁêÜÁöÑÊñπÂºèÊòØ‰ΩøÁî®mapÂáΩÊï∞ÔºåÂ∞ÜÈ¢ÑÂ§ÑÁêÜÂáΩÊï∞prepare_train_featuresÂ∫îÁî®Âà∞Ôºàmap)ÊâÄÊúâÊ†∑Êú¨‰∏ä„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoded_dataset = dataset.<span class="built_in">map</span>(preprocess_function, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h1 id="ÂæÆË∞ÉÊ®°Âûã"><a href="#ÂæÆË∞ÉÊ®°Âûã" class="headerlink" title="ÂæÆË∞ÉÊ®°Âûã"></a>ÂæÆË∞ÉÊ®°Âûã</h1><p>Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about sentence classification, we use the AutoModelForSequenceClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which is always 2, except for STS-B which is a regression problem and MNLI where we have 3 labels):<br>Êó¢ÁÑ∂Êï∞ÊçÆÂ∑≤ÁªèÂáÜÂ§áÂ•Ω‰∫ÜÔºåÁé∞Âú®Êàë‰ª¨ÈúÄË¶Å‰∏ãËΩΩÂπ∂Âä†ËΩΩÊàë‰ª¨ÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºåÁÑ∂ÂêéÂæÆË∞ÉÈ¢ÑËÆ≠ÁªÉÊ®°Âûã„ÄÇÊó¢ÁÑ∂Êàë‰ª¨ÊòØÂÅöseq2seq‰ªªÂä°ÔºåÈÇ£‰πàÊàë‰ª¨ÈúÄË¶Å‰∏Ä‰∏™ËÉΩËß£ÂÜ≥Ëøô‰∏™‰ªªÂä°ÁöÑÊ®°ÂûãÁ±ª„ÄÇÊàë‰ª¨‰ΩøÁî®AutoModelForSequenceClassification Ëøô‰∏™Á±ª„ÄÇÂíåtokenizerÁõ∏‰ººÔºåfrom_pretrainedÊñπÊ≥ïÂêåÊ†∑ÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨‰∏ãËΩΩÂπ∂Âä†ËΩΩÊ®°ÂûãÔºåÂêåÊó∂‰πü‰ºöÂØπÊ®°ÂûãËøõË°åÁºìÂ≠òÔºåÂ∞±‰∏ç‰ºöÈáçÂ§ç‰∏ãËΩΩÊ®°ÂûãÂï¶„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, TrainingArguments, Trainer</span><br><span class="line"></span><br><span class="line">num_labels = <span class="number">3</span> <span class="keyword">if</span> task.startswith(<span class="string">&quot;mnli&quot;</span>) <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">if</span> task==<span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br></pre></td></tr></table></figure>
<p>ËæìÂá∫‰∏∫Ôºö</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: [&#x27;vocab_transform.bias&#x27;, &#x27;vocab_projector.weight&#x27;, &#x27;vocab_layer_norm.bias&#x27;, &#x27;vocab_layer_norm.weight&#x27;, &#x27;vocab_projector.bias&#x27;, &#x27;vocab_transform.weight&#x27;]</span><br><span class="line">- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</span><br><span class="line">- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</span><br><span class="line">Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#x27;classifier.weight&#x27;, &#x27;classifier.bias&#x27;, &#x27;pre_classifier.bias&#x27;, &#x27;pre_classifier.weight&#x27;]</span><br><span class="line">You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</span><br></pre></td></tr></table></figure>
<p>The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don‚Äôt have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do.<br>Áî±‰∫éÊàë‰ª¨ÂæÆË∞ÉÁöÑ‰ªªÂä°ÊòØÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°ÔºåËÄåÊàë‰ª¨Âä†ËΩΩÁöÑÊòØÈ¢ÑËÆ≠ÁªÉÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÊâÄ‰ª•‰ºöÊèêÁ§∫Êàë‰ª¨Âä†ËΩΩÊ®°ÂûãÁöÑÊó∂ÂÄôÊâîÊéâ‰∫Ü‰∏Ä‰∫õ‰∏çÂåπÈÖçÁöÑÁ•ûÁªèÁΩëÁªúÂèÇÊï∞ÔºàÊØîÂ¶ÇÔºöÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÁöÑÁ•ûÁªèÁΩëÁªúheadË¢´ÊâîÊéâ‰∫ÜÔºåÂêåÊó∂ÈöèÊú∫ÂàùÂßãÂåñ‰∫ÜÊñáÊú¨ÂàÜÁ±ªÁöÑÁ•ûÁªèÁΩëÁªúheadÔºâ„ÄÇ</p>
<p>To instantiate a <code>Trainer</code>, we will need to define two more things. The most important is the <code>TrainingArguments</code>, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:<br>‰∏∫‰∫ÜËÉΩÂ§üÂæóÂà∞‰∏Ä‰∏™TrainerËÆ≠ÁªÉÂ∑•ÂÖ∑ÔºåÊàë‰ª¨ËøòÈúÄË¶Å3‰∏™Ë¶ÅÁ¥†ÔºåÂÖ∂‰∏≠ÊúÄÈáçË¶ÅÁöÑÊòØËÆ≠ÁªÉÁöÑËÆæÂÆö/ÂèÇÊï∞ TrainingArguments„ÄÇËøô‰∏™ËÆ≠ÁªÉËÆæÂÆöÂåÖÂê´‰∫ÜËÉΩÂ§üÂÆö‰πâËÆ≠ÁªÉËøáÁ®ãÁöÑÊâÄÊúâÂ±ûÊÄß„ÄÇ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">metric_name = <span class="string">&quot;pearson&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="string">&quot;matthews_correlation&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;cola&quot;</span> <span class="keyword">else</span> <span class="string">&quot;accuracy&quot;</span></span><br><span class="line">model_name = model_checkpoint.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">args = TrainingArguments(</span><br><span class="line">    <span class="string">&quot;test-glue&quot;</span>,</span><br><span class="line">    evaluation_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    save_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=batch_size,</span><br><span class="line">    per_device_eval_batch_size=batch_size,</span><br><span class="line">    num_train_epochs=<span class="number">5</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">    metric_for_best_model=metric_name,</span><br><span class="line">    push_to_hub=<span class="literal">False</span>,</span><br><span class="line">    push_to_hub_model_id=<span class="string">f&quot;<span class="subst">&#123;model_name&#125;</span>-finetuned-<span class="subst">&#123;task&#125;</span>&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the <code>batch_size</code> defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. Since the best model might not be the one at the end of training, we ask the <code>Trainer</code> to load the best model it saved (according to <code>metric_name</code>) at the end of training.<br>‰∏äÈù¢evaluation_strategy = ‚Äúepoch‚ÄùÂèÇÊï∞ÂëäËØâËÆ≠ÁªÉ‰ª£Á†ÅÔºöÊàë‰ª¨ÊØè‰∏™epcoh‰ºöÂÅö‰∏ÄÊ¨°È™åËØÅËØÑ‰º∞„ÄÇ<br>‰∏äÈù¢batch_sizeÂú®Ëøô‰∏™notebook‰πãÂâçÂÆö‰πâÂ•Ω‰∫Ü„ÄÇ</p>
<p>The last two arguments are to setup everything so we can push the model to the <code>Hub</code> at the end of training. Remove the two of them if you didn‚Äôt follow the installation steps at the top of the notebook, otherwise you can change the value of <code>push_to_hub_model_id</code> to something you would prefer.<br><em>(ÂêéÈù¢ÈúÄË¶ÅËøûÊé•Âà∞hubÂÆ¢Êà∑Á´ØÔºåÂ§™È∫ªÁÉ¶ÔºåÊâÄ‰ª•ÂÖàËÆæ‰∏∫False)</em></p>
<p>The last thing to define for our <code>Trainer</code> is how to compute the metrics from the predictions. We need to define a function for this, which will just use the <code>metric</code> we loaded earlier, the only preprocessing we have to do is to take the argmax of our predicted logits (our just squeeze the last axis in the case of STS-B):<br>ÊúÄÂêéÔºåÁî±‰∫é‰∏çÂêåÁöÑ‰ªªÂä°ÈúÄË¶Å‰∏çÂêåÁöÑËØÑÊµãÊåáÊ†áÔºåÊàë‰ª¨ÂÆö‰∏Ä‰∏™ÂáΩÊï∞Êù•Ê†πÊçÆ‰ªªÂä°ÂêçÂ≠óÂæóÂà∞ËØÑ‰ª∑ÊñπÊ≥ï:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">eval_pred</span>):</span></span><br><span class="line">    predictions, labels = eval_pred</span><br><span class="line">    <span class="keyword">if</span> task != <span class="string">&quot;stsb&quot;</span>:</span><br><span class="line">        predictions = np.argmax(predictions, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        predictions = predictions[:, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure>

<p>Then we just need to pass all of this along with our datasets to the Trainer:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">validation_key = <span class="string">&quot;validation_mismatched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation_matched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation&quot;</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>BUG:<br>ValueError: You must login to the Hugging Face hub on this computer by typing <code>transformers-cli login</code> and entering your credentials to use <code>use_auth_token=True</code>. Alternatively, you can pass your own token as the <code>use_auth_token</code> argument.<br>ÊääargsÈáåÈù¢ÁöÑËØ•È°πÂèÇÊï∞Êîπ‰∏∫False   <code>push_to_hub=False,</code>„ÄÇ</p>
</blockquote>
<p>We can now finetune our model by just calling the <code>train</code> method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>
<p>ËæìÂá∫‰∏∫Ôºö</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>We can check with the <code>evaluate</code> method that our <code>Trainer</code> did reload the best model properly (if it was not the last one):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.evaluate()</span><br></pre></td></tr></table></figure>
<p>ËæìÂá∫‰∏∫Ôºö</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h1 id="Ë∂ÖÂèÇÊêúÁ¥¢"><a href="#Ë∂ÖÂèÇÊêúÁ¥¢" class="headerlink" title="Ë∂ÖÂèÇÊêúÁ¥¢"></a>Ë∂ÖÂèÇÊêúÁ¥¢</h1><p>The Trainer supports hyperparameter search using optuna or Ray Tune. </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install optuna</span><br><span class="line">pip install ray[tune]</span><br></pre></td></tr></table></figure>

<p>During hyperparameter search, the Trainer will run several trainings, so it needs to have the model defined via a function (so it can be reinitialized at each new run) instead of just having it passed. We jsut use the same function as before:<br>Ë∂ÖÂèÇÊêúÁ¥¢Êó∂ÔºåTrainerÂ∞Ü‰ºöËøîÂõûÂ§ö‰∏™ËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãÔºåÊâÄ‰ª•ÈúÄË¶Å‰º†ÂÖ•‰∏Ä‰∏™ÂÆö‰πâÂ•ΩÁöÑÊ®°Âûã‰ªéËÄåËÆ©TrainerÂèØ‰ª•‰∏çÊñ≠ÈáçÊñ∞ÂàùÂßãÂåñËØ•‰º†ÂÖ•ÁöÑÊ®°ÂûãÔºö</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_init</span>():</span></span><br><span class="line">    <span class="keyword">return</span> AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br></pre></td></tr></table></figure>

<p>And we can instantiate our Trainer like before:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    model_init=model_init,</span><br><span class="line">    args=args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>The method we call this time is <code>hyperparameter_search</code>. Note that it can take a long time to run on the full dataset for some of the tasks. You can try to find some good hyperparameter on a portion of the training dataset by replacing the <code>train_dataset</code> line above by:<br><code>train_dataset = encoded_dataset[&quot;train&quot;].shard(index=1, num_shards=10) </code><br>for 1/10th of the dataset. Then you can run a full training on the best hyperparameters picked by the search.<br>Ë∞ÉÁî®ÊñπÊ≥ïhyperparameter_search„ÄÇÊ≥®ÊÑèÔºåËøô‰∏™ËøáÁ®ãÂèØËÉΩÂæà‰πÖÔºåÊàë‰ª¨ÂèØ‰ª•ÂÖàÁî®ÈÉ®ÂàÜÊï∞ÊçÆÈõÜËøõË°åË∂ÖÂèÇÊêúÁ¥¢ÔºåÂÜçËøõË°åÂÖ®ÈáèËÆ≠ÁªÉ„ÄÇ ÊØîÂ¶Ç‰ΩøÁî®1/10ÁöÑÊï∞ÊçÆËøõË°åÊêúÁ¥¢Ôºö</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_run = trainer.hyperparameter_search(n_trials=<span class="number">10</span>, direction=<span class="string">&quot;maximize&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>The hyperparameter_search method returns a <code>BestRun</code> objects, which contains the value of the objective maximized (by default the sum of all metrics) and the hyperparameters it used for that run.<br>hyperparameter_search‰ºöËøîÂõûÊïàÊûúÊúÄÂ•ΩÁöÑÊ®°ÂûãÁõ∏ÂÖ≥ÁöÑÂèÇÊï∞Ôºö</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>best_run</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>To reproduce the best training, just set the hyperparameters in your TrainingArgument before creating a Trainer:<br>Â∞ÜTrainnerËÆæÁΩÆ‰∏∫ÊêúÁ¥¢Âà∞ÁöÑÊúÄÂ•ΩÂèÇÊï∞ÔºåËøõË°åËÆ≠ÁªÉÔºö</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> n, v <span class="keyword">in</span> best_run.hyperparameters.items():</span><br><span class="line">    <span class="built_in">setattr</span>(trainer.args, n, v)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>


<h1 id="ÂèÇËÄÉËµÑÊñô"><a href="#ÂèÇËÄÉËµÑÊñô" class="headerlink" title="ÂèÇËÄÉËµÑÊñô"></a>ÂèÇËÄÉËµÑÊñô</h1><ul>
<li>HuggingFace/transfomers/BERT <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/bert.html#">https://huggingface.co/transformers/model_doc/bert.html#</a></li>
<li>Âü∫‰∫étransformersÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ(NLP)ÂÖ•Èó®‚ÄìÂú®Á∫øÈòÖËØª <a target="_blank" rel="noopener" href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a></li>
</ul>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/pytorch-chap03/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    Chapter03 PyTorchÁöÑ‰∏ªË¶ÅÁªÑÊàêÊ®°Âùó
                
            </div>
        </a>
    
    
        <a href="/nlp-transformer-task06/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">Task06 BERTÂ∫îÁî®„ÄÅËÆ≠ÁªÉÂíå‰ºòÂåñ</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            Xiaoyu CHU &copy; 2021 
            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>