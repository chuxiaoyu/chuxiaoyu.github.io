<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset="utf-8">
    
    <title>Task07 ä½¿ç”¨Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ | Memex</title>
    
    
        <meta name="keywords" content="ç¬”è®°,NLP,ç»„é˜Ÿå­¦ä¹ ,é¢„è®­ç»ƒæ¨¡å‹,BERT,transfomer,æ–‡æœ¬åˆ†ç±»" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="è¯¥éƒ¨åˆ†çš„å†…å®¹ç¿»è¯‘è‡ªğŸ¤—HuggingFace&#x2F;notebooks https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;notebooks&#x2F;tree&#x2F;master&#x2F;examplesä¸­æ–‡ç¿»è¯‘ï¼šDatawhale&#x2F;learn-nlp-with-transformers&#x2F;4.1-æ–‡æœ¬åˆ†ç±» Datawhale&#x2F;learn-nlp-with-transformers&#x2F;4.1-æ–‡æœ¬åˆ†ç±» å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹">
<meta property="og:type" content="article">
<meta property="og:title" content="Task07 ä½¿ç”¨Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡">
<meta property="og:url" content="http://example.com/nlp-transformer-task07/index.html">
<meta property="og:site_name" content="Memex">
<meta property="og:description" content="è¯¥éƒ¨åˆ†çš„å†…å®¹ç¿»è¯‘è‡ªğŸ¤—HuggingFace&#x2F;notebooks https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;notebooks&#x2F;tree&#x2F;master&#x2F;examplesä¸­æ–‡ç¿»è¯‘ï¼šDatawhale&#x2F;learn-nlp-with-transformers&#x2F;4.1-æ–‡æœ¬åˆ†ç±» Datawhale&#x2F;learn-nlp-with-transformers&#x2F;4.1-æ–‡æœ¬åˆ†ç±» å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/00_bg.png?raw=true">
<meta property="article:published_time" content="2021-09-25T08:57:45.000Z">
<meta property="article:modified_time" content="2021-10-02T09:21:50.190Z">
<meta property="article:author" content="Xiaoyu CHU">
<meta property="article:tag" content="ç¬”è®°">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="ç»„é˜Ÿå­¦ä¹ ">
<meta property="article:tag" content="é¢„è®­ç»ƒæ¨¡å‹">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="transfomer">
<meta property="article:tag" content="æ–‡æœ¬åˆ†ç±»">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/00_bg.png?raw=true">
    

    
        <link rel="alternate" href="/atom.xml" title="Memex" type="application/atom+xml" />
    

    
        <link rel="icon" href="/logo.jpg" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Memex</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">é¦–é¡µ</a>
                
                    <a class="main-nav-link" href="/archives">å½’æ¡£</a>
                
                    <a class="main-nav-link" href="/categories">åˆ†ç±»</a>
                
                    <a class="main-nav-link" href="/tags">æ ‡ç­¾</a>
                
                    <a class="main-nav-link" href="/about">å…³äº</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">é¦–é¡µ</a></td>
                
                    <td><a class="main-nav-link" href="/archives">å½’æ¡£</a></td>
                
                    <td><a class="main-nav-link" href="/categories">åˆ†ç±»</a></td>
                
                    <td><a class="main-nav-link" href="/tags">æ ‡ç­¾</a></td>
                
                    <td><a class="main-nav-link" href="/about">å…³äº</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>categories</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-up fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" style="display: block;"> 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            01 è®¡ç®—æœºåŸºç¡€
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;"> 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            CS61A è®¡ç®—æœºç¨‹åºçš„æ„é€ ä¸è§£é‡Š
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/cs61a-week1/">CS61A Week1 Comupter_Science, Functions</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            CSAPP æ·±å…¥ç†è§£è®¡ç®—æœºç³»ç»Ÿ
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/csapp-chap01/">CSAPP Chap01 è®¡ç®—æœºç³»ç»Ÿæ¼«æ¸¸</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            02 äººå·¥æ™ºèƒ½
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;"> 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            CS224n è‡ªç„¶è¯­è¨€å¤„ç†
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/cs224n-lec01/">CS224n Lec01 Introduction and Word Vectors</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            æ•°æ®åˆ†æ
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/">æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡</a></li>  <li class="file"><a href="/SQL%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/">SQLå­¦ä¹ èµ„æ–™</a></li>  <li class="file"><a href="/SQL%E9%87%8D%E7%82%B9/">SQLè¡¨è¿æ¥&èšåˆå‡½æ•°&çª—å£å‡½æ•°</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            æå®æ¯…æœºå™¨å­¦ä¹ 
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/leeml-lec01-introduction/">Lecture01 æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç®€ä»‹</a></li>  <li class="file"><a href="/leeml-lec01-bp/">Lecture01(elective) åå‘ä¼ æ’­ç®—æ³•</a></li>  <li class="file"><a href="/leeml-rnn/">å¾ªç¯ç¥ç»ç½‘ç»œ</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            è‡ªç„¶è¯­è¨€å¤„ç†
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/nlp-text-representation/">NLPä¹‹æ–‡æœ¬è¡¨ç¤º</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            03 å·¥å…·ç®±
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%AD%E8%8B%B1%E6%96%87LaTeX%E7%AE%80%E5%8E%86%E6%A8%A1%E6%9D%BF/">ä¸€äº›å¥½ç”¨çš„ä¸­è‹±æ–‡LaTeXç®€å†æ¨¡æ¿</a></li>  <li class="file"><a href="/git/">5hæ‰“é€šGitå…¨å¥—æ•™ç¨‹</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            04 ç»„é˜Ÿå­¦ä¹ 
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;"> 
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            ç¬¬29æœŸ åŸºäºtransformerçš„NLP
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/nlp-transformer-task01/">Task01 NLPå­¦ä¹ æ¦‚è§ˆ</a></li>  <li class="file"><a href="/nlp-transformer-task02/">Task02 å­¦ä¹ Attentioinå’ŒTransformer</a></li>  <li class="file"><a href="/nlp-transformer-task03/">Task03 å­¦ä¹ BERT</a></li>  <li class="file"><a href="/nlp-transformer-task04/">Task04 å­¦ä¹ GPT</a></li>  <li class="file"><a href="/nlp-transformer-task05/">Task05 ç¼–å†™BERTæ¨¡å‹</a></li>  <li class="file"><a href="/nlp-transformer-task06/">Task06 BERTåº”ç”¨ã€è®­ç»ƒå’Œä¼˜åŒ–</a></li>  <li class="file active"><a href="/nlp-transformer-task07/">Task07 ä½¿ç”¨Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡</a></li>  <li class="file"><a href="/nlp-transformer-summary/">Summary Transformerè¯¾ç¨‹æ€»ç»“</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            ç¬¬30æœŸ æ·±å…¥æµ…å‡ºPyTorch
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/pytorch-chap01-02/">Chapter01-02 PyTorchçš„ç®€ä»‹å’Œå®‰è£…ã€PyTorchåŸºç¡€çŸ¥è¯†</a></li>  <li class="file"><a href="/pytorch-chap03/">Chapter03 PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—</a></li>  <li class="file"><a href="/pytorch-chap04/">Chapter04 PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMNISTå›¾åƒåˆ†ç±»</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            æ²‰æ€å½•
                        </a>
                         <ul class="unstyled" id="tree" style="display: block;">  <li class="file"><a href="/%E5%A4%A7%E7%90%86/">å¤§ç†ï¼Œåœ¨æ°‘å®¿æ‰“å·¥çš„æ—¥å­</a></li>  <li class="file"><a href="/formula/">å…¬å¼ä¹‹ç¾ï¼ŒEVERYTHING IS EPHEMERAL BUT FORMULA IS ETERNAL</a></li>  <li class="file"><a href="/feynman-quotes/">è´¹æ›¼è¯­å½•ï¼ˆç¿»è¯‘è‡ªTwitterï¼‰</a></li>  </ul> 
                    </li> 
                     </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // å·¦é”®å•ç‹¬å±•å¼€ç›®å½•
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // å³é”®å±•å¼€ä¸‹å±æ‰€æœ‰ç›®å½•
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // å±•å¼€å…³é—­æ‰€æœ‰ç›®å½•æŒ‰é’®
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>recent</span></h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/feynman-quotes/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/feynman.jpg?raw=true)" alt="è´¹æ›¼è¯­å½•ï¼ˆç¿»è¯‘è‡ªTwitterï¼‰" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%B2%89%E6%80%9D%E5%BD%95/">æ²‰æ€å½•</a></p>
                            <p class="item-title"><a href="/feynman-quotes/" class="title">è´¹æ›¼è¯­å½•ï¼ˆç¿»è¯‘è‡ªTwitterï¼‰</a></p>
                            <p class="item-date"><time datetime="2021-12-02T05:38:38.000Z" itemprop="datePublished">2021-12-02</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/cs224n-lec01/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/nlp.jpg?raw=true)" alt="CS224n Lec01 Introduction and Word Vectors" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">02 äººå·¥æ™ºèƒ½</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/CS224n-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">CS224n è‡ªç„¶è¯­è¨€å¤„ç†</a></p>
                            <p class="item-title"><a href="/cs224n-lec01/" class="title">CS224n Lec01 Introduction and Word Vectors</a></p>
                            <p class="item-date"><time datetime="2021-11-28T11:37:51.000Z" itemprop="datePublished">2021-11-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/csapp-chap01/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/csapp/00.jpg?raw=true)" alt="CSAPP Chap01 è®¡ç®—æœºç³»ç»Ÿæ¼«æ¸¸" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/">01 è®¡ç®—æœºåŸºç¡€</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/CSAPP-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/">CSAPP æ·±å…¥ç†è§£è®¡ç®—æœºç³»ç»Ÿ</a></p>
                            <p class="item-title"><a href="/csapp-chap01/" class="title">CSAPP Chap01 è®¡ç®—æœºç³»ç»Ÿæ¼«æ¸¸</a></p>
                            <p class="item-date"><time datetime="2021-10-26T02:26:30.000Z" itemprop="datePublished">2021-10-26</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/leeml-rnn/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/00_logo.jpeg?raw=true)" alt="å¾ªç¯ç¥ç»ç½‘ç»œ" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">02 äººå·¥æ™ºèƒ½</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">æå®æ¯…æœºå™¨å­¦ä¹ </a></p>
                            <p class="item-title"><a href="/leeml-rnn/" class="title">å¾ªç¯ç¥ç»ç½‘ç»œ</a></p>
                            <p class="item-date"><time datetime="2021-10-24T08:15:10.000Z" itemprop="datePublished">2021-10-24</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/leeml-lec01-bp/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/00_logo.jpeg?raw=true)" alt="Lecture01(elective) åå‘ä¼ æ’­ç®—æ³•" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">02 äººå·¥æ™ºèƒ½</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">æå®æ¯…æœºå™¨å­¦ä¹ </a></p>
                            <p class="item-title"><a href="/leeml-lec01-bp/" class="title">Lecture01(elective) åå‘ä¼ æ’­ç®—æ³•</a></p>
                            <p class="item-date"><time datetime="2021-10-15T06:55:13.000Z" itemprop="datePublished">2021-10-15</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>archives</span></h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a><span class="archive-list-count">7</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>tag cloud</span></h3>
        <div class="widget tagcloud">
            <a href="/tags/BERT/" style="font-size: 14.29px;">BERT</a> <a href="/tags/CS%E5%85%AC%E5%BC%80%E8%AF%BE/" style="font-size: 11.43px;">CSå…¬å¼€è¯¾</a> <a href="/tags/GPT/" style="font-size: 10px;">GPT</a> <a href="/tags/NLP/" style="font-size: 18.57px;">NLP</a> <a href="/tags/PyTorch/" style="font-size: 12.86px;">PyTorch</a> <a href="/tags/SQL/" style="font-size: 11.43px;">SQL</a> <a href="/tags/attention/" style="font-size: 10px;">attention</a> <a href="/tags/back-propagation/" style="font-size: 10px;">back propagation</a> <a href="/tags/computer-system/" style="font-size: 10px;">computer system</a> <a href="/tags/csapp/" style="font-size: 10px;">csapp</a> <a href="/tags/feynman/" style="font-size: 10px;">feynman</a> <a href="/tags/function/" style="font-size: 10px;">function</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/laTeX/" style="font-size: 10px;">laTeX</a> <a href="/tags/machine-learning/" style="font-size: 12.86px;">machine learning</a> <a href="/tags/math/" style="font-size: 10px;">math</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/quote/" style="font-size: 10px;">quote</a> <a href="/tags/regression/" style="font-size: 10px;">regression</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/team-leaning/" style="font-size: 10px;">team leaning</a> <a href="/tags/team-learning/" style="font-size: 10px;">team learning</a> <a href="/tags/transfomer/" style="font-size: 15.71px;">transfomer</a> <a href="/tags/%E5%A4%A7%E7%90%86/" style="font-size: 10px;">å¤§ç†</a> <a href="/tags/%E6%80%BB%E7%BB%93/" style="font-size: 10px;">æ€»ç»“</a> <a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" style="font-size: 10px;">æ–‡æœ¬åˆ†ç±»</a> <a href="/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/" style="font-size: 10px;">æ–‡æœ¬è¡¨ç¤º</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 20px;">ç¬”è®°</a> <a href="/tags/%E7%AE%80%E5%8E%86/" style="font-size: 10px;">ç®€å†</a> <a href="/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">ç»„é˜Ÿå­¦ä¹ </a> <a href="/tags/%E7%BB%9F%E8%AE%A1/" style="font-size: 10px;">ç»Ÿè®¡</a> <a href="/tags/%E9%98%85%E8%AF%BB/" style="font-size: 10px;">é˜…è¯»</a> <a href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" style="font-size: 17.14px;">é¢„è®­ç»ƒæ¨¡å‹</a>
        </div>
    </div>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-nlp-transformer-task07" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/">04 ç»„é˜Ÿå­¦ä¹ </a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/">ç¬¬29æœŸ åŸºäºtransformerçš„NLP</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/BERT/" rel="tag">BERT</a>, <a class="tag-link-link" href="/tags/NLP/" rel="tag">NLP</a>, <a class="tag-link-link" href="/tags/transfomer/" rel="tag">transfomer</a>, <a class="tag-link-link" href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" rel="tag">æ–‡æœ¬åˆ†ç±»</a>, <a class="tag-link-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">ç¬”è®°</a>, <a class="tag-link-link" href="/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/" rel="tag">ç»„é˜Ÿå­¦ä¹ </a>, <a class="tag-link-link" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" rel="tag">é¢„è®­ç»ƒæ¨¡å‹</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/nlp-transformer-task07/">
            <time datetime="2021-09-25T08:57:45.000Z" itemprop="datePublished">2021-09-25</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            Task07 ä½¿ç”¨Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">Catalogue</strong>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB"><span class="toc-number">1.</span> <span class="toc-text">å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.</span> <span class="toc-text">åŠ è½½æ•°æ®é›†</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">æ•°æ®é¢„å¤„ç†</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">å¾®è°ƒæ¨¡å‹</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%90%9C%E7%B4%A2"><span class="toc-number">5.</span> <span class="toc-text">è¶…å‚æœç´¢</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">6.</span> <span class="toc-text">å‚è€ƒèµ„æ–™</span></a></li></ol>
                </div>
            
        
        
            <p><em>è¯¥éƒ¨åˆ†çš„å†…å®¹ç¿»è¯‘è‡ªğŸ¤—HuggingFace/notebooks <a target="_blank" rel="noopener" href="https://github.com/huggingface/notebooks/tree/master/examples">https://github.com/huggingface/notebooks/tree/master/examples</a></em><br><em>ä¸­æ–‡ç¿»è¯‘ï¼šDatawhale/learn-nlp-with-transformers/4.1-æ–‡æœ¬åˆ†ç±» <a target="_blank" rel="noopener" href="https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1/4.1-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.md">Datawhale/learn-nlp-with-transformers/4.1-æ–‡æœ¬åˆ†ç±»</a></em></p>
<h1 id="å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»"><a href="#å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»" class="headerlink" title="å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»"></a>å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»</h1><p>æˆ‘ä»¬å°†ä½¿ç”¨ ğŸ¤— Transformersä»£ç åº“ä¸­çš„æ¨¡å‹æ¥è§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œä»»åŠ¡æ¥æºäºGLUE Benchmark.<br>GLUEæ¦œå•åŒ…å«äº†9ä¸ªå¥å­çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡ï¼Œåˆ†åˆ«æ˜¯ï¼š</p>
<ul>
<li>CoLA (Corpus of Linguistic Acceptability) é‰´åˆ«ä¸€ä¸ªå¥å­æ˜¯å¦è¯­æ³•æ­£ç¡®.</li>
<li>MNLI (Multi-Genre Natural Language Inference) ç»™å®šä¸€ä¸ªå‡è®¾ï¼Œåˆ¤æ–­å¦ä¸€ä¸ªå¥å­ä¸è¯¥å‡è®¾çš„å…³ç³»ï¼šentails, contradicts æˆ–è€… unrelatedã€‚</li>
<li>MRPC (Microsoft Research Paraphrase Corpus) åˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦äº’ä¸ºparaphrases.</li>
<li>QNLI (Question-answering Natural Language Inference) åˆ¤æ–­ç¬¬2å¥æ˜¯å¦åŒ…å«ç¬¬1å¥é—®é¢˜çš„ç­”æ¡ˆã€‚</li>
<li>QQP (Quora Question Pairs2) åˆ¤æ–­ä¸¤ä¸ªé—®å¥æ˜¯å¦è¯­ä¹‰ç›¸åŒã€‚</li>
<li>RTE (Recognizing Textual Entailment)åˆ¤æ–­ä¸€ä¸ªå¥å­æ˜¯å¦ä¸å‡è®¾æˆentailå…³ç³»ã€‚</li>
<li>SST-2 (Stanford Sentiment Treebank) åˆ¤æ–­ä¸€ä¸ªå¥å­çš„æƒ…æ„Ÿæ­£è´Ÿå‘.</li>
<li>STS-B (Semantic Textual Similarity Benchmark) åˆ¤æ–­ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼æ€§ï¼ˆåˆ†æ•°ä¸º1-5åˆ†ï¼‰ã€‚</li>
<li>WNLI (Winograd Natural Language Inference) Determine if a sentence with an anonymous pronoun and a sentence with this pronoun replaced are entailed or not.</li>
</ul>
<p>å¯¹äºä»¥ä¸Šä»»åŠ¡ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç®€å•çš„Datasetåº“åŠ è½½æ•°æ®é›†ï¼ŒåŒæ—¶ä½¿ç”¨transformerä¸­çš„Traineræ¥å£å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GLUE_TASKS = [<span class="string">&quot;cola&quot;</span>, <span class="string">&quot;mnli&quot;</span>, <span class="string">&quot;mnli-mm&quot;</span>, <span class="string">&quot;mrpc&quot;</span>, <span class="string">&quot;qnli&quot;</span>, <span class="string">&quot;qqp&quot;</span>, <span class="string">&quot;rte&quot;</span>, <span class="string">&quot;sst2&quot;</span>, <span class="string">&quot;stsb&quot;</span>, <span class="string">&quot;wnli&quot;</span>]</span><br></pre></td></tr></table></figure>

<p>This notebook is built to run on any of the tasks in the list above, with any model checkpoint from the Model Hub as long as that model has a version with a classification head. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:<br>æœ¬notebookç†è®ºä¸Šå¯ä»¥ä½¿ç”¨å„ç§å„æ ·çš„transformeræ¨¡å‹ï¼ˆæ¨¡å‹é¢æ¿ï¼‰ï¼Œè§£å†³ä»»ä½•æ–‡æœ¬åˆ†ç±»åˆ†ç±»ä»»åŠ¡ã€‚å¦‚æœæ‚¨æ‰€å¤„ç†çš„ä»»åŠ¡æœ‰æ‰€ä¸åŒï¼Œå¤§æ¦‚ç‡åªéœ€è¦å¾ˆå°çš„æ”¹åŠ¨ä¾¿å¯ä»¥ä½¿ç”¨æœ¬notebookè¿›è¡Œå¤„ç†ã€‚åŒæ—¶ï¼Œæ‚¨åº”è¯¥æ ¹æ®æ‚¨çš„GPUæ˜¾å­˜æ¥è°ƒæ•´å¾®è°ƒè®­ç»ƒæ‰€éœ€è¦çš„btach sizeå¤§å°ï¼Œé¿å…æ˜¾å­˜æº¢å‡ºã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">task = <span class="string">&quot;cola&quot;</span></span><br><span class="line">model_checkpoint = <span class="string">&quot;distilbert-base-uncased&quot;</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br></pre></td></tr></table></figure>

<h1 id="åŠ è½½æ•°æ®é›†"><a href="#åŠ è½½æ•°æ®é›†" class="headerlink" title="åŠ è½½æ•°æ®é›†"></a>åŠ è½½æ•°æ®é›†</h1><p>We will use the ğŸ¤— Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions <code>load_dataset</code> and <code>load_metric</code>.<br>æˆ‘ä»¬å°†ä¼šä½¿ç”¨ğŸ¤— Datasetsåº“æ¥åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼ã€‚æ•°æ®åŠ è½½å’Œè¯„æµ‹æ–¹å¼åŠ è½½åªéœ€è¦ç®€å•ä½¿ç”¨load_datasetå’Œload_metricå³å¯ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from datasets import load_dataset, load_metric</span><br></pre></td></tr></table></figure>

<p>Apart from mnli-mm being a special code, we can directly pass our task name to those functions. <code>load_dataset</code> will cache the dataset to avoid downloading it again the next time you run this cell.<br>é™¤äº†mnli-mmä»¥å¤–ï¼Œå…¶ä»–ä»»åŠ¡éƒ½å¯ä»¥ç›´æ¥é€šè¿‡ä»»åŠ¡åå­—è¿›è¡ŒåŠ è½½ã€‚æ•°æ®åŠ è½½ä¹‹åä¼šè‡ªåŠ¨ç¼“å­˜ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">actual_task = <span class="string">&quot;mnli&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> task</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;glue&quot;</span>, actual_task)</span><br><span class="line">metric = load_metric(<span class="string">&#x27;glue&#x27;</span>, actual_task)</span><br></pre></td></tr></table></figure>
<p><em>ä¸ŠèŠ‚è®²è¿‡ï¼Œè¿™é‡Œï¼Œæœ€å¥½æ‰‹åŠ¨ä¸‹è½½glue.pyå’Œgule_metric.pyï¼Œä¸ä¸‹è½½åˆ°æœ¬åœ°çš„è¯ï¼Œå®¹æ˜“å‡ºç°è¿æ¥é”™è¯¯ã€‚</em></p>
<p>The dataset object itself is DatasetDict, which contains one key for the training, validation and test set (with more keys for the mismatched validation and test set in the special case of mnli).<br>è¿™ä¸ªdatasetså¯¹è±¡æœ¬èº«æ˜¯ä¸€ç§DatasetDictæ•°æ®ç»“æ„.å¯¹äºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œåªéœ€è¦ä½¿ç”¨å¯¹åº”çš„keyï¼ˆtrainï¼Œvalidationï¼Œtestï¼‰å³å¯å¾—åˆ°ç›¸åº”çš„æ•°æ®ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataset</span><br><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">8551</span></span><br><span class="line">    &#125;)</span><br><span class="line">    validation: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1043</span></span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1063</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataset[<span class="string">&quot;train&quot;</span>][<span class="number">0</span>]</span><br><span class="line">&#123;<span class="string">&#x27;sentence&#x27;</span>: <span class="string">&quot;Our friends won&#x27;t buy this analysis, let alone the next one we propose.&quot;</span>,</span><br><span class="line"><span class="string">&#x27;label&#x27;</span>: <span class="number">1</span>, </span><br><span class="line"><span class="string">&#x27;idx&#x27;</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure>

<p>To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset.<br>ä¸ºäº†èƒ½å¤Ÿè¿›ä¸€æ­¥ç†è§£æ•°æ®é•¿ä»€ä¹ˆæ ·å­ï¼Œä¸‹é¢çš„å‡½æ•°å°†ä»æ•°æ®é›†é‡Œéšæœºé€‰æ‹©å‡ ä¸ªä¾‹å­è¿›è¡Œå±•ç¤ºã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, HTML</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_random_elements</span>(<span class="params">dataset, num_examples=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">assert</span> num_examples &lt;= <span class="built_in">len</span>(dataset), <span class="string">&quot;Can&#x27;t pick more elements than there are in the dataset.&quot;</span></span><br><span class="line">    picks = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_examples):</span><br><span class="line">        pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">while</span> pick <span class="keyword">in</span> picks:</span><br><span class="line">            pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        picks.append(pick)</span><br><span class="line">    </span><br><span class="line">    df = pd.DataFrame(dataset[picks])</span><br><span class="line">    <span class="keyword">for</span> column, typ <span class="keyword">in</span> dataset.features.items():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(typ, datasets.ClassLabel):</span><br><span class="line">            df[column] = df[column].transform(<span class="keyword">lambda</span> i: typ.names[i])</span><br><span class="line">    display(HTML(df.to_html()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_random_elements(dataset[<span class="string">&quot;train&quot;</span>])</span><br></pre></td></tr></table></figure>

<p>The metric is an instance of datasets.Metric:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>You can call its <code>compute</code> method with your predictions and labels directly and it will return a dictionary with the metric(s) value:<br>ç›´æ¥è°ƒç”¨metricçš„computeæ–¹æ³•ï¼Œä¼ å…¥labelså’Œpredictionså³å¯å¾—åˆ°metricçš„å€¼ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">fake_preds = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(<span class="number">64</span>,))</span><br><span class="line">fake_labels = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(<span class="number">64</span>,))</span><br><span class="line">metric.compute(predictions=fake_preds, references=fake_labels)</span><br></pre></td></tr></table></figure>
<p>Note that load_metric has loaded the proper metric associated to your task, which is:<br>æ¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡æ‰€å¯¹åº”çš„meticæœ‰æ‰€ä¸åŒï¼Œå…·ä½“å¦‚ä¸‹:</p>
<ul>
<li>for CoLA: Matthews Correlation Coefficient</li>
<li>for MNLI (matched or mismatched): Accuracy</li>
<li>for MRPC: Accuracy and F1 score</li>
<li>for QNLI: Accuracy</li>
<li>for QQP: Accuracy and F1 score</li>
<li>for RTE: Accuracy</li>
<li>for SST-2: Accuracy</li>
<li>for STS-B: Pearson Correlation Coefficient and Spearmanâ€™s_Rank_Correlation_Coefficient</li>
<li>for WNLI: Accuracy</li>
</ul>
<p>so the metric object only computes the one(s) needed for your task.</p>
<h1 id="æ•°æ®é¢„å¤„ç†"><a href="#æ•°æ®é¢„å¤„ç†" class="headerlink" title="æ•°æ®é¢„å¤„ç†"></a>æ•°æ®é¢„å¤„ç†</h1><p>Before we can feed those texts to our model, we need to preprocess them. This is done by a ğŸ¤— Transformers <code>Tokenizer</code> which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.<br>åœ¨å°†æ•°æ®å–‚å…¥æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚é¢„å¤„ç†çš„å·¥å…·å«Tokenizerã€‚Tokenizeré¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œtokenizeï¼Œç„¶åå°†tokensè½¬åŒ–ä¸ºé¢„æ¨¡å‹ä¸­éœ€è¦å¯¹åº”çš„token IDï¼Œå†è½¬åŒ–ä¸ºæ¨¡å‹éœ€è¦çš„è¾“å…¥æ ¼å¼ã€‚</p>
<p>To do all of this, we instantiate our tokenizer with the <code>AutoTokenizer.from_pretrained</code> method, which will ensure:</p>
<ul>
<li>we get a tokenizer that corresponds to the model architecture we want to use,</li>
<li>we download the vocabulary used when pretraining this specific checkpoint.</li>
</ul>
<p>ä¸ºäº†è¾¾åˆ°æ•°æ®é¢„å¤„ç†çš„ç›®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨AutoTokenizer.from_pretrainedæ–¹æ³•å®ä¾‹åŒ–æˆ‘ä»¬çš„tokenizerï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ï¼š</p>
<ul>
<li>æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€ä¸€å¯¹åº”çš„tokenizerã€‚</li>
<li>ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹checkpointå¯¹åº”çš„tokenizerçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¸‹è½½äº†æ¨¡å‹éœ€è¦çš„è¯è¡¨åº“vocabularyï¼Œå‡†ç¡®æ¥è¯´æ˜¯tokens vocabularyã€‚</li>
</ul>
<p>That vocabulary will be cached, so itâ€™s not downloaded again the next time we run the cell.<br>è¿™ä¸ªè¢«ä¸‹è½½çš„tokens vocabularyä¼šè¢«ç¼“å­˜èµ·æ¥ï¼Œä»è€Œå†æ¬¡ä½¿ç”¨çš„æ—¶å€™ä¸ä¼šé‡æ–°ä¸‹è½½ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">    </span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>You can directly call this tokenizer on one sentence or a pair of sentences:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer(<span class="string">&quot;Hello, this one sentence!&quot;</span>, <span class="string">&quot;And this sentence goes with it.&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>è¾“å‡ºä¸ºï¼š<br>pass</p>
<p>To preprocess our dataset, we will thus need the names of the columns containing the sentence(s). The following dictionary keeps track of the correspondence task to column names:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">task_to_keys = &#123;</span><br><span class="line">    <span class="string">&quot;cola&quot;</span>: (<span class="string">&quot;sentence&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    <span class="string">&quot;mnli&quot;</span>: (<span class="string">&quot;premise&quot;</span>, <span class="string">&quot;hypothesis&quot;</span>),</span><br><span class="line">    <span class="string">&quot;mnli-mm&quot;</span>: (<span class="string">&quot;premise&quot;</span>, <span class="string">&quot;hypothesis&quot;</span>),</span><br><span class="line">    <span class="string">&quot;mrpc&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;qnli&quot;</span>: (<span class="string">&quot;question&quot;</span>, <span class="string">&quot;sentence&quot;</span>),</span><br><span class="line">    <span class="string">&quot;qqp&quot;</span>: (<span class="string">&quot;question1&quot;</span>, <span class="string">&quot;question2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;rte&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;sst2&quot;</span>: (<span class="string">&quot;sentence&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    <span class="string">&quot;stsb&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;wnli&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>We can double check it does work on our current dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sentence1_key, sentence2_key = task_to_keys[task]</span><br><span class="line"><span class="keyword">if</span> sentence2_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence1_key]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence 1: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence1_key]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence 2: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence2_key]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>è¾“å‡ºä¸ºï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sentence: Our friends won&#x27;t buy this analysis, let alone the next one we propose.</span><br></pre></td></tr></table></figure>

<p>We can them write the function that will preprocess our samples. We just feed them to the <code>tokenizer</code> with the argument <code>truncation=True</code>. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_function</span>(<span class="params">examples</span>):</span></span><br><span class="line">    <span class="keyword">if</span> sentence2_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> tokenizer(examples[sentence1_key], truncation=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>preprocess_function(dataset[<span class="string">&#x27;train&#x27;</span>][:<span class="number">5</span>])</span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [[<span class="number">101</span>, <span class="number">2256</span>, <span class="number">2814</span>, <span class="number">2180</span>, <span class="number">1005</span>, <span class="number">1056</span>, <span class="number">4965</span>, <span class="number">2023</span>, <span class="number">4106</span>, <span class="number">1010</span>, <span class="number">2292</span>, <span class="number">2894</span>, <span class="number">1996</span>, <span class="number">2279</span>, <span class="number">2028</span>, <span class="number">2057</span>, <span class="number">16599</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2028</span>, <span class="number">2062</span>, <span class="number">18404</span>, <span class="number">2236</span>, <span class="number">3989</span>, <span class="number">1998</span>, <span class="number">1045</span>, <span class="number">1005</span>, <span class="number">1049</span>, <span class="number">3228</span>, <span class="number">2039</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2028</span>, <span class="number">2062</span>, <span class="number">18404</span>, <span class="number">2236</span>, <span class="number">3989</span>, <span class="number">2030</span>, <span class="number">1045</span>, <span class="number">1005</span>, <span class="number">1049</span>, <span class="number">3228</span>, <span class="number">2039</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">1996</span>, <span class="number">2062</span>, <span class="number">2057</span>, <span class="number">2817</span>, <span class="number">16025</span>, <span class="number">1010</span>, <span class="number">1996</span>, <span class="number">13675</span>, <span class="number">16103</span>, <span class="number">2121</span>, <span class="number">2027</span>, <span class="number">2131</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2154</span>, <span class="number">2011</span>, <span class="number">2154</span>, <span class="number">1996</span>, <span class="number">8866</span>, <span class="number">2024</span>, <span class="number">2893</span>, <span class="number">14163</span>, <span class="number">8024</span>, <span class="number">3771</span>, <span class="number">1012</span>, <span class="number">102</span>]], <span class="string">&#x27;attention_mask&#x27;</span>: [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]&#125;</span><br></pre></td></tr></table></figure>

<p>To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the <code>map</code> method of our <code>dataset</code> object we created earlier. This will apply the function on all the elements of all the splits in <code>dataset</code>, so our training, validation and testing data will be preprocessed in one single command.<br>æ¥ä¸‹æ¥å¯¹æ•°æ®é›†datasetsé‡Œé¢çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œå¤„ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨mapå‡½æ•°ï¼Œå°†é¢„å¤„ç†å‡½æ•°prepare_train_featuresåº”ç”¨åˆ°ï¼ˆmap)æ‰€æœ‰æ ·æœ¬ä¸Šã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoded_dataset = dataset.<span class="built_in">map</span>(preprocess_function, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h1 id="å¾®è°ƒæ¨¡å‹"><a href="#å¾®è°ƒæ¨¡å‹" class="headerlink" title="å¾®è°ƒæ¨¡å‹"></a>å¾®è°ƒæ¨¡å‹</h1><p>Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about sentence classification, we use the AutoModelForSequenceClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which is always 2, except for STS-B which is a regression problem and MNLI where we have 3 labels):<br>æ—¢ç„¶æ•°æ®å·²ç»å‡†å¤‡å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦ä¸‹è½½å¹¶åŠ è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚æ—¢ç„¶æˆ‘ä»¬æ˜¯åšseq2seqä»»åŠ¡ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½è§£å†³è¿™ä¸ªä»»åŠ¡çš„æ¨¡å‹ç±»ã€‚æˆ‘ä»¬ä½¿ç”¨AutoModelForSequenceClassification è¿™ä¸ªç±»ã€‚å’Œtokenizerç›¸ä¼¼ï¼Œfrom_pretrainedæ–¹æ³•åŒæ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿä¼šå¯¹æ¨¡å‹è¿›è¡Œç¼“å­˜ï¼Œå°±ä¸ä¼šé‡å¤ä¸‹è½½æ¨¡å‹å•¦ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, TrainingArguments, Trainer</span><br><span class="line"></span><br><span class="line">num_labels = <span class="number">3</span> <span class="keyword">if</span> task.startswith(<span class="string">&quot;mnli&quot;</span>) <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">if</span> task==<span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br></pre></td></tr></table></figure>
<p>è¾“å‡ºä¸ºï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: [&#x27;vocab_transform.bias&#x27;, &#x27;vocab_projector.weight&#x27;, &#x27;vocab_layer_norm.bias&#x27;, &#x27;vocab_layer_norm.weight&#x27;, &#x27;vocab_projector.bias&#x27;, &#x27;vocab_transform.weight&#x27;]</span><br><span class="line">- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</span><br><span class="line">- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</span><br><span class="line">Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#x27;classifier.weight&#x27;, &#x27;classifier.bias&#x27;, &#x27;pre_classifier.bias&#x27;, &#x27;pre_classifier.weight&#x27;]</span><br><span class="line">You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</span><br></pre></td></tr></table></figure>
<p>The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we donâ€™t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do.<br>ç”±äºæˆ‘ä»¬å¾®è°ƒçš„ä»»åŠ¡æ˜¯æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œè€Œæˆ‘ä»¬åŠ è½½çš„æ˜¯é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œæ‰€ä»¥ä¼šæç¤ºæˆ‘ä»¬åŠ è½½æ¨¡å‹çš„æ—¶å€™æ‰”æ‰äº†ä¸€äº›ä¸åŒ¹é…çš„ç¥ç»ç½‘ç»œå‚æ•°ï¼ˆæ¯”å¦‚ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç¥ç»ç½‘ç»œheadè¢«æ‰”æ‰äº†ï¼ŒåŒæ—¶éšæœºåˆå§‹åŒ–äº†æ–‡æœ¬åˆ†ç±»çš„ç¥ç»ç½‘ç»œheadï¼‰ã€‚</p>
<p>To instantiate a <code>Trainer</code>, we will need to define two more things. The most important is the <code>TrainingArguments</code>, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:<br>ä¸ºäº†èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ªTrainerè®­ç»ƒå·¥å…·ï¼Œæˆ‘ä»¬è¿˜éœ€è¦3ä¸ªè¦ç´ ï¼Œå…¶ä¸­æœ€é‡è¦çš„æ˜¯è®­ç»ƒçš„è®¾å®š/å‚æ•° TrainingArgumentsã€‚è¿™ä¸ªè®­ç»ƒè®¾å®šåŒ…å«äº†èƒ½å¤Ÿå®šä¹‰è®­ç»ƒè¿‡ç¨‹çš„æ‰€æœ‰å±æ€§ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">metric_name = <span class="string">&quot;pearson&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="string">&quot;matthews_correlation&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;cola&quot;</span> <span class="keyword">else</span> <span class="string">&quot;accuracy&quot;</span></span><br><span class="line">model_name = model_checkpoint.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">args = TrainingArguments(</span><br><span class="line">    <span class="string">&quot;test-glue&quot;</span>,</span><br><span class="line">    evaluation_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    save_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=batch_size,</span><br><span class="line">    per_device_eval_batch_size=batch_size,</span><br><span class="line">    num_train_epochs=<span class="number">5</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">    metric_for_best_model=metric_name,</span><br><span class="line">    push_to_hub=<span class="literal">False</span>,</span><br><span class="line">    push_to_hub_model_id=<span class="string">f&quot;<span class="subst">&#123;model_name&#125;</span>-finetuned-<span class="subst">&#123;task&#125;</span>&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the <code>batch_size</code> defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. Since the best model might not be the one at the end of training, we ask the <code>Trainer</code> to load the best model it saved (according to <code>metric_name</code>) at the end of training.<br>ä¸Šé¢evaluation_strategy = â€œepochâ€å‚æ•°å‘Šè¯‰è®­ç»ƒä»£ç ï¼šæˆ‘ä»¬æ¯ä¸ªepcohä¼šåšä¸€æ¬¡éªŒè¯è¯„ä¼°ã€‚<br>ä¸Šé¢batch_sizeåœ¨è¿™ä¸ªnotebookä¹‹å‰å®šä¹‰å¥½äº†ã€‚</p>
<p>The last two arguments are to setup everything so we can push the model to the <code>Hub</code> at the end of training. Remove the two of them if you didnâ€™t follow the installation steps at the top of the notebook, otherwise you can change the value of <code>push_to_hub_model_id</code> to something you would prefer.<br><em>(åé¢éœ€è¦è¿æ¥åˆ°hubå®¢æˆ·ç«¯ï¼Œå¤ªéº»çƒ¦ï¼Œæ‰€ä»¥å…ˆè®¾ä¸ºFalse)</em></p>
<p>The last thing to define for our <code>Trainer</code> is how to compute the metrics from the predictions. We need to define a function for this, which will just use the <code>metric</code> we loaded earlier, the only preprocessing we have to do is to take the argmax of our predicted logits (our just squeeze the last axis in the case of STS-B):<br>æœ€åï¼Œç”±äºä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„è¯„æµ‹æŒ‡æ ‡ï¼Œæˆ‘ä»¬å®šä¸€ä¸ªå‡½æ•°æ¥æ ¹æ®ä»»åŠ¡åå­—å¾—åˆ°è¯„ä»·æ–¹æ³•:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">eval_pred</span>):</span></span><br><span class="line">    predictions, labels = eval_pred</span><br><span class="line">    <span class="keyword">if</span> task != <span class="string">&quot;stsb&quot;</span>:</span><br><span class="line">        predictions = np.argmax(predictions, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        predictions = predictions[:, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure>

<p>Then we just need to pass all of this along with our datasets to the Trainer:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">validation_key = <span class="string">&quot;validation_mismatched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation_matched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation&quot;</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>BUG:<br>ValueError: You must login to the Hugging Face hub on this computer by typing <code>transformers-cli login</code> and entering your credentials to use <code>use_auth_token=True</code>. Alternatively, you can pass your own token as the <code>use_auth_token</code> argument.<br>æŠŠargsé‡Œé¢çš„è¯¥é¡¹å‚æ•°æ”¹ä¸ºFalse   <code>push_to_hub=False,</code>ã€‚</p>
</blockquote>
<p>We can now finetune our model by just calling the <code>train</code> method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>
<p>è¾“å‡ºä¸ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>We can check with the <code>evaluate</code> method that our <code>Trainer</code> did reload the best model properly (if it was not the last one):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.evaluate()</span><br></pre></td></tr></table></figure>
<p>è¾“å‡ºä¸ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h1 id="è¶…å‚æœç´¢"><a href="#è¶…å‚æœç´¢" class="headerlink" title="è¶…å‚æœç´¢"></a>è¶…å‚æœç´¢</h1><p>The Trainer supports hyperparameter search using optuna or Ray Tune. </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install optuna</span><br><span class="line">pip install ray[tune]</span><br></pre></td></tr></table></figure>

<p>During hyperparameter search, the Trainer will run several trainings, so it needs to have the model defined via a function (so it can be reinitialized at each new run) instead of just having it passed. We jsut use the same function as before:<br>è¶…å‚æœç´¢æ—¶ï¼ŒTrainerå°†ä¼šè¿”å›å¤šä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ‰€ä»¥éœ€è¦ä¼ å…¥ä¸€ä¸ªå®šä¹‰å¥½çš„æ¨¡å‹ä»è€Œè®©Trainerå¯ä»¥ä¸æ–­é‡æ–°åˆå§‹åŒ–è¯¥ä¼ å…¥çš„æ¨¡å‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_init</span>():</span></span><br><span class="line">    <span class="keyword">return</span> AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br></pre></td></tr></table></figure>

<p>And we can instantiate our Trainer like before:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    model_init=model_init,</span><br><span class="line">    args=args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>The method we call this time is <code>hyperparameter_search</code>. Note that it can take a long time to run on the full dataset for some of the tasks. You can try to find some good hyperparameter on a portion of the training dataset by replacing the <code>train_dataset</code> line above by:<br><code>train_dataset = encoded_dataset[&quot;train&quot;].shard(index=1, num_shards=10) </code><br>for 1/10th of the dataset. Then you can run a full training on the best hyperparameters picked by the search.<br>è°ƒç”¨æ–¹æ³•hyperparameter_searchã€‚æ³¨æ„ï¼Œè¿™ä¸ªè¿‡ç¨‹å¯èƒ½å¾ˆä¹…ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆç”¨éƒ¨åˆ†æ•°æ®é›†è¿›è¡Œè¶…å‚æœç´¢ï¼Œå†è¿›è¡Œå…¨é‡è®­ç»ƒã€‚ æ¯”å¦‚ä½¿ç”¨1/10çš„æ•°æ®è¿›è¡Œæœç´¢ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_run = trainer.hyperparameter_search(n_trials=<span class="number">10</span>, direction=<span class="string">&quot;maximize&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>The hyperparameter_search method returns a <code>BestRun</code> objects, which contains the value of the objective maximized (by default the sum of all metrics) and the hyperparameters it used for that run.<br>hyperparameter_searchä¼šè¿”å›æ•ˆæœæœ€å¥½çš„æ¨¡å‹ç›¸å…³çš„å‚æ•°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>best_run</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>To reproduce the best training, just set the hyperparameters in your TrainingArgument before creating a Trainer:<br>å°†Trainnerè®¾ç½®ä¸ºæœç´¢åˆ°çš„æœ€å¥½å‚æ•°ï¼Œè¿›è¡Œè®­ç»ƒï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> n, v <span class="keyword">in</span> best_run.hyperparameters.items():</span><br><span class="line">    <span class="built_in">setattr</span>(trainer.args, n, v)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>


<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul>
<li>HuggingFace/transfomers/BERT <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/bert.html#">https://huggingface.co/transformers/model_doc/bert.html#</a></li>
<li>åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨â€“åœ¨çº¿é˜…è¯» <a target="_blank" rel="noopener" href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a></li>
</ul>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/pytorch-chap03/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    Chapter03 PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—
                
            </div>
        </a>
    
    
        <a href="/nlp-transformer-task06/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">Task06 BERTåº”ç”¨ã€è®­ç»ƒå’Œä¼˜åŒ–</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            Xiaoyu CHU &copy; 2021 
            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>