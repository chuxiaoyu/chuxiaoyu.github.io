<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset="utf-8">
    
    <title>CS224n Lec07 机器翻译、Seq2seq模型、注意力机制 | CHU XIAOYU</title>
    
    
        <meta name="keywords" content="CS公开课,NLP" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="参考资料:  CS224n官方网站http:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;cs224n&#x2F; bilibili https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1nP4y1j7rZ   本节主要内容 机器翻译任务 seq2seq模型架构 注意力机制  1 深度学习之前的机器翻译1.1 机器翻译任务定义机器翻译（Machine Translation, MT）任务">
<meta property="og:type" content="article">
<meta property="og:title" content="CS224n Lec07 机器翻译、Seq2seq模型、注意力机制">
<meta property="og:url" content="http://example.com/cs224n-lec07/index.html">
<meta property="og:site_name" content="CHU XIAOYU">
<meta property="og:description" content="参考资料:  CS224n官方网站http:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;cs224n&#x2F; bilibili https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1nP4y1j7rZ   本节主要内容 机器翻译任务 seq2seq模型架构 注意力机制  1 深度学习之前的机器翻译1.1 机器翻译任务定义机器翻译（Machine Translation, MT）任务">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/nlp.jpg?raw=true">
<meta property="article:published_time" content="2021-11-28T18:37:51.000Z">
<meta property="article:modified_time" content="2022-03-22T22:18:27.588Z">
<meta property="article:author" content="chuxiaoyu">
<meta property="article:tag" content="CS公开课">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/nlp.jpg?raw=true">
    

    
        <link rel="alternate" href="/atom.xml" title="CHU XIAOYU" type="application/atom+xml" />
    

    
        <link rel="icon" href="/images/logo.png" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">CHU XIAOYU</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">首页</a>
                
                    <a class="main-nav-link" href="/archives">归档</a>
                
                    <a class="main-nav-link" href="/categories">分类</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">关于</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id='categories'>
        <h3 class="widget-title">
            <span>categories</span>
            &nbsp;
            <a id='allExpand' href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            01 计算机基础
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            CS61A 计算机程序的构造与解释
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/cs61a-week1/">CS61A Week1 Comupter_Science, Functions</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            数据结构与算法
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/dsa-python/">数据结构与算法Python</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            02 人工智能
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            CS224n 自然语言处理
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file active"><a href="/cs224n-lec07/">CS224n Lec07 机器翻译、Seq2seq模型、注意力机制</a></li>  <li class="file"><a href="/cs224n-lec09/">CS224n Lec09 自注意力模型、Transformers</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            数据分析
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/">概率论与数理统计</a></li>  <li class="file"><a href="/SQL%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/">SQL学习资料</a></li>  <li class="file"><a href="/SQL%E9%87%8D%E7%82%B9/">SQL表连接&聚合函数&窗口函数</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            李宏毅机器学习
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/leeml-lec01-introduction/">Lecture01 机器学习和深度学习简介</a></li>  <li class="file"><a href="/leeml-rnn/">循环神经网络</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            03 工具箱
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%AD%E8%8B%B1%E6%96%87LaTeX%E7%AE%80%E5%8E%86%E6%A8%A1%E6%9D%BF/">一些好用的中英文LaTeX简历模板</a></li>  <li class="file"><a href="/git/">5h打通Git全套教程</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            04 组队学习
                        </a>
                         <ul class="unstyled" id="tree" > 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            2021-09 基于transformer的NLP
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/nlp-transformer-task01/">Task01 NLP学习概览</a></li>  <li class="file"><a href="/nlp-transformer-task02/">Task02 学习Attentioin和Transformer</a></li>  <li class="file"><a href="/nlp-transformer-task03/">Task03 学习BERT</a></li>  <li class="file"><a href="/nlp-transformer-task04/">Task04 学习GPT</a></li>  <li class="file"><a href="/nlp-transformer-task05/">Task05 编写BERT模型</a></li>  <li class="file"><a href="/nlp-transformer-task06/">Task06 BERT应用、训练和优化</a></li>  <li class="file"><a href="/nlp-transformer-task07/">Task07 使用Transformers解决文本分类任务</a></li>  <li class="file"><a href="/nlp-transformer-summary/">Summary Transformer课程总结</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            2021-10 深入浅出PyTorch
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/pytorch-chap01-02/">Chapter01-02 PyTorch的简介和安装、PyTorch基础知识</a></li>  <li class="file"><a href="/pytorch-chap03/">Chapter03 PyTorch的主要组成模块</a></li>  <li class="file"><a href="/pytorch-chap04/">Chapter04 PyTorch基础实战——FashionMNIST图像分类</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            2022-01 LeetCode刷题
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/leetcode/">Leetcode刷题（第1-2期）</a></li>  </ul> 
                    </li> 
                     </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            沉思录
                        </a>
                         <ul class="unstyled" id="tree" >  <li class="file"><a href="/%E5%A4%A7%E7%90%86/">大理，在民宿打工的日子</a></li>  <li class="file"><a href="/formula/">公式之美，EVERYTHING IS EPHEMERAL BUT FORMULA IS ETERNAL</a></li>  <li class="file"><a href="/feynman-quotes/">费曼语录（翻译自Twitter）</a></li>  </ul> 
                    </li> 
                     <li class="file"><a href="/hello-world/">Hello-World|本站导航</a></li>  </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>recent</span></h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/cs224n-lec09/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/nlp.jpg?raw=true)" alt="CS224n Lec09 自注意力模型、Transformers" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">02 人工智能</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/CS224n-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">CS224n 自然语言处理</a></p>
                            <p class="item-title"><a href="/cs224n-lec09/" class="title">CS224n Lec09 自注意力模型、Transformers</a></p>
                            <p class="item-date"><time datetime="2022-03-22T22:19:47.000Z" itemprop="datePublished">2022-03-22</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/dsa-python/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/leetcode.png?raw=true)" alt="数据结构与算法Python" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/">01 计算机基础</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">数据结构与算法</a></p>
                            <p class="item-title"><a href="/dsa-python/" class="title">数据结构与算法Python</a></p>
                            <p class="item-date"><time datetime="2022-02-07T00:31:45.000Z" itemprop="datePublished">2022-02-07</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/leetcode/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/leetcode.png?raw=true)" alt="Leetcode刷题（第1-2期）" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/">04 组队学习</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/2022-01-LeetCode%E5%88%B7%E9%A2%98/">2022-01 LeetCode刷题</a></p>
                            <p class="item-title"><a href="/leetcode/" class="title">Leetcode刷题（第1-2期）</a></p>
                            <p class="item-date"><time datetime="2022-01-24T15:26:18.000Z" itemprop="datePublished">2022-01-24</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/hello-world/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/formula/08-shang.jpg?raw=true)" alt="Hello-World|本站导航" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/hello-world/" class="title">Hello-World|本站导航</a></p>
                            <p class="item-date"><time datetime="2022-01-19T18:39:32.000Z" itemprop="datePublished">2022-01-19</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/feynman-quotes/" class="thumbnail">
    
    
        <span style="background-image:url(https://github.com/chuxiaoyu/blog_image/blob/master/cs224n/feynman.jpg?raw=true)" alt="费曼语录（翻译自Twitter）" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%B2%89%E6%80%9D%E5%BD%95/">沉思录</a></p>
                            <p class="item-title"><a href="/feynman-quotes/" class="title">费曼语录（翻译自Twitter）</a></p>
                            <p class="item-date"><time datetime="2021-12-02T05:38:38.000Z" itemprop="datePublished">2021-12-02</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>archives</span></h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a><span class="archive-list-count">6</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><span>tag cloud</span></h3>
        <div class="widget tagcloud">
            <a href="/tags/BERT/" style="font-size: 14.29px;">BERT</a> <a href="/tags/CS%E5%85%AC%E5%BC%80%E8%AF%BE/" style="font-size: 12.86px;">CS公开课</a> <a href="/tags/GPT/" style="font-size: 10px;">GPT</a> <a href="/tags/NLP/" style="font-size: 18.57px;">NLP</a> <a href="/tags/PyTorch/" style="font-size: 12.86px;">PyTorch</a> <a href="/tags/SQL/" style="font-size: 11.43px;">SQL</a> <a href="/tags/attention/" style="font-size: 10px;">attention</a> <a href="/tags/data-structure/" style="font-size: 10px;">data structure</a> <a href="/tags/feynman/" style="font-size: 10px;">feynman</a> <a href="/tags/function/" style="font-size: 10px;">function</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/laTeX/" style="font-size: 10px;">laTeX</a> <a href="/tags/leetcode/" style="font-size: 10px;">leetcode</a> <a href="/tags/machine-learning/" style="font-size: 11.43px;">machine learning</a> <a href="/tags/math/" style="font-size: 10px;">math</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/quote/" style="font-size: 10px;">quote</a> <a href="/tags/regression/" style="font-size: 10px;">regression</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/team-learning/" style="font-size: 10px;">team learning</a> <a href="/tags/transfomer/" style="font-size: 15.71px;">transfomer</a> <a href="/tags/%E5%A4%A7%E7%90%86/" style="font-size: 10px;">大理</a> <a href="/tags/%E6%80%BB%E7%BB%93/" style="font-size: 10px;">总结</a> <a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" style="font-size: 10px;">文本分类</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 20px;">笔记</a> <a href="/tags/%E7%AE%80%E5%8E%86/" style="font-size: 10px;">简历</a> <a href="/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">组队学习</a> <a href="/tags/%E7%BB%9F%E8%AE%A1/" style="font-size: 10px;">统计</a> <a href="/tags/%E9%98%85%E8%AF%BB/" style="font-size: 10px;">阅读</a> <a href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" style="font-size: 17.14px;">预训练模型</a>
        </div>
    </div>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-cs224n-lec07" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">02 人工智能</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/CS224n-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">CS224n 自然语言处理</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/CS%E5%85%AC%E5%BC%80%E8%AF%BE/" rel="tag">CS公开课</a>, <a class="tag-link-link" href="/tags/NLP/" rel="tag">NLP</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/cs224n-lec07/">
            <time datetime="2021-11-28T18:37:51.000Z" itemprop="datePublished">2021-11-28</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            CS224n Lec07 机器翻译、Seq2seq模型、注意力机制
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">Catalogue</strong>
                    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E8%8A%82%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="toc-number">1.</span> <span class="toc-text">本节主要内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%89%8D%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"><span class="toc-number">2.</span> <span class="toc-text">1 深度学习之前的机器翻译</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%BB%BB%E5%8A%A1%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.</span> <span class="toc-text">1.1 机器翻译任务定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E7%9A%84%E5%8F%91%E5%B1%95%E9%98%B6%E6%AE%B5"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 机器翻译的发展阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"><span class="toc-number">2.3.</span> <span class="toc-text">1.3 基于统计的机器翻译</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"><span class="toc-number">3.</span> <span class="toc-text">2 基于神经网络的机器翻译</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">4.</span> <span class="toc-text">3 注意力机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-seq2seq%E6%9E%B6%E6%9E%84%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">4.1.</span> <span class="toc-text">3.1 seq2seq架构存在的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%9C%89%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84seq2seq%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">3.2 有注意力机制的seq2seq模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E5%85%AC%E5%BC%8F%E8%A1%A8%E7%A4%BA"><span class="toc-number">4.3.</span> <span class="toc-text">3.3 注意力机制的公式表示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-number">4.4.</span> <span class="toc-text">3.3 注意力机制的优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%98%AF%E4%B8%80%E7%A7%8D%E5%B9%BF%E6%B3%9B%E6%80%A7%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E5%B7%A7"><span class="toc-number">4.5.</span> <span class="toc-text">3.4 注意力机制是一种广泛性的深度学习技巧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%B0%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-number">4.6.</span> <span class="toc-text">3.5 注意力分数的计算</span></a></li></ol></li></ol>
                </div>
            
        
        
            <blockquote>
<p>参考资料:</p>
<ul>
<li>CS224n官方网站<a target="_blank" rel="noopener" href="http://web.stanford.edu/class/cs224n/">http://web.stanford.edu/class/cs224n/</a></li>
<li>bilibili <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1nP4y1j7rZ">https://www.bilibili.com/video/BV1nP4y1j7rZ</a></li>
</ul>
</blockquote>
<h2 id="本节主要内容"><a href="#本节主要内容" class="headerlink" title="本节主要内容"></a>本节主要内容</h2><ul>
<li>机器翻译任务</li>
<li>seq2seq模型架构</li>
<li>注意力机制</li>
</ul>
<h2 id="1-深度学习之前的机器翻译"><a href="#1-深度学习之前的机器翻译" class="headerlink" title="1 深度学习之前的机器翻译"></a>1 深度学习之前的机器翻译</h2><h3 id="1-1-机器翻译任务定义"><a href="#1-1-机器翻译任务定义" class="headerlink" title="1.1 机器翻译任务定义"></a>1.1 机器翻译任务定义</h3><p>机器翻译（Machine Translation, MT）任务：将句子$x$从一种语言（Source Language）翻译成另一种语言（Target Language）的句子$y$。</p>
<h3 id="1-2-机器翻译的发展阶段"><a href="#1-2-机器翻译的发展阶段" class="headerlink" title="1.2 机器翻译的发展阶段"></a>1.2 机器翻译的发展阶段</h3><ul>
<li>1950s: 早期机器翻译</li>
<li>1990s-2010s: 基于统计的机器翻译（Statistics Machine Translation, SMT）</li>
<li>2014-: 基于神经网络的机器翻译（Neural Machine Translation, NMT）</li>
<li>2017-: 以Transformer为代表的预训练模型时代</li>
</ul>
<h3 id="1-3-基于统计的机器翻译"><a href="#1-3-基于统计的机器翻译" class="headerlink" title="1.3 基于统计的机器翻译"></a>1.3 基于统计的机器翻译</h3><p>基于统计的机器翻译（Statistics Machine Translation, SMT）的核心思想是从数据中学习一个概率模型。</p>
<p>例如，给定一个法语语句$x$，找出对应的最合适的英文翻译语句$y$，公式如下：<br>$$<br>argmax_yP(y|x)<br>$$<br>利用贝叶斯公式，可以将上述概率转化为两部分，分别进行学习：<br>$$<br>argmax_yP(x|y)P(y)<br>$$<br>上式中，$P(x|y)$代表翻译模型（Translation Model），负责学习如何准确翻译单词、短语（fidelity，保真性）；$P(y)$代表语言模型（Language Model），是对语言的流畅性（fluency）进行学习。<em>（注：对应翻译的两个标准：忠实、通顺）</em></p>
<p>那么，如何学习翻译模型$P(x|y)$？</p>
<p>首先，需要大量的平行数据（Parallel Data），如大量人工翻译的法语/英语语句对。</p>
<p>然后，引入隐变量$a$：$P(x, a|y)$，$a$是$alignment$，即语句$x$和语句$y$之间的单词级别的对应关系。这种对应非常负责，考虑以下情形：</p>
<ul>
<li>有些单词没有或不需要对应的翻译词（no counterpart）</li>
<li>多个单词对应一个翻译词（many-to-one）</li>
<li>一个单词对应多个翻译词（one-to-many）</li>
<li>多个单词对应多个翻译词（many-to-many）</li>
</ul>
<p>对应关系$alignment$没有显性地存在于数据中，因此需要特殊的学习算法（如EM算法）。</p>
<p>基于统计的机器翻译缺点如下：</p>
<ul>
<li>整个翻译系统及其复杂，包含大量未提及的细节和单独设计的子模块</li>
<li>需要大量的特征工程（需要针对不同的特殊用法设计各种特征）</li>
<li>需要大量的人力和成本来维护语料资源</li>
</ul>
<h2 id="2-基于神经网络的机器翻译"><a href="#2-基于神经网络的机器翻译" class="headerlink" title="2 基于神经网络的机器翻译"></a>2 基于神经网络的机器翻译</h2><p>基于神经网络的机器翻译（Neural Machine Translation, NMT）是一种用端对端神经网络进行机器翻译的方式。这种神经网络架构称为sequence-to-sequence（seq2seq）模型，包含两个循环神经网络（RNNs）。</p>
<p>seq2seq不只在机器翻译中使用，还被广泛应用于以下任务：</p>
<ul>
<li>文本摘要</li>
<li>对话系统</li>
<li>句法解析</li>
<li>代码生成</li>
</ul>
<p>seq2seq可以视为条件语言模型（Conditional Language Model）的一种：</p>
<ul>
<li>语言模型是因为它的解码器用于预测目标语句$y$的下一个单词</li>
<li>条件是因为它的预测是基于源语句$x$的（条件概率）</li>
</ul>
<p>NMT直接计算$P(y|x)$：<br>$$<br>P(y|x) = P(y_1|x)P(y_2|y_1,x)P(y_3|y_1,y_2,x)…P(y_T|y_1,…,y_{T-1}, x)<br>$$<br>其中，$P(y_T|y_1,…,y_{T-1}, x)$表示给定已有的目标单词和源语句$x$，下一个目标单词的概率。</p>
<p>训练NMT需要大量平行语料，并且可以使用多层RNN。</p>
<p>RNN有两种解码方式：</p>
<ul>
<li>Greedy decoding</li>
<li>Beam search decoding</li>
</ul>
<p>相较于SMT，NMT有如下优点：</p>
<ul>
<li>性能更好</li>
<li>没有子模块</li>
<li>降低了人力需求（不需要特征工程和考虑特例）</li>
</ul>
<p>同时也有如下缺点：</p>
<ul>
<li>不可解释性</li>
<li>很难受控制</li>
</ul>
<p>从BLEU（Bilingual Evaluation Understudy）评测结果可以看出，NMT的性能已经远远超过SMT。</p>
<p>NMT可能是深度学习在NLP中最成功的应用：</p>
<ul>
<li><p>2014年，seq2seq论文发表；</p>
</li>
<li><p>2016年，NMT成为机器翻译的标准方法，谷歌翻译从SMT转为NMT；</p>
</li>
<li><p>2018年，所有公司的翻译工具均应用了NMT。</p>
</li>
</ul>
<p>然而，机器学习任务并未被彻底终结，许多困难仍然存在，如常识信息未得到应用、背景信息在长文本中难以维护以及模型偏见等。</p>
<h2 id="3-注意力机制"><a href="#3-注意力机制" class="headerlink" title="3 注意力机制"></a>3 注意力机制</h2><h3 id="3-1-seq2seq架构存在的问题"><a href="#3-1-seq2seq架构存在的问题" class="headerlink" title="3.1 seq2seq架构存在的问题"></a>3.1 seq2seq架构存在的问题</h3><ol>
<li>语义向量可能无法完全捕捉到整个输入序列的信息；</li>
<li>先输入到网络的内容携带的信息会被后输入的信息覆盖掉。输入序列越长，这个现象就越严重。</li>
</ol>
<p>因此，Attention（注意力机制）提供了一种解决方法。</p>
<h3 id="3-2-有注意力机制的seq2seq模型"><a href="#3-2-有注意力机制的seq2seq模型" class="headerlink" title="3.2 有注意力机制的seq2seq模型"></a>3.2 有注意力机制的seq2seq模型</h3><p>注意力机制的核心思路是：在解码器进行解码的每一步，直接连接到编码器来关注输入序列中的特定部分。</p>
<p><img src="/image/image-20220111171442329.jpg" alt="image-20220111171442329"></p>
<h3 id="3-3-注意力机制的公式表示"><a href="#3-3-注意力机制的公式表示" class="headerlink" title="3.3 注意力机制的公式表示"></a>3.3 注意力机制的公式表示</h3><p>假设编码器隐藏状态为$h_1,…,h_N∈R^h$，在时间步$t$时解码器的隐藏状态为$s_t∈R^h$，则该时间步的注意力分数$e_t$可以表示为：</p>
<p>$$<br>e_t = [s^T_th_1,…,s^T_th_N]∈R^N<br>$$</p>
<p>然后使用softmax得到注意力概率分布$α^t$：</p>
<p>$$<br>α^t = softmax(e^t)∈R^N<br>$$</p>
<p>利用$α^t$计算编码器隐藏状态的权重和，得到注意力输出$a_t$：</p>
<p>$$<br>a_t = \sum_{i=1}^n{α^t_ih_i}∈R^h<br>$$</p>
<p>最后，将注意力输出$a_t$与解码器隐藏状态$s_t$拼接，后续的处理与没有注意力的seq2seq模型一样。</p>
<p>$$<br>[a_t; s_t]∈R^h<br>$$</p>
<h3 id="3-3-注意力机制的优点"><a href="#3-3-注意力机制的优点" class="headerlink" title="3.3 注意力机制的优点"></a>3.3 注意力机制的优点</h3><ul>
<li>显著提升了NMT性能</li>
<li>解决了3.1中提到的seq2seq架构中的问题</li>
<li>对解决梯度消失问题有一定帮助[?]</li>
<li>提供了一定的可解释性</li>
</ul>
<h3 id="3-4-注意力机制是一种广泛性的深度学习技巧"><a href="#3-4-注意力机制是一种广泛性的深度学习技巧" class="headerlink" title="3.4 注意力机制是一种广泛性的深度学习技巧"></a>3.4 注意力机制是一种广泛性的深度学习技巧</h3><p>注意力可以用于多种架构（不限于seq2seq）和多种任务（不限于机器翻译）中。</p>
<p><strong>因此，一种更广义的注意力定义是：给定一组向量$values$（值），和一个向量$query$（查询），注意力是一种基于$query$计算$values$的带权重的和的技巧。</strong></p>
<h3 id="3-5-注意力分数的计算"><a href="#3-5-注意力分数的计算" class="headerlink" title="3.5 注意力分数的计算"></a>3.5 注意力分数的计算</h3><p>假设$h_1,…,h_N∈R^{d1}$，$s∈R^{d2}$，那么注意力分数$e_t∈R^N$有多种计算方式：</p>
<ol>
<li><p>点积注意力（Basic dot-product attention）<br>$$<br>e_i = s^Th_i∈R<br>$$</p>
</li>
<li><p>乘法注意力（Multiplicative attention）<br>$$<br>e_i = s^TWh_i∈R<br>$$<br>其中，$W$是权重矩阵。</p>
</li>
</ol>
<ol start="3">
<li>加性注意力（Additive attention）<br>$$<br>e_i = v^Ttanh(W_1h_i + W_2s)∈R<br>$$<br>其中，$W_1, W_2$是权重矩阵，$v$是权重向量。</li>
</ol>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/feynman-quotes/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    费曼语录（翻译自Twitter）
                
            </div>
        </a>
    
    
        <a href="/leeml-rnn/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">循环神经网络</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            chuxiaoyu &copy; 2022 
            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>