<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Memex</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-11-28T11:35:44.982Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Xiaoyu CHU</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>chap01 è®¡ç®—æœºç³»ç»Ÿæ¼«æ¸¸</title>
    <link href="http://example.com/csapp-chap01/"/>
    <id>http://example.com/csapp-chap01/</id>
    <published>2021-10-26T02:26:30.000Z</published>
    <updated>2021-11-28T11:35:44.982Z</updated>
    
    <content type="html"><![CDATA[<p>ã€Šæ·±å…¥ç†è§£è®¡ç®—æœºç³»ç»Ÿã€‹å…¨ä¹¦æ¦‚è§ˆï¼š</p><ul><li>Chap01. A Tour of Computer System/è®¡ç®—æœºç³»ç»Ÿæ¼«æ¸¸</li><li>Part I. Program Structure and Execution/ç¨‹åºç»“æ„å’Œæ‰§è¡Œ</li><li>Part II. Running Programs on a System/åœ¨ç³»ç»Ÿä¸Šè¿è¡Œç¨‹åº</li><li>Part III. Interaction and Communication between Programs/è¿›ç¨‹é—´çš„äº¤äº’å’Œé€šä¿¡</li></ul><h1 id="hello-worldçš„ç”Ÿå‘½å‘¨æœŸ"><a href="#hello-worldçš„ç”Ÿå‘½å‘¨æœŸ" class="headerlink" title="hello, worldçš„ç”Ÿå‘½å‘¨æœŸ"></a>hello, worldçš„ç”Ÿå‘½å‘¨æœŸ</h1><p>ä¸€ä¸ªç¨‹åºçš„ç”Ÿå‘½å‘¨æœŸï¼š</p><ol><li>åˆ›å»º/Create</li><li>ç¼–è¯‘/Compile<ul><li>é¢„å¤„ç†ï¼ˆhello.c â†’ hello.iï¼‰</li><li>ç¼–è¯‘ï¼ˆhello.i â†’ hello.sï¼‰</li><li>æ±‡ç¼–ï¼ˆhello.s â†’ hello.oï¼‰</li><li>é“¾æ¥ï¼ˆhello.o + printf.o â†’ helloï¼‰</li></ul></li><li>è¿è¡Œ/Run</li><li>é€€å‡º/Exit</li></ol><h2 id="åˆ›å»º"><a href="#åˆ›å»º" class="headerlink" title="åˆ›å»º"></a>åˆ›å»º</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/02.jpg?raw=true" width="600" alt="" align="center" /><p>helloç¨‹åºä¿å­˜å¾—åˆ°ä¸€ä¸ªåç¼€åä¸º<code>.c</code>çš„æ–‡ä»¶<code>hello.c</code></p><h2 id="ç¼–è¯‘ğŸ¯"><a href="#ç¼–è¯‘ğŸ¯" class="headerlink" title="ç¼–è¯‘ğŸ¯"></a>ç¼–è¯‘ğŸ¯</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/04.jpg?raw=true" width="600" alt="" align="center" /><p>æ¥ä¸‹æ¥ï¼Œé€šè¿‡<code>gcc -o hello hello.c</code>å‘½ä»¤å®Œæˆå¯¹æºä»£ç çš„ç¼–è¯‘ï¼Œç”Ÿæˆå¯æ‰§è¡Œç¨‹åº<code>hello</code><br>ã€‚è¿™ä¸ªè¿‡ç¨‹ä¸­ç¼–è¯‘ç³»ç»Ÿçš„å¤„ç†å¤§è‡´å¯ä»¥åˆ†ä¸ºå››ä¸ªé˜¶æ®µï¼Œåˆ†åˆ«ä¸ºï¼šé¢„å¤„ç†ã€ç¼–è¯‘ã€æ±‡ç¼–ä»¥åŠé“¾æ¥ã€‚</p><h3 id="é¢„å¤„ç†"><a href="#é¢„å¤„ç†" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h3><p>é¢„å¤„ç†å™¨ä¼šæ ¹æ®ä»¥<code>#</code>å¼€å¤´çš„ä»£ç ï¼Œæ¥ä¿®æ”¹åŸå§‹ç¨‹åºã€‚ä¾‹å¦‚helloç¨‹åºä¸­å¼•å…¥äº†å¤´æ–‡ä»¶ <code>stdio.h</code> ï¼Œé¢„å¤„ç†å™¨ä¼šè¯»å–è¯¥å¤´æ–‡ä»¶ä¸­çš„å†…å®¹ï¼Œå°†å…¶ä¸­çš„å†…å®¹ç›´æ¥æ’å…¥åˆ°æºç¨‹åºä¸­ï¼Œç»“æœå°±å¾—åˆ°äº†å¦å¤–ä¸€ä¸ª C ç¨‹åºï¼Œè¿™ä¸ªç»è¿‡é¢„å¤„ç†å™¨å¤„ç†åå¾—åˆ°çš„æ–‡ä»¶é€šå¸¸ä»¥ <code>.i </code>ç»“å°¾. <code>hello.c</code> ç»è¿‡é¢„å¤„ç†å™¨åå¾—åˆ° <code>hello.i</code>ï¼Œè¿™ä¸ª <code>hello.i</code> ä»æ—§æ˜¯ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ã€‚</p><h3 id="ç¼–è¯‘"><a href="#ç¼–è¯‘" class="headerlink" title="ç¼–è¯‘"></a>ç¼–è¯‘</h3><p>ç¼–è¯‘å™¨å°† <code>hello.i</code> æ–‡ä»¶ç¿»è¯‘æˆ <code>hello.s</code> æ–‡ä»¶ã€‚è¿™ä¸€é˜¶æ®µåŒ…æ‹¬è¯æ³•åˆ†æã€è¯­æ³•åˆ†æã€è¯­ä¹‰åˆ†æã€ä¸­é—´ä»£ç ç”Ÿæˆä»¥åŠä¼˜åŒ–ç­‰ç­‰ä¸€ç³»åˆ—çš„ä¸­é—´æ“ä½œã€‚æ„Ÿå…´è¶£çš„å¯ä»¥äº†è§£ä¸€ä¸‹ã€Šç¼–è¯‘åŸç†ã€‹ã€‚</p><h3 id="æ±‡ç¼–"><a href="#æ±‡ç¼–" class="headerlink" title="æ±‡ç¼–"></a>æ±‡ç¼–</h3><p>æ±‡ç¼–å™¨æ ¹æ®æŒ‡ä»¤é›†å°†æ±‡ç¼–ç¨‹åº <code>hello.s</code> ç¿»è¯‘æˆæœºå™¨æŒ‡ä»¤ï¼Œå¹¶ä¸”æŠŠè¿™ä¸€ç³»åˆ—çš„æœºå™¨æŒ‡ä»¤æŒ‰ç…§å›ºå®šçš„è§„åˆ™è¿›è¡Œæ‰“åŒ…ï¼Œå¾—åˆ°å¯é‡å®šä½ç›®æ ‡æ–‡ä»¶ <code>hello.o</code> ã€‚æ­¤æ—¶ <code>hello.o</code> è™½ç„¶æ˜¯ä¸€ä¸ªäºŒè¿›åˆ¶çš„æ–‡ä»¶ï¼Œä½†æ˜¯è¿˜ä¸èƒ½æ‰§è¡Œã€‚</p><h3 id="é“¾æ¥"><a href="#é“¾æ¥" class="headerlink" title="é“¾æ¥"></a>é“¾æ¥</h3><p>åœ¨ <code>hello.c</code> è¿™ä¸ªç¨‹åºä¸­ï¼Œæˆ‘ä»¬è°ƒç”¨äº†<code>printf </code>å‡½æ•°ï¼Œ<code>printf</code> å‡½æ•°åœ¨æ˜¯åœ¨åä¸º <code>printf.o</code> çš„æ–‡ä»¶ä¸­ï¼Œè¿™ä¸ªæ–‡ä»¶æ˜¯ä¸€ä¸ªæå‰ç¼–è¯‘å¥½çš„ç›®æ ‡æ–‡ä»¶ï¼Œé“¾æ¥å™¨(ldï¼‰è´Ÿè´£æŠŠ <code>hello.o</code> å’Œ <code>printf.o</code> è¿›è¡Œåˆå¹¶ã€‚å› ä¸ºé“¾æ¥å™¨è¦éµå¾ªä¸€å®šè§„åˆ™å¯¹ hello.o å’Œ printf.o çš„è¿›è¡Œè°ƒæ•´ï¼Œæ‰€ä»¥ <code>hello.o</code> æ‰ä¼šè¢«ç§°ä¹‹ä¸ºå¯é‡å®šä½ç›®æ ‡æ–‡ä»¶ã€‚æœ€ç»ˆï¼Œ<code>hello.o</code>ç»è¿‡é“¾æ¥é˜¶æ®µå¯ä»¥å¾—åˆ°å¯æ‰§è¡Œç›®æ ‡æ–‡ä»¶ <code>hello</code>ã€‚æ­¤æ—¶ï¼Œå¾—åˆ°çš„ <code>hello</code> å°±å¯ä»¥è¢«åŠ è½½åˆ°å†…å­˜ä¸­æ‰§è¡Œäº†ã€‚</p><h2 id="è¿è¡Œ"><a href="#è¿è¡Œ" class="headerlink" title="è¿è¡Œ"></a>è¿è¡Œ</h2><p>é€šè¿‡shellè¿è¡Œç¨‹åºï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/05.jpg?raw=true" width="600" alt="" align="center" /><p>ç¨‹åºè¿è¡Œçš„è¿‡ç¨‹ä¸­ç³»ç»Ÿå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿâ†“â†“â†“é¦–å…ˆï¼Œè¦äº†è§£ä¸€ä¸‹ç³»ç»Ÿçš„ç¡¬ä»¶ç»„æˆã€‚</p><h1 id="ç³»ç»Ÿçš„ç¡¬ä»¶ç»„æˆ"><a href="#ç³»ç»Ÿçš„ç¡¬ä»¶ç»„æˆ" class="headerlink" title="ç³»ç»Ÿçš„ç¡¬ä»¶ç»„æˆ"></a>ç³»ç»Ÿçš„ç¡¬ä»¶ç»„æˆ</h1><p>æ€»è§ˆï¼š<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/06_yingjian.jpg?raw=true" width="600" alt="" align="center" /></p><h2 id="ä¸­å¤®å¤„ç†å™¨ï¼ˆCentral-Processing-Unit-CPUï¼‰"><a href="#ä¸­å¤®å¤„ç†å™¨ï¼ˆCentral-Processing-Unit-CPUï¼‰" class="headerlink" title="ä¸­å¤®å¤„ç†å™¨ï¼ˆCentral Processing Unit, CPUï¼‰"></a>ä¸­å¤®å¤„ç†å™¨ï¼ˆCentral Processing Unit, CPUï¼‰</h2><p>ä¸­å¤®å¤„ç†å•å…ƒ/ä¸­å¤®å¤„ç†å™¨ã€‚</p><h3 id="ç¨‹åºè®¡æ•°å™¨ï¼ˆProgram-Count-PCï¼‰"><a href="#ç¨‹åºè®¡æ•°å™¨ï¼ˆProgram-Count-PCï¼‰" class="headerlink" title="ç¨‹åºè®¡æ•°å™¨ï¼ˆProgram Count, PCï¼‰"></a>ç¨‹åºè®¡æ•°å™¨ï¼ˆProgram Count, PCï¼‰</h3><p>ç¨‹åºè®¡æ•°å™¨ã€‚<br>PCå°±æ˜¯ä¸€ä¸ª4å­—èŠ‚ï¼ˆ32ä½æœºå™¨ï¼‰æˆ–æ˜¯8å­—èŠ‚ï¼ˆ64ä½æœºå™¨ï¼‰çš„å­˜å‚¨ç©ºé—´ï¼Œé‡Œé¢å­˜æ”¾çš„æ˜¯æŸä¸€æ¡æŒ‡ä»¤çš„åœ°å€ã€‚ä»ç³»ç»Ÿä¸Šç”µçš„é‚£ä¸€ç¬é—´ï¼Œç›´åˆ°ç³»ç»Ÿæ–­ç”µï¼ŒCPUå°±ä¸æ–­åœ°åœ¨æ‰§è¡ŒPCæŒ‡å‘çš„æŒ‡ä»¤ï¼Œç„¶åæ›´æ–°PCï¼Œä½¿å…¶æŒ‡å‘ä¸‹ä¸€æ¡è¦æ‰§è¡Œçš„æŒ‡ä»¤ã€‚</p><h3 id="å¯„å­˜å™¨æ–‡ä»¶ï¼ˆRegister-Fileï¼‰"><a href="#å¯„å­˜å™¨æ–‡ä»¶ï¼ˆRegister-Fileï¼‰" class="headerlink" title="å¯„å­˜å™¨æ–‡ä»¶ï¼ˆRegister Fileï¼‰"></a>å¯„å­˜å™¨æ–‡ä»¶ï¼ˆRegister Fileï¼‰</h3><p>å¯„å­˜å™¨æ–‡ä»¶ã€‚<br>å®ƒæ˜¯ CPU å†…éƒ¨çš„ä¸€ä¸ªå­˜å‚¨è®¾å¤‡ã€‚é€šä¿—çš„è®²ï¼Œå¯„å­˜å™¨å¯ä»¥ç†è§£ä¸ºä¸€ä¸ªä¸´æ—¶å­˜æ”¾æ•°æ®çš„ç©ºé—´ã€‚<br>ä¾‹å¦‚ï¼Œè®¡ç®—ä¸¤ä¸ªå˜é‡ a+b çš„å’Œï¼Œå¤„ç†å™¨ä»å†…å­˜ä¸­è¯»å– a çš„å€¼æš‚å­˜åœ¨å¯„å­˜å™¨ X ä¸­ï¼Œè¯»å– B çš„å€¼æš‚å­˜åœ¨å¯„å­˜å™¨ Y ä¸­ï¼Œè¿™ä¸ªæ“ä½œä¼šè¦†ç›–å¯„å­˜å™¨ä¸­åŸæ¥çš„æ•°å€¼ã€‚</p><h3 id="ç®—æœ¯é€»è¾‘å•å…ƒï¼ˆArithmatic-logic-Unitï¼ŒALUï¼‰"><a href="#ç®—æœ¯é€»è¾‘å•å…ƒï¼ˆArithmatic-logic-Unitï¼ŒALUï¼‰" class="headerlink" title="ç®—æœ¯é€»è¾‘å•å…ƒï¼ˆArithmatic/logic Unitï¼ŒALUï¼‰"></a>ç®—æœ¯é€»è¾‘å•å…ƒï¼ˆArithmatic/logic Unitï¼ŒALUï¼‰</h3><p>ç®—æœ¯é€»è¾‘å•å…ƒã€‚<br>å¤„ç†å™¨å®ŒæˆåŠ è½½çš„æ“ä½œåï¼ŒALUï¼ˆArithmatic/logic Unitï¼‰ä¼šä»å¤åˆ¶å¯„å­˜å™¨ X å’Œ Y ä¸­ä¿å­˜çš„æ•°å€¼ï¼Œç„¶åè¿›è¡Œç®—æœ¯è¿ç®—ï¼Œå¾—åˆ°çš„ç»“æœä¼šä¿å­˜åˆ°å¯„å­˜å™¨ X æˆ–è€…å¯„å­˜å™¨ Y ä¸­ï¼Œæ­¤æ—¶å¯„å­˜å™¨ä¸­åŸæ¥çš„æ•°å€¼ä¼šè¢«æ–°çš„æ•°å€¼è¦†ç›–ã€‚</p><h2 id="å†…å­˜ï¼ˆMain-Memoryï¼‰"><a href="#å†…å­˜ï¼ˆMain-Memoryï¼‰" class="headerlink" title="å†…å­˜ï¼ˆMain Memoryï¼‰"></a>å†…å­˜ï¼ˆMain Memoryï¼‰</h2><p>å†…å­˜ï¼Œä¹Ÿç§°ä¸ºä¸»å­˜ã€‚å¤„ç†å™¨åœ¨æ‰§è¡Œç¨‹åºæ—¶ï¼Œå†…å­˜ä¸»è¦å­˜æ”¾ç¨‹åºæŒ‡ä»¤ä»¥åŠæ•°æ®ã€‚<br>ä»ç‰©ç†ä¸Šè®²ï¼Œå†…å­˜æ˜¯ç”±éšæœºåŠ¨æ€å­˜å‚¨å™¨èŠ¯ç‰‡ç»„æˆï¼›ä»é€»è¾‘ä¸Šè®²ï¼Œå†…å­˜å¯ä»¥çœ‹æˆä¸€ä¸ªä»é›¶å¼€å§‹çš„å¤§æ•°ç»„ï¼Œæ¯ä¸ªå­—èŠ‚éƒ½æœ‰ç›¸åº”åœ°å€ã€‚</p><h2 id="æ€»çº¿ï¼ˆBusï¼‰"><a href="#æ€»çº¿ï¼ˆBusï¼‰" class="headerlink" title="æ€»çº¿ï¼ˆBusï¼‰"></a>æ€»çº¿ï¼ˆBusï¼‰</h2><p>å†…å­˜å’Œå¤„ç†å™¨ï¼ˆCPUï¼‰ä¹‹é—´é€šè¿‡æ€»çº¿ï¼ˆBusï¼‰æ¥è¿›è¡Œæ•°æ®ä¼ é€’ã€‚å®é™…ä¸Šï¼Œæ€»çº¿è´¯ç©¿äº†æ•´ä¸ªè®¡ç®—æœºç³»ç»Ÿï¼Œå®ƒè´Ÿè´£å°†ä¿¡æ¯ä»ä¸€ä¸ªéƒ¨ä»¶ä¼ é€’åˆ°å¦å¤–ä¸€ä¸ªéƒ¨ä»¶ã€‚<br>é€šå¸¸æ€»çº¿è¢«è®¾è®¡æˆä¼ é€å›ºå®šé•¿åº¦çš„å­—èŠ‚å—ï¼Œä¹Ÿå°±æ˜¯å­—ï¼ˆwordï¼‰ã€‚è‡³äºè¿™ä¸ªå­—åˆ°åº•æ˜¯å¤šå°‘ä¸ªå­—èŠ‚ï¼Œå„ä¸ªç³»ç»Ÿä¸­æ˜¯ä¸ä¸€æ ·çš„ï¼Œ32ä½çš„æœºå™¨ï¼Œä¸€ä¸ªå­—é•¿æ˜¯4ä¸ªå­—èŠ‚ï¼›è€Œ64ä½çš„æœºå™¨ï¼Œä¸€ä¸ªå­—é•¿æ˜¯8ä¸ªå­—èŠ‚ã€‚</p><h2 id="è¾“å…¥è¾“å‡ºè®¾å¤‡ï¼ˆI-Oï¼‰"><a href="#è¾“å…¥è¾“å‡ºè®¾å¤‡ï¼ˆI-Oï¼‰" class="headerlink" title="è¾“å…¥è¾“å‡ºè®¾å¤‡ï¼ˆI/Oï¼‰"></a>è¾“å…¥è¾“å‡ºè®¾å¤‡ï¼ˆI/Oï¼‰</h2><p>é™¤äº†å¤„ç†å™¨ã€å†…å­˜ä»¥åŠæ€»çº¿ï¼Œè®¡ç®—æœºç³»ç»Ÿè¿˜åŒ…å«äº†å„ç§è¾“å…¥è¾“å‡ºè®¾å¤‡ï¼Œä¾‹å¦‚é”®ç›˜ã€é¼ æ ‡ã€æ˜¾ç¤ºå™¨ä»¥åŠç£ç›˜ç­‰ç­‰ã€‚<br>æ¯ä¸€ä¸ªè¾“å…¥è¾“å‡ºè®¾å¤‡éƒ½é€šè¿‡ä¸€ä¸ªæ§åˆ¶å™¨ï¼ˆControllerï¼‰æˆ–è€…é€‚é…å™¨ï¼ˆAdapterï¼‰ä¸ IO æ€»çº¿ç›¸è¿ã€‚</p><p>å›åˆ°æœ€åˆçš„é—®é¢˜ï¼šç¨‹åºè¿è¡Œçš„è¿‡ç¨‹ä¸­ç³»ç»Ÿå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿå³â†“â†“â†“</p><h1 id="ç¨‹åºæ˜¯æ€æ ·è·‘èµ·æ¥çš„"><a href="#ç¨‹åºæ˜¯æ€æ ·è·‘èµ·æ¥çš„" class="headerlink" title="ç¨‹åºæ˜¯æ€æ ·è·‘èµ·æ¥çš„"></a>ç¨‹åºæ˜¯æ€æ ·è·‘èµ·æ¥çš„</h1><h2 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a>Step1</h2><p>é¦–å…ˆ,æˆ‘ä»¬é€šè¿‡é”®ç›˜è¾“å…¥â€./helloâ€ çš„å­—ç¬¦ä¸²ï¼Œshell ç¨‹åºä¼šå°†è¾“å…¥çš„å­—ç¬¦é€ä¸€è¯»å…¥å¯„å­˜å™¨ï¼Œå¤„ç†å™¨ä¼šæŠŠ hello è¿™ä¸ªå­—ç¬¦ä¸²æ”¾å…¥å†…å­˜ä¸­ã€‚<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/07_step1.jpg?raw=true" width="600" alt="" align="center" /></p><h2 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a>Step2</h2><p>å½“æˆ‘ä»¬å®Œæˆè¾“å…¥ï¼ŒæŒ‰ä¸‹å›è½¦é”®æ—¶ï¼Œshell ç¨‹åºå°±çŸ¥é“æˆ‘ä»¬å·²ç»å®Œæˆäº†å‘½ä»¤çš„è¾“å…¥ï¼Œç„¶åæ‰§è¡Œä¸€ç³»åˆ—çš„æŒ‡ä»¤æ¥æ¥åŠ è½½å¯æ‰§è¡Œæ–‡ä»¶ hello ï¼Œè¿™äº›æŒ‡ä»¤å°† hello ä¸­çš„æ•°æ®å’Œä»£ç ä»ç£ç›˜å¤åˆ¶åˆ°å†…å­˜ã€‚<br>æ•°æ®å°±æ˜¯æˆ‘ä»¬è¦æ˜¾ç¤ºè¾“å‡ºçš„ â€œhello , world\nâ€ ;å½“å¯æ‰§è¡Œæ–‡ä»¶ hello ä¸­çš„ä»£ç å’Œæ•°æ®è¢«åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œå¤„ç†å™¨å°±å¼€å§‹æ‰§è¡Œ main å‡½æ•°ä¸­çš„ä»£ç ã€‚<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/09_step1.5.jpg?raw=true" width="600" alt="" align="center" /></p><h2 id="Step3"><a href="#Step3" class="headerlink" title="Step3"></a>Step3</h2><p>CPUä¼šå°† â€œhello , world\nâ€ è¿™ä¸ªå­—ç¬¦ä¸²ä»å†…å­˜å¤åˆ¶åˆ°å¯„å­˜å™¨æ–‡ä»¶ã€‚ç„¶åå†ä»å¯„å­˜å™¨æ–‡ä»¶å¤åˆ¶åˆ°æ˜¾ç¤ºè®¾å¤‡ï¼Œæœ€ç»ˆhello , worldæ˜¾ç¤ºåœ¨å±å¹•ä¸Šã€‚<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/08_step2.jpg?raw=true" width="600" alt="" align="center" /></p><h1 id="å­˜å‚¨è®¾å¤‡"><a href="#å­˜å‚¨è®¾å¤‡" class="headerlink" title="å­˜å‚¨è®¾å¤‡"></a>å­˜å‚¨è®¾å¤‡</h1><h2 id="å­˜å‚¨è®¾å¤‡çš„å®¹é‡"><a href="#å­˜å‚¨è®¾å¤‡çš„å®¹é‡" class="headerlink" title="å­˜å‚¨è®¾å¤‡çš„å®¹é‡"></a>å­˜å‚¨è®¾å¤‡çš„å®¹é‡</h2><p>å¯„å­˜å™¨æ–‡ä»¶ï¼ˆRegister Fileï¼‰: 100-1000B<br>é«˜é€Ÿç¼“å­˜ L1 cacheï¼š10-100KB<br>é«˜é€Ÿç¼“å­˜ L2 cacheï¼š0.1-10MB<br>é«˜é€Ÿç¼“å­˜ L3 cacheï¼š10-100MB<br>å†…å­˜ï¼ˆMain Memoryï¼‰ï¼š1-100GB<br>ç£ç›˜ï¼ˆDiskï¼‰ï¼š1-1000TB</p><h2 id="å­˜å‚¨è®¾å¤‡çš„å±‚çº§ç»“æ„"><a href="#å­˜å‚¨è®¾å¤‡çš„å±‚çº§ç»“æ„" class="headerlink" title="å­˜å‚¨è®¾å¤‡çš„å±‚çº§ç»“æ„"></a>å­˜å‚¨è®¾å¤‡çš„å±‚çº§ç»“æ„</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/11_memo2.jpg?raw=true" width="600" alt="" align="center" /><p>ä»è¿™ä¸ªå±‚æ¬¡ç»“æ„æ¥çœ‹ï¼Œä»ä¸Šåˆ°ä¸‹ï¼Œè®¾å¤‡çš„è®¿é—®é€Ÿåº¦è¶Šæ¥è¶Šæ…¢ï¼Œå®¹é‡è¶Šæ¥è¶Šå¤§ï¼Œæ¯å­—èŠ‚çš„é€ ä»·ä¹Ÿè¶Šæ¥è¶Šä¾¿å®œã€‚è¿™ä¸ªå±‚æ¬¡ç»“æ„çš„ä¸»è¦æ€æƒ³å°±æ˜¯ï¼šä¸Šä¸€å±‚å­˜å‚¨è®¾å¤‡æ˜¯ä¸‹ä¸€å±‚å­˜å‚¨è®¾å¤‡çš„é«˜é€Ÿç¼“å­˜ã€‚</p><h1 id="æ“ä½œç³»ç»Ÿ"><a href="#æ“ä½œç³»ç»Ÿ" class="headerlink" title="æ“ä½œç³»ç»Ÿ"></a>æ“ä½œç³»ç»Ÿ</h1><h2 id="ç¡¬ä»¶ã€è½¯ä»¶ä¹‹é—´çš„å…³ç³»"><a href="#ç¡¬ä»¶ã€è½¯ä»¶ä¹‹é—´çš„å…³ç³»" class="headerlink" title="ç¡¬ä»¶ã€è½¯ä»¶ä¹‹é—´çš„å…³ç³»"></a>ç¡¬ä»¶ã€è½¯ä»¶ä¹‹é—´çš„å…³ç³»</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/12_os1.jpg?raw=true" width="600" alt="" align="center" /><h2 id="æ“ä½œç³»ç»Ÿä¸­çš„æ¦‚å¿µ"><a href="#æ“ä½œç³»ç»Ÿä¸­çš„æ¦‚å¿µ" class="headerlink" title="æ“ä½œç³»ç»Ÿä¸­çš„æ¦‚å¿µ"></a>æ“ä½œç³»ç»Ÿä¸­çš„æ¦‚å¿µ</h2><p>ä¸ºäº†å®ç°ä¸Šè¿°çš„åŠŸèƒ½ï¼Œæ“ä½œç³»ç»Ÿå¼•äººäº†å‡ ä¸ªæŠ½è±¡çš„æ¦‚å¿µï¼š</p><ul><li>æ–‡ä»¶ï¼šIO è®¾å¤‡çš„æŠ½è±¡ï¼›</li><li>è™šæ‹Ÿå†…å­˜ï¼šå†…å­˜å’Œç£ç›˜IOè®¾å¤‡çš„æŠ½è±¡ï¼›</li><li>è¿›ç¨‹ï¼šå¤„ç†å™¨ã€å†…å­˜ä»¥åŠ IO è®¾å¤‡çš„æŠ½è±¡ã€‚<img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/13_chouxiang.jpg?raw=true" width="600" alt="" align="center" /></li></ul><h3 id="è¿›ç¨‹ï¼ˆProcessï¼‰"><a href="#è¿›ç¨‹ï¼ˆProcessï¼‰" class="headerlink" title="è¿›ç¨‹ï¼ˆProcessï¼‰"></a>è¿›ç¨‹ï¼ˆProcessï¼‰</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/14_process.jpg?raw=true" width="600" alt="" align="center" /><p>çº¿ç¨‹ï¼ˆå¯¹åº”ç¬¬12ç« ï¼‰ï¼š<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/15_thread.jpg?raw=true" width="600" alt="" align="center" /></p><h3 id="è™šæ‹Ÿå†…å­˜ï¼ˆVirtual-Memoryï¼‰"><a href="#è™šæ‹Ÿå†…å­˜ï¼ˆVirtual-Memoryï¼‰" class="headerlink" title="è™šæ‹Ÿå†…å­˜ï¼ˆVirtual Memoryï¼‰"></a>è™šæ‹Ÿå†…å­˜ï¼ˆVirtual Memoryï¼‰</h3><p>å¯¹åº”ç¬¬3ã€7ã€9ç« <br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/16_vm.jpg?raw=true" width="600" alt="" align="center" /></p><h3 id="æ–‡ä»¶ï¼ˆFileï¼‰"><a href="#æ–‡ä»¶ï¼ˆFileï¼‰" class="headerlink" title="æ–‡ä»¶ï¼ˆFileï¼‰"></a>æ–‡ä»¶ï¼ˆFileï¼‰</h3><p>å¯¹åº”ç¬¬10ç« <br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/17_file.jpg?raw=true" width="600" alt="" align="center" /></p><h1 id="ç½‘ç»œï¼ˆNetworkï¼‰"><a href="#ç½‘ç»œï¼ˆNetworkï¼‰" class="headerlink" title="ç½‘ç»œï¼ˆNetworkï¼‰"></a>ç½‘ç»œï¼ˆNetworkï¼‰</h1><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/18_network.jpg?raw=true" width="600" alt="" align="center" /><p>å¦‚ä½•é€šè¿‡ç½‘ç»œåœ¨è¿œç¨‹ä¸»æœºä¸Šè¿è¡Œhelloç¨‹åºï¼Ÿ<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/19_network2.jpg?raw=true" width="600" alt="" align="center" /></p><h1 id="ç³»ç»ŸåŠ é€Ÿ-é«˜æ€§èƒ½"><a href="#ç³»ç»ŸåŠ é€Ÿ-é«˜æ€§èƒ½" class="headerlink" title="ç³»ç»ŸåŠ é€Ÿ/é«˜æ€§èƒ½"></a>ç³»ç»ŸåŠ é€Ÿ/é«˜æ€§èƒ½</h1><h2 id="é˜¿å§†è¾¾å°”å®šå¾‹ï¼ˆAmdahlâ€™s-Lawï¼‰"><a href="#é˜¿å§†è¾¾å°”å®šå¾‹ï¼ˆAmdahlâ€™s-Lawï¼‰" class="headerlink" title="é˜¿å§†è¾¾å°”å®šå¾‹ï¼ˆAmdahlâ€™s Lawï¼‰"></a>é˜¿å§†è¾¾å°”å®šå¾‹ï¼ˆAmdahlâ€™s Lawï¼‰</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/21_am.jpg?raw=true" width="300" alt="" align="center" />æ¨å¯¼ï¼š<img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/22.jpg?raw=true" width="600" alt="" align="center" /><h2 id="å¦‚ä½•è·å¾—é«˜æ€§èƒ½è®¡ç®—èƒ½åŠ›ï¼Ÿ"><a href="#å¦‚ä½•è·å¾—é«˜æ€§èƒ½è®¡ç®—èƒ½åŠ›ï¼Ÿ" class="headerlink" title="å¦‚ä½•è·å¾—é«˜æ€§èƒ½è®¡ç®—èƒ½åŠ›ï¼Ÿ"></a>å¦‚ä½•è·å¾—é«˜æ€§èƒ½è®¡ç®—èƒ½åŠ›ï¼Ÿ</h2><ol><li>çº¿ç¨‹çº§å¹¶å‘</li><li>æŒ‡ä»¤çº§å¹¶è¡Œ</li><li>å•æŒ‡ä»¤å¤šæ•°æ®å¹¶è¡Œ</li></ol><h3 id="çº¿ç¨‹çº§å¹¶å‘ï¼ˆThread-level-Concurrencyï¼‰"><a href="#çº¿ç¨‹çº§å¹¶å‘ï¼ˆThread-level-Concurrencyï¼‰" class="headerlink" title="çº¿ç¨‹çº§å¹¶å‘ï¼ˆThread-level Concurrencyï¼‰"></a>çº¿ç¨‹çº§å¹¶å‘ï¼ˆThread-level Concurrencyï¼‰</h3><h4 id="å¤šæ ¸å¤„ç†å™¨çš„ç»„ç»‡ç»“æ„"><a href="#å¤šæ ¸å¤„ç†å™¨çš„ç»„ç»‡ç»“æ„" class="headerlink" title="å¤šæ ¸å¤„ç†å™¨çš„ç»„ç»‡ç»“æ„"></a>å¤šæ ¸å¤„ç†å™¨çš„ç»„ç»‡ç»“æ„</h4><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/23.jpg?raw=true" width="600" alt="" align="center" /><h4 id="è¶…çº¿ç¨‹ï¼ˆHyperthreadingï¼‰"><a href="#è¶…çº¿ç¨‹ï¼ˆHyperthreadingï¼‰" class="headerlink" title="è¶…çº¿ç¨‹ï¼ˆHyperthreadingï¼‰"></a>è¶…çº¿ç¨‹ï¼ˆHyperthreadingï¼‰</h4><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/24.jpg?raw=true" width="600" alt="" align="center" /><p>å½“ä¸€ä¸ªçº¿ç¨‹å› ä¸ºè¯»å–æ•°æ®è€Œè¿›äººç­‰å¾…çŠ¶æ€æ—¶ï¼ŒCPUå¯ä»¥å»æ‰§è¡Œå¦å¤–ä¸€ä¸ªçº¿ç¨‹ï¼Œå…¶ä¸­çº¿ç¨‹ä¹‹é—´çš„åˆ‡æ¢åªéœ€è¦æå°‘çš„æ—¶é—´ä»£ä»·ã€‚</p><h3 id="æŒ‡ä»¤çº§å¹¶è¡Œï¼ˆInstruction-level-Parallelismï¼‰"><a href="#æŒ‡ä»¤çº§å¹¶è¡Œï¼ˆInstruction-level-Parallelismï¼‰" class="headerlink" title="æŒ‡ä»¤çº§å¹¶è¡Œï¼ˆInstruction-level Parallelismï¼‰"></a>æŒ‡ä»¤çº§å¹¶è¡Œï¼ˆInstruction-level Parallelismï¼‰</h3><p>ç°ä»£å¤„ç†å™¨å¯ä»¥åŒæ—¶æ‰§è¡Œå¤šæ¡æŒ‡ä»¤çš„å±æ€§ç§°ä¸ºæŒ‡ä½˜çº§å¹¶è¡Œï¼Œåœ¨ç¬¬4ç« ä¸­å°†ä»‹ç»æµæ°´çº¿æŠ€æœ¯ã€‚</p><h3 id="å•æŒ‡ä»¤å¤šæ•°æ®å¹¶è¡Œ"><a href="#å•æŒ‡ä»¤å¤šæ•°æ®å¹¶è¡Œ" class="headerlink" title="å•æŒ‡ä»¤å¤šæ•°æ®å¹¶è¡Œ"></a>å•æŒ‡ä»¤å¤šæ•°æ®å¹¶è¡Œ</h3><p>ç°ä»£å¤„ç†å™¨æ‹¥æœ‰ç‰¹æ®Šçš„ç¡¬ä»¶éƒ¨ä»¶ï¼Œå…è®¸ä¸€æ¡æŒ‡ä»¤äº§ç”Ÿå¤šä¸ªå¹¶è¡Œçš„æ“ä½œï¼Œè¿™ç§æ–¹å¼ç§°ä¸ºå•æŒ‡ä»¤å¤šæ•°æ®ï¼ˆSingle-Instruction Multiple-Data Parallelismï¼‰ã€‚</p><h1 id="è™šæ‹Ÿæœºï¼ˆVirtual-Machineï¼‰"><a href="#è™šæ‹Ÿæœºï¼ˆVirtual-Machineï¼‰" class="headerlink" title="è™šæ‹Ÿæœºï¼ˆVirtual Machineï¼‰"></a>è™šæ‹Ÿæœºï¼ˆVirtual Machineï¼‰</h1><img src="https://github.com/chuxiaoyu/blog_image/blob/master/csapp/20_vm.jpg?raw=true" width="600" alt="" align="center" /><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>ã€åˆé›†ã€‘CSAPP-æ·±å…¥ç†è§£è®¡ç®—æœºç³»ç»Ÿ <a href="https://www.bilibili.com/video/BV1cD4y1D7uR">https://www.bilibili.com/video/BV1cD4y1D7uR</a></li><li>CSDNè®¡ç®—æœºç³»ç»Ÿ-01è®¡ç®—æœºç³»ç»Ÿæ¼«æ¸¸ <a href="https://blog.csdn.net/qq_29051413/article/details/116450610">https://blog.csdn.net/qq_29051413/article/details/116450610</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;ã€Šæ·±å…¥ç†è§£è®¡ç®—æœºç³»ç»Ÿã€‹å…¨ä¹¦æ¦‚è§ˆï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chap01. A Tour of Computer System/è®¡ç®—æœºç³»ç»Ÿæ¼«æ¸¸&lt;/li&gt;
&lt;li&gt;Part I. Program Structure and Execution/ç¨‹åºç»“æ„å’Œæ‰§è¡Œ&lt;/li&gt;
&lt;li</summary>
      
    
    
    
    <category term="01 è®¡ç®—æœºåŸºç¡€" scheme="http://example.com/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CSAPP æ·±å…¥ç†è§£è®¡ç®—æœºç³»ç»Ÿ" scheme="http://example.com/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/CSAPP-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="computer system" scheme="http://example.com/tags/computer-system/"/>
    
    <category term="csapp" scheme="http://example.com/tags/csapp/"/>
    
  </entry>
  
  <entry>
    <title>å¾ªç¯ç¥ç»ç½‘ç»œ</title>
    <link href="http://example.com/leeml-rnn/"/>
    <id>http://example.com/leeml-rnn/</id>
    <published>2021-10-24T08:15:10.000Z</published>
    <updated>2021-11-24T09:54:26.470Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡å­¦ä¹ çš„è¯¾ç¨‹æ˜¯ï¼šæå®æ¯…æœºå™¨å­¦ä¹ (2017)-RNN <a href="https://www.bilibili.com/video/BV13x411v7US?p=36">https://www.bilibili.com/video/BV13x411v7US?p=36</a></p><p>ï¼ˆæŒ–å‘ï¼‰</p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>æå®æ¯…æœºå™¨å­¦ä¹ (2017)-RNN <a href="https://www.bilibili.com/video/BV13x411v7US?p=36">https://www.bilibili.com/video/BV13x411v7US?p=36</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;æœ¬æ–‡å­¦ä¹ çš„è¯¾ç¨‹æ˜¯ï¼šæå®æ¯…æœºå™¨å­¦ä¹ (2017)-RNN &lt;a href=&quot;https://www.bilibili.com/video/BV13x411v7US?p=36&quot;&gt;https://www.bilibili.com/video/BV13x411v7US?p=36&lt;/a</summary>
      
    
    
    
    <category term="02 äººå·¥æ™ºèƒ½" scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="æå®æ¯…æœºå™¨å­¦ä¹ " scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="machine learning" scheme="http://example.com/tags/machine-learning/"/>
    
    <category term="rnn" scheme="http://example.com/tags/rnn/"/>
    
  </entry>
  
  <entry>
    <title>Lecture01(elective) åå‘ä¼ æ’­ç®—æ³•</title>
    <link href="http://example.com/leeml-lec01-bp/"/>
    <id>http://example.com/leeml-lec01-bp/</id>
    <published>2021-10-15T06:55:13.000Z</published>
    <updated>2021-11-24T09:54:18.393Z</updated>
    
    <content type="html"><![CDATA[<p>ï¼ˆæŒ–å‘ï¼‰</p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li><a href=""></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;ï¼ˆæŒ–å‘ï¼‰&lt;/p&gt;
&lt;h1 id=&quot;å‚è€ƒèµ„æ–™&quot;&gt;&lt;a href=&quot;#å‚è€ƒèµ„æ–™&quot; class=&quot;headerlink&quot; title=&quot;å‚è€ƒèµ„æ–™&quot;&gt;&lt;/a&gt;å‚è€ƒèµ„æ–™&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</summary>
      
    
    
    
    <category term="02 äººå·¥æ™ºèƒ½" scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="æå®æ¯…æœºå™¨å­¦ä¹ " scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="machine learning" scheme="http://example.com/tags/machine-learning/"/>
    
    <category term="team leaning" scheme="http://example.com/tags/team-leaning/"/>
    
    <category term="back propagation" scheme="http://example.com/tags/back-propagation/"/>
    
  </entry>
  
  <entry>
    <title>Chapter04 PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMNISTå›¾åƒåˆ†ç±»</title>
    <link href="http://example.com/pytorch-chap04/"/>
    <id>http://example.com/pytorch-chap04/</id>
    <published>2021-10-14T10:02:55.000Z</published>
    <updated>2021-10-21T02:53:10.210Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¬¬å››ç« -PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMNISTå›¾åƒåˆ†ç±»"><a href="#ç¬¬å››ç« -PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMNISTå›¾åƒåˆ†ç±»" class="headerlink" title="ç¬¬å››ç«  PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMNISTå›¾åƒåˆ†ç±»"></a>ç¬¬å››ç«  PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMNISTå›¾åƒåˆ†ç±»</h1><h2 id="æ•°æ®é›†å’Œä»»åŠ¡ä»‹ç»"><a href="#æ•°æ®é›†å’Œä»»åŠ¡ä»‹ç»" class="headerlink" title="æ•°æ®é›†å’Œä»»åŠ¡ä»‹ç»"></a>æ•°æ®é›†å’Œä»»åŠ¡ä»‹ç»</h2><p>æˆ‘ä»¬è¿™é‡Œçš„ä»»åŠ¡æ˜¯å¯¹10ä¸ªç±»åˆ«çš„â€œæ—¶è£…â€å›¾åƒè¿›è¡Œåˆ†ç±»ï¼Œä½¿ç”¨FashionMNISTæ•°æ®é›†ã€‚</p><p>FashionMNISTæ•°æ®é›†ä¸­åŒ…å«å·²ç»é¢„å…ˆåˆ’åˆ†å¥½çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­è®­ç»ƒé›†å…±60,000å¼ å›¾åƒï¼Œæµ‹è¯•é›†å…±10,000å¼ å›¾åƒã€‚æ¯å¼ å›¾åƒå‡ä¸ºå•é€šé“é»‘ç™½å›¾åƒï¼Œå¤§å°ä¸º32*32pixelï¼Œåˆ†å±10ä¸ªç±»åˆ«ã€‚</p><h2 id="å¯¼å…¥å¿…è¦çš„åŒ…"><a href="#å¯¼å…¥å¿…è¦çš„åŒ…" class="headerlink" title="å¯¼å…¥å¿…è¦çš„åŒ…"></a>å¯¼å…¥å¿…è¦çš„åŒ…</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br></pre></td></tr></table></figure><h2 id="é…ç½®è®­ç»ƒç¯å¢ƒå’Œè¶…å‚æ•°"><a href="#é…ç½®è®­ç»ƒç¯å¢ƒå’Œè¶…å‚æ•°" class="headerlink" title="é…ç½®è®­ç»ƒç¯å¢ƒå’Œè¶…å‚æ•°"></a>é…ç½®è®­ç»ƒç¯å¢ƒå’Œè¶…å‚æ•°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é…ç½®GPUï¼Œè¿™é‡Œæœ‰ä¸¤ç§æ–¹å¼</span></span><br><span class="line"><span class="comment">## æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨os.environ</span></span><br><span class="line"><span class="comment"># os.environ[&#x27;CUDA_VISIBLE_DEVICES&#x27;] = &#x27;0&#x27;</span></span><br><span class="line"><span class="comment"># æ–¹æ¡ˆäºŒï¼šä½¿ç”¨â€œdeviceâ€ï¼Œåç»­å¯¹è¦ä½¿ç”¨GPUçš„å˜é‡ç”¨.to(device)å³å¯</span></span><br><span class="line"><span class="comment"># device = torch.device(&quot;cuda:1&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## é…ç½®å…¶ä»–è¶…å‚æ•°ï¼Œå¦‚batch_size, num_workers, learning rate, ä»¥åŠæ€»çš„epochs</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">num_workers = <span class="number">4</span></span><br><span class="line">lr = <span class="number">1e-4</span></span><br><span class="line">epochs = <span class="number">20</span></span><br></pre></td></tr></table></figure><h2 id="æ•°æ®è¯»å…¥å’ŒåŠ è½½"><a href="#æ•°æ®è¯»å…¥å’ŒåŠ è½½" class="headerlink" title="æ•°æ®è¯»å…¥å’ŒåŠ è½½"></a>æ•°æ®è¯»å…¥å’ŒåŠ è½½</h2><p>æ•°æ®è¯»å…¥æœ‰ä¸¤ç§æ–¹å¼:</p><ul><li>ä¸‹è½½å¹¶ä½¿ç”¨PyTorchæä¾›çš„å†…ç½®æ•°æ®é›†ã€‚è¿™ç§æ–¹å¼åªé€‚ç”¨äºå¸¸è§çš„æ•°æ®é›†ï¼Œå¦‚MNISTï¼ŒCIFAR10ç­‰ï¼ŒPyTorchå®˜æ–¹æä¾›äº†æ•°æ®ä¸‹è½½ã€‚è¿™ç§æ–¹å¼å¾€å¾€é€‚ç”¨äºå¿«é€Ÿæµ‹è¯•æ–¹æ³•ï¼ˆæ¯”å¦‚æµ‹è¯•ä¸‹æŸä¸ªideaåœ¨MNISTæ•°æ®é›†ä¸Šæ˜¯å¦æœ‰æ•ˆï¼‰</li><li>ä»ç½‘ç«™ä¸‹è½½ä»¥csvæ ¼å¼å­˜å‚¨çš„æ•°æ®ï¼Œè¯»å…¥å¹¶è½¬æˆé¢„æœŸçš„æ ¼å¼ã€‚è¿™ç§æ•°æ®è¯»å…¥æ–¹å¼éœ€è¦è‡ªå·±æ„å»ºDatasetï¼Œè¿™å¯¹äºPyTorchåº”ç”¨äºè‡ªå·±çš„å·¥ä½œä¸­ååˆ†é‡è¦</li></ul><p>åŒæ—¶ï¼Œè¿˜éœ€è¦å¯¹æ•°æ®è¿›è¡Œå¿…è¦çš„å˜æ¢ï¼Œæ¯”å¦‚è¯´éœ€è¦å°†å›¾ç‰‡ç»Ÿä¸€ä¸ºä¸€è‡´çš„å¤§å°ï¼Œä»¥ä¾¿åç»­èƒ½å¤Ÿè¾“å…¥ç½‘ç»œè®­ç»ƒï¼›éœ€è¦å°†æ•°æ®æ ¼å¼è½¬ä¸ºTensorç±»ï¼Œç­‰ç­‰ã€‚è¿™äº›å˜æ¢å¯ä»¥å¾ˆæ–¹ä¾¿åœ°å€ŸåŠ©torchvisionåŒ…æ¥å®Œæˆï¼Œtorchvisionè¿™æ˜¯PyTorchå®˜æ–¹ç”¨äºå›¾åƒå¤„ç†çš„å·¥å…·åº“ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é¦–å…ˆè®¾ç½®æ•°æ®å˜æ¢</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">image_size = <span class="number">28</span></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),   <span class="comment"># è¿™ä¸€æ­¥å–å†³äºåç»­çš„æ•°æ®è¯»å–æ–¹å¼ï¼Œå¦‚æœä½¿ç”¨å†…ç½®æ•°æ®é›†åˆ™ä¸éœ€è¦</span></span><br><span class="line">    transforms.Resize(image_size),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>è¯»å–æ–¹å¼ä¸€ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## è¯»å–æ–¹å¼ä¸€ï¼šä½¿ç”¨torchvisionè‡ªå¸¦æ•°æ®é›†ï¼Œä¸‹è½½å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">train_data = datasets.FashionMNIST(root=<span class="string">&#x27;./&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=data_transform)</span><br><span class="line">test_data = datasets.FashionMNIST(root=<span class="string">&#x27;./&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=data_transform)</span><br></pre></td></tr></table></figure><p>è¯»å–æ–¹å¼äºŒï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## è¯»å–æ–¹å¼äºŒï¼šè¯»å…¥csvæ ¼å¼çš„æ•°æ®ï¼Œè‡ªè¡Œæ„å»ºDatasetç±»</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FMDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, df, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.df = df</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.images = df.iloc[:,<span class="number">1</span>:].values.astype(np.uint8)</span><br><span class="line">        self.labels = df.iloc[:, <span class="number">0</span>].values</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        image = self.images[idx].reshape(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line">        label = <span class="built_in">int</span>(self.labels[idx])</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            image = torch.tensor(image/<span class="number">255.</span>, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        label = torch.tensor(label, dtype=torch.long)</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(<span class="string">&quot;./FashionMNIST/fashion-mnist_train.csv&quot;</span>)</span><br><span class="line">test_df = pd.read_csv(<span class="string">&quot;./FashionMNIST/fashion-mnist_test.csv&quot;</span>)</span><br><span class="line">train_data = FMDataset(train_df, data_transform)</span><br><span class="line">test_data = FMDataset(test_df, data_transform)</span><br></pre></td></tr></table></figure><blockquote><p>æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è‡ªå·±ä¸‹è½½æ•°æ®ã€‚å¯ä»¥ä»kaggleä¸Šä¸‹è½½ï¼ˆéœ€ç§‘å­¦ä¸Šç½‘ï¼‰ï¼ˆä½†è²Œä¼¼ä¹Ÿä¸æ˜¯æ•™ç¨‹ç”¨çš„ç‰ˆæœ¬ï¼‰ï¼š<a href="https://www.kaggle.com/zalando-research/fashionmnist/">https://www.kaggle.com/zalando-research/fashionmnist/</a></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰DataLoaderç±»ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒå’Œæµ‹è¯•æ—¶åŠ è½½æ•°æ®</span></span><br><span class="line">train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=num_workers, drop_last=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=num_workers)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ•°æ®å¯è§†åŒ–</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image, label = <span class="built_in">next</span>(<span class="built_in">iter</span>(test_loader))</span><br><span class="line"><span class="built_in">print</span>(image.shape, label.shape)</span><br><span class="line">plt.imshow(image[<span class="number">0</span>][<span class="number">0</span>], cmap=<span class="string">&quot;gray&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>è¿™é‡Œç¨‹åºè¿è¡Œäº†å¾ˆä¹…ï¼Œä¸€ç›´è·‘ä¸å‡ºç»“æœï¼Œæ”¹ç”¨äº†colab</p></blockquote><h2 id="æ¨¡å‹è®¾è®¡"><a href="#æ¨¡å‹è®¾è®¡" class="headerlink" title="æ¨¡å‹è®¾è®¡"></a>æ¨¡å‹è®¾è®¡</h2><p>æ‰‹æ­ä¸€ä¸ªCNN</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, <span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.3</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="comment"># x = nn.functional.normalize(x)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line"><span class="comment"># model = model.cuda()  # å°†æ¨¡å‹æ”¾åˆ°GPUä¸Šç”¨äºè®­ç»ƒ</span></span><br><span class="line"><span class="comment"># model = nn.DataParallel(model).cuda()   # å¤šå¡è®­ç»ƒæ—¶çš„å†™æ³•ï¼Œä¹‹åçš„è¯¾ç¨‹ä¸­ä¼šè¿›ä¸€æ­¥è®²è§£</span></span><br></pre></td></tr></table></figure><h2 id="è®¾å®šæŸå¤±å‡½æ•°"><a href="#è®¾å®šæŸå¤±å‡½æ•°" class="headerlink" title="è®¾å®šæŸå¤±å‡½æ•°"></a>è®¾å®šæŸå¤±å‡½æ•°</h2><p>ä½¿ç”¨torch.nnæ¨¡å—è‡ªå¸¦çš„CrossEntropyæŸå¤±ã€‚<br>PyTorchä¼šè‡ªåŠ¨æŠŠæ•´æ•°å‹çš„labelè½¬ä¸ºone-hotå‹ï¼Œç”¨äºè®¡ç®—CE lossã€‚<br>è¿™é‡Œéœ€è¦ç¡®ä¿labelæ˜¯ä»0å¼€å§‹çš„ï¼ŒåŒæ—¶æ¨¡å‹ä¸åŠ softmaxå±‚ï¼ˆä½¿ç”¨logitsè®¡ç®—ï¼‰,è¿™ä¹Ÿè¯´æ˜äº†PyTorchè®­ç»ƒä¸­å„ä¸ªéƒ¨åˆ†ä¸æ˜¯ç‹¬ç«‹çš„ï¼Œéœ€è¦é€šç›˜è€ƒè™‘ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># criterion = nn.CrossEntropyLoss(weight=[1,1,1,1,3,1,1,1,1,1])</span></span><br></pre></td></tr></table></figure><h2 id="è®¾å®šä¼˜åŒ–å™¨"><a href="#è®¾å®šä¼˜åŒ–å™¨" class="headerlink" title="è®¾å®šä¼˜åŒ–å™¨"></a>è®¾å®šä¼˜åŒ–å™¨</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure><h2 id="è®­ç»ƒå’Œæµ‹è¯•"><a href="#è®­ç»ƒå’Œæµ‹è¯•" class="headerlink" title="è®­ç»ƒå’Œæµ‹è¯•"></a>è®­ç»ƒå’Œæµ‹è¯•</h2><p><strong>è®­ç»ƒå’Œæµ‹è¯•ï¼ˆéªŒè¯ï¼‰</strong><br>å„è‡ªå°è£…æˆå‡½æ•°ï¼Œæ–¹ä¾¿åç»­è°ƒç”¨<br>å…³æ³¨ä¸¤è€…çš„ä¸»è¦åŒºåˆ«ï¼š</p><ul><li>æ¨¡å‹çŠ¶æ€è®¾ç½®</li><li>æ˜¯å¦éœ€è¦åˆå§‹åŒ–ä¼˜åŒ–å™¨</li><li>æ˜¯å¦éœ€è¦å°†lossä¼ å›åˆ°ç½‘ç»œ</li><li>æ˜¯å¦éœ€è¦æ¯æ­¥æ›´æ–°optimizer</li></ul><p>æ­¤å¤–ï¼Œå¯¹äºæµ‹è¯•æˆ–éªŒè¯è¿‡ç¨‹ï¼Œå¯ä»¥è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        <span class="comment"># data, label = data.cuda(), label.cuda()  # ä¸ç”¨cudaå…ˆ</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output, label)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        train_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">    train_loss = train_loss/<span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, train_loss))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val</span>(<span class="params">epoch</span>):</span>       </span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    val_loss = <span class="number">0</span></span><br><span class="line">    gt_labels = []</span><br><span class="line">    pred_labels = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> test_loader:</span><br><span class="line">            <span class="comment"># data, label = data.cuda(), label.cuda()  # ä¸ç”¨cudaå…ˆ</span></span><br><span class="line">            output = model(data)</span><br><span class="line">            preds = torch.argmax(output, <span class="number">1</span>)</span><br><span class="line">            gt_labels.append(label.cpu().data.numpy())</span><br><span class="line">            pred_labels.append(preds.cpu().data.numpy())</span><br><span class="line">            loss = criterion(output, label)</span><br><span class="line">            val_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">    val_loss = val_loss/<span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)</span><br><span class="line">    acc = np.<span class="built_in">sum</span>(gt_labels==pred_labels)/<span class="built_in">len</span>(pred_labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tValidation Loss: &#123;:.6f&#125;, Accuracy: &#123;:6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, val_loss, acc))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, epochs+<span class="number">1</span>):</span><br><span class="line">    train(epoch)</span><br><span class="line">    val(epoch)</span><br></pre></td></tr></table></figure><p>ç»“æœï¼ˆä¸æ˜¯å¾ˆå¥½ï¼‰ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/lib/python3<span class="number">.7</span>/dist-packages/torch/utils/data/dataloader.py:<span class="number">481</span>: UserWarning: This DataLoader will create <span class="number">4</span> worker processes <span class="keyword">in</span> total. Our suggested <span class="built_in">max</span> number of worker <span class="keyword">in</span> current system <span class="keyword">is</span> <span class="number">2</span>, which <span class="keyword">is</span> smaller than what this DataLoader <span class="keyword">is</span> going to create. Please be aware that excessive worker creation might get DataLoader running slow <span class="keyword">or</span> even freeze, lower the worker number to avoid potential slowness/freeze <span class="keyword">if</span> necessary.</span><br><span class="line">  cpuset_checked))</span><br><span class="line">/usr/local/lib/python3<span class="number">.7</span>/dist-packages/torch/nn/functional.py:<span class="number">718</span>: UserWarning: Named tensors <span class="keyword">and</span> <span class="built_in">all</span> their associated APIs are an experimental feature <span class="keyword">and</span> subject to change. Please do <span class="keyword">not</span> use them <span class="keyword">for</span> anything important until they are released <span class="keyword">as</span> stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:<span class="number">1156.</span>)</span><br><span class="line">  <span class="keyword">return</span> torch.max_pool2d(<span class="built_in">input</span>, kernel_size, stride, padding, dilation, ceil_mode)</span><br><span class="line">Epoch: <span class="number">1</span> Training Loss: <span class="number">1.859782</span></span><br><span class="line">Epoch: <span class="number">1</span> Validation Loss: <span class="number">1.252422</span>, Accuracy: <span class="number">0.504242</span></span><br><span class="line">Epoch: <span class="number">2</span> Training Loss: <span class="number">1.073511</span></span><br><span class="line">Epoch: <span class="number">2</span> Validation Loss: <span class="number">0.958262</span>, Accuracy: <span class="number">0.620891</span></span><br><span class="line">Epoch: <span class="number">3</span> Training Loss: <span class="number">0.912065</span></span><br><span class="line">Epoch: <span class="number">3</span> Validation Loss: <span class="number">0.859967</span>, Accuracy: <span class="number">0.682927</span></span><br><span class="line">Epoch: <span class="number">4</span> Training Loss: <span class="number">0.803673</span></span><br><span class="line">Epoch: <span class="number">4</span> Validation Loss: <span class="number">0.725328</span>, Accuracy: <span class="number">0.743902</span></span><br><span class="line">Epoch: <span class="number">5</span> Training Loss: <span class="number">0.723244</span></span><br><span class="line">Epoch: <span class="number">5</span> Validation Loss: <span class="number">0.699738</span>, Accuracy: <span class="number">0.725345</span></span><br><span class="line">Epoch: <span class="number">6</span> Training Loss: <span class="number">0.676728</span></span><br><span class="line">Epoch: <span class="number">6</span> Validation Loss: <span class="number">0.688325</span>, Accuracy: <span class="number">0.742312</span></span><br><span class="line">Epoch: <span class="number">7</span> Training Loss: <span class="number">0.624213</span></span><br><span class="line">Epoch: <span class="number">7</span> Validation Loss: <span class="number">0.633743</span>, Accuracy: <span class="number">0.744963</span></span><br><span class="line">Epoch: <span class="number">8</span> Training Loss: <span class="number">0.595873</span></span><br><span class="line">Epoch: <span class="number">8</span> Validation Loss: <span class="number">0.588029</span>, Accuracy: <span class="number">0.770414</span></span><br><span class="line">Epoch: <span class="number">9</span> Training Loss: <span class="number">0.561574</span></span><br><span class="line">Epoch: <span class="number">9</span> Validation Loss: <span class="number">0.578903</span>, Accuracy: <span class="number">0.765642</span></span><br><span class="line">Epoch: <span class="number">10</span> Training Loss: <span class="number">0.544152</span></span><br><span class="line">Epoch: <span class="number">10</span> Validation Loss: <span class="number">0.563249</span>, Accuracy: <span class="number">0.791622</span></span><br><span class="line">Epoch: <span class="number">11</span> Training Loss: <span class="number">0.532662</span></span><br><span class="line">Epoch: <span class="number">11</span> Validation Loss: <span class="number">0.561163</span>, Accuracy: <span class="number">0.790032</span></span><br><span class="line">Epoch: <span class="number">12</span> Training Loss: <span class="number">0.520769</span></span><br><span class="line">Epoch: <span class="number">12</span> Validation Loss: <span class="number">0.560051</span>, Accuracy: <span class="number">0.783139</span></span><br><span class="line">Epoch: <span class="number">13</span> Training Loss: <span class="number">0.495388</span></span><br><span class="line">Epoch: <span class="number">13</span> Validation Loss: <span class="number">0.537520</span>, Accuracy: <span class="number">0.794804</span></span><br><span class="line">Epoch: <span class="number">14</span> Training Loss: <span class="number">0.461928</span></span><br><span class="line">Epoch: <span class="number">14</span> Validation Loss: <span class="number">0.533855</span>, Accuracy: <span class="number">0.799046</span></span><br><span class="line">Epoch: <span class="number">15</span> Training Loss: <span class="number">0.453786</span></span><br><span class="line">Epoch: <span class="number">15</span> Validation Loss: <span class="number">0.534338</span>, Accuracy: <span class="number">0.805408</span></span><br><span class="line">Epoch: <span class="number">16</span> Training Loss: <span class="number">0.457692</span></span><br><span class="line">Epoch: <span class="number">16</span> Validation Loss: <span class="number">0.515626</span>, Accuracy: <span class="number">0.812831</span></span><br><span class="line">Epoch: <span class="number">17</span> Training Loss: <span class="number">0.449596</span></span><br><span class="line">Epoch: <span class="number">17</span> Validation Loss: <span class="number">0.504590</span>, Accuracy: <span class="number">0.816013</span></span><br><span class="line">Epoch: <span class="number">18</span> Training Loss: <span class="number">0.443980</span></span><br><span class="line">Epoch: <span class="number">18</span> Validation Loss: <span class="number">0.503526</span>, Accuracy: <span class="number">0.818134</span></span><br><span class="line">Epoch: <span class="number">19</span> Training Loss: <span class="number">0.420621</span></span><br><span class="line">Epoch: <span class="number">19</span> Validation Loss: <span class="number">0.488520</span>, Accuracy: <span class="number">0.826087</span></span><br><span class="line">Epoch: <span class="number">20</span> Training Loss: <span class="number">0.418917</span></span><br><span class="line">Epoch: <span class="number">20</span> Validation Loss: <span class="number">0.524965</span>, Accuracy: <span class="number">0.797985</span></span><br></pre></td></tr></table></figure><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>ç¨‹åºçš„colabé“¾æ¥ï¼š<a href="https://colab.research.google.com/drive/1kvaBEEgQ_a5G5xOHUe5ih4Qq8L5C9zYY?usp=sharing">https://colab.research.google.com/drive/1kvaBEEgQ_a5G5xOHUe5ih4Qq8L5C9zYY?usp=sharing</a></li><li>Datawhaleå¼€æºé¡¹ç›®ï¼šæ·±å…¥æµ…å‡ºPyTorch <a href="https://github.com/datawhalechina/thorough-pytorch/">https://github.com/datawhalechina/thorough-pytorch/</a></li><li>æå®æ¯…æœºå™¨å­¦ä¹ 2021æ˜¥-PyTorch Tutorial <a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=5">https://www.bilibili.com/video/BV1Wv411h7kN?p=5</a></li><li>åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ pytorchç‰ˆ <a href="https://zh-v2.d2l.ai/chapter_preface/index.html">https://zh-v2.d2l.ai/chapter_preface/index.html</a></li><li>PyTorchå®˜æ–¹æ•™ç¨‹ä¸­æ–‡ç‰ˆ <a href="https://pytorch123.com/SecondSection/training_a_classifier/">https://pytorch123.com/SecondSection/training_a_classifier/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ç¬¬å››ç« -PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMNISTå›¾åƒåˆ†ç±»&quot;&gt;&lt;a href=&quot;#ç¬¬å››ç« -PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMNISTå›¾åƒåˆ†ç±»&quot; class=&quot;headerlink&quot; title=&quot;ç¬¬å››ç«  PyTorchåŸºç¡€å®æˆ˜â€”â€”FashionMN</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬30æœŸ æ·±å…¥æµ…å‡ºPyTorch" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC30%E6%9C%9F-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAPyTorch/"/>
    
    
    <category term="PyTorch" scheme="http://example.com/tags/PyTorch/"/>
    
    <category term="team learning" scheme="http://example.com/tags/team-learning/"/>
    
    <category term="note" scheme="http://example.com/tags/note/"/>
    
  </entry>
  
  <entry>
    <title>Lecture01 æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç®€ä»‹</title>
    <link href="http://example.com/leeml-lec01-introduction/"/>
    <id>http://example.com/leeml-lec01-introduction/</id>
    <published>2021-10-12T05:40:12.000Z</published>
    <updated>2021-11-24T09:54:31.117Z</updated>
    
    <content type="html"><![CDATA[<h1 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h1><p>æœ¬æ–‡å­¦ä¹ çš„è¯¾ç¨‹æ˜¯ï¼šæå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ Lecture01 æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç®€ä»‹ <a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=2">https://www.bilibili.com/video/BV1Wv411h7kN?p=2</a></p><h1 id="æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹å¤§çº²"><a href="#æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹å¤§çº²" class="headerlink" title="æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹å¤§çº²"></a>æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹å¤§çº²</h1><p>ç¬¬ä¸€èŠ‚ Introduction  ä½œä¸š HW1: Regression<br>ç¬¬äºŒèŠ‚ Deep Learning  ä½œä¸š HW2: Classification<br>ç¬¬ä¸‰èŠ‚ Self-Attention  ä½œä¸š HW3: CNN HW4: Self-Attention<br>ç¬¬å››èŠ‚ Theory of ML<br>ç¬¬äº”èŠ‚ Transformer  ä½œä¸š HW5: Transformer<br>ç¬¬å…­èŠ‚ Generative Model  ä½œä¸š HW6: GAN<br>ç¬¬ä¸ƒèŠ‚ Self-Supervised Learning  ä½œä¸š HW7: BERT HW8: Autoencoder<br>ç¬¬å…«èŠ‚ Explainable AI / Adversarial Attack  ä½œä¸š HW9: Explainable AI HW10: Adversarial Attack<br>ç¬¬ä¹èŠ‚ Domain Adaptation/ RL  ä½œä¸š HW11: Adaptation<br>ç¬¬åèŠ‚ RL  ä½œä¸š HW12: RL<br>ç¬¬åä¸€èŠ‚  Privacy v.s. ML<br>ç¬¬åäºŒèŠ‚  Quantum ML<br>ç¬¬åä¸‰èŠ‚  Life-Long/Compression  ä½œä¸š HW13: Life-Long HW14: Compression<br>ç¬¬åå››èŠ‚  Meta Learning  ä½œä¸š HW15: Meta Learning</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/00_lec_schedule.jpg?raw=true" width="600" alt="" align="center" /><h1 id="Buffet-Style-Learning-è‡ªåŠ©å¼å­¦ä¹ "><a href="#Buffet-Style-Learning-è‡ªåŠ©å¼å­¦ä¹ " class="headerlink" title="Buffet Style Learning/è‡ªåŠ©å¼å­¦ä¹ "></a>Buffet Style Learning/è‡ªåŠ©å¼å­¦ä¹ </h1><blockquote><p>Everyone can take this course.</p><p>You decide how much you want to learn.</p><p>You decide how deep you want to learn.</p></blockquote><h1 id="æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹"><a href="#æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹" class="headerlink" title="æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹"></a>æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹</h1><p>Machine Learning çº¦ç­‰äº Looking for Function</p><h2 id="ä¸åŒç±»å‹çš„å‡½æ•°"><a href="#ä¸åŒç±»å‹çš„å‡½æ•°" class="headerlink" title="ä¸åŒç±»å‹çš„å‡½æ•°"></a>ä¸åŒç±»å‹çš„å‡½æ•°</h2><p>Regression/å›å½’ï¼šå‡½æ•°çš„è¾“å‡ºæ˜¯æ•°å€¼ã€‚</p><p>Classification/åˆ†ç±»ï¼šç»™å®šé€‰é¡¹ï¼ˆç±»åˆ«ï¼‰ï¼Œè¾“å‡ºæ­£ç¡®çš„ç±»åˆ«ã€‚</p><p>Structured Learningï¼šcreate something with structure (image, document etc.)</p><h2 id="How-to-find-a-function-A-case"><a href="#How-to-find-a-function-A-case" class="headerlink" title="How to find a function: A case"></a>How to find a function: A case</h2><p>Case: Predict YouTobe views</p><p>æ¨¡å‹çš„è®­ç»ƒï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/05_framework.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Step1-Function-with-Unknown-Parameters"><a href="#Step1-Function-with-Unknown-Parameters" class="headerlink" title="Step1. Function with Unknown Parameters"></a>Step1. Function with Unknown Parameters</h3><p>åŸºäºé¢†åŸŸçŸ¥è¯†å†™å‡ºä¸€ä¸ªå¸¦æœ‰ä½ç½®å‚æ•°çš„å‡½æ•°</p><p><code>y = b + wx1</code> w: weight, b: bias </p><h3 id="Step2-Define-Loss-from-Training-Data"><a href="#Step2-Define-Loss-from-Training-Data" class="headerlink" title="Step2. Define Loss from Training Data"></a>Step2. Define Loss from Training Data</h3><p>Loss is a function of parameters. <code>L(b, w)</code></p><p>Loss is how good a set of values is.</p><h3 id="Step3-Optimization"><a href="#Step3-Optimization" class="headerlink" title="Step3. Optimization"></a>Step3. Optimization</h3><p><code>w*, b* = arg min L(w, b)</code></p><p>Gradient Descent/æ¢¯åº¦ä¸‹é™ï¼ˆ1ä¸ªå‚æ•°ï¼Œå¤šå‚æ•°åŒç†ï¼‰</p><ul><li><p>éšæœºé€‰å–ä¸€ä¸ªåˆå§‹ç‚¹w0</p></li><li><p>è®¡ç®—w0å¯¹Lçš„å¾®åˆ†ã€‚learning rate/å­¦ä¹ ç‡ã€‚</p><ul><li>Negative: increase w</li><li>Positive: decrease w</li></ul></li><li><p>Update w iteratively/è¿­ä»£æ›´æ–°w</p></li></ul><h3 id="Training-Step1-3"><a href="#Training-Step1-3" class="headerlink" title="Training: Step1-3"></a>Training: Step1-3</h3><h1 id="æ·±åº¦å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹"><a href="#æ·±åº¦å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹" class="headerlink" title="æ·±åº¦å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹"></a>æ·±åº¦å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹</h1><h2 id="Regression-å›å½’ï¼Œæ¢¦å¼€å§‹çš„åœ°æ–¹"><a href="#Regression-å›å½’ï¼Œæ¢¦å¼€å§‹çš„åœ°æ–¹" class="headerlink" title="Regression/å›å½’ï¼Œæ¢¦å¼€å§‹çš„åœ°æ–¹"></a>Regression/å›å½’ï¼Œæ¢¦å¼€å§‹çš„åœ°æ–¹</h2><h3 id="å¦‚ä½•é€¼è¿‘å¤æ‚çš„æ›²çº¿ï¼Ÿâ€”â€”Sigmoid-Function"><a href="#å¦‚ä½•é€¼è¿‘å¤æ‚çš„æ›²çº¿ï¼Ÿâ€”â€”Sigmoid-Function" class="headerlink" title="å¦‚ä½•é€¼è¿‘å¤æ‚çš„æ›²çº¿ï¼Ÿâ€”â€”Sigmoid Function"></a>å¦‚ä½•é€¼è¿‘å¤æ‚çš„æ›²çº¿ï¼Ÿâ€”â€”Sigmoid Function</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/01_sigmoid.jpg?raw=true" width="400" alt="" align="center" /><p>ç”¨å¤šæ®µsigmoidé€¼è¿‘å¤æ‚å‡½æ•°ï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/02_sigmoid.jpg?raw=true" width="400" alt="" align="center" /><p>ç»™sigmoidåŠ æ›´å¤šçš„featureï¼ˆå°±æ˜¯å¤šæ®µ <code>y=b+wx</code>ç»„åˆèµ·æ¥ï¼‰ï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/03_sigmoid.jpg?raw=true" width="400" alt="" align="center" /><p>sigmoidçš„çŸ©é˜µè¿ç®—ï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/04_sigmoid.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Loss-æŸå¤±å‡½æ•°"><a href="#Loss-æŸå¤±å‡½æ•°" class="headerlink" title="Loss/æŸå¤±å‡½æ•°"></a>Loss/æŸå¤±å‡½æ•°</h3><p>ä»€ä¹ˆæ˜¯æŸå¤±å‡½æ•°ï¼š</p><ul><li>ä¸€ä¸ªå…³äºå‚æ•°çš„å‡½æ•°<code>L(ğœƒ)</code></li><li>è¡¡é‡è¿™ä¸€ç»„æ¨¡å‹å‚æ•°çš„æ•ˆæœ</li></ul><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/06_loss.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Optimization-ä¼˜åŒ–å™¨"><a href="#Optimization-ä¼˜åŒ–å™¨" class="headerlink" title="Optimization/ä¼˜åŒ–å™¨"></a>Optimization/ä¼˜åŒ–å™¨</h3><p>ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°ï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/07_optm.jpg?raw=true" width="400" alt="" align="center" /><p>ä¸€äº›æ¦‚å¿µï¼š</p><ul><li><p>Batch: æ•°æ®åŒ…</p></li><li><p>Updateï¼šæ¯æ¬¡æ›´æ–°ä¸€æ¬¡å‚æ•°</p></li><li><p>Epochï¼šæ‰€æœ‰batchè¿‡ä¸€é</p></li></ul><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/08_optm.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Activation-function-æ¿€æ´»å‡½æ•°"><a href="#Activation-function-æ¿€æ´»å‡½æ•°" class="headerlink" title="Activation function/æ¿€æ´»å‡½æ•°"></a>Activation function/æ¿€æ´»å‡½æ•°</h3><ul><li>sigmoid</li><li>ReLU</li></ul><h3 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h3><p>A fancy name: Deep Learning. </p><blockquote><p>It is just so deep, right?</p></blockquote><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/09_dl.jpg?raw=true" width="400" alt="" align="center" /><p>Go deeper and deeper:</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/10_dl.jpg?raw=true" width="400" alt="" align="center" /><p>Think: Why deep network, not fat network?</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/11_dl.jpg?raw=true" width="400" alt="" align="center" /><h2 id="é€‰ä¿®-æ·±åº¦å­¦ä¹ ç®€ä»‹"><a href="#é€‰ä¿®-æ·±åº¦å­¦ä¹ ç®€ä»‹" class="headerlink" title="(é€‰ä¿®)æ·±åº¦å­¦ä¹ ç®€ä»‹"></a>(é€‰ä¿®)æ·±åº¦å­¦ä¹ ç®€ä»‹</h2><h3 id="Deep-Learningçš„å‘å±•å†ç¨‹"><a href="#Deep-Learningçš„å‘å±•å†ç¨‹" class="headerlink" title="Deep Learningçš„å‘å±•å†ç¨‹"></a>Deep Learningçš„å‘å±•å†ç¨‹</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/12_dl.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Deep-Learningçš„ä¸‰ä¸ªæ­¥éª¤"><a href="#Deep-Learningçš„ä¸‰ä¸ªæ­¥éª¤" class="headerlink" title="Deep Learningçš„ä¸‰ä¸ªæ­¥éª¤"></a>Deep Learningçš„ä¸‰ä¸ªæ­¥éª¤</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/13_dl.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Full-Connect-Feedforward-Network-å…¨è¿æ¥å‰é¦ˆç¥ç»ç½‘ç»œ"><a href="#Full-Connect-Feedforward-Network-å…¨è¿æ¥å‰é¦ˆç¥ç»ç½‘ç»œ" class="headerlink" title="Full Connect Feedforward Network/å…¨è¿æ¥å‰é¦ˆç¥ç»ç½‘ç»œ"></a>Full Connect Feedforward Network/å…¨è¿æ¥å‰é¦ˆç¥ç»ç½‘ç»œ</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/14_dl.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Matrix-Operation-çŸ©é˜µè¿ç®—"><a href="#Matrix-Operation-çŸ©é˜µè¿ç®—" class="headerlink" title="Matrix Operation/çŸ©é˜µè¿ç®—"></a>Matrix Operation/çŸ©é˜µè¿ç®—</h3><p>å‚æ•°çŸ©é˜µï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/15_dl.jpg?raw=true" width="400" alt="" align="center" /><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/16_dl.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Output-Layer"><a href="#Output-Layer" class="headerlink" title="Output Layer"></a>Output Layer</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/17_dl.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Example-Application"><a href="#Example-Application" class="headerlink" title="Example Application"></a>Example Application</h3><p>æ‰‹å†™è¯†åˆ«æ¡ˆä¾‹ï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/18_dl.jpg?raw=true" width="400" alt="" align="center" /><p>You need to decide the network structure to let a good function in your function set.</p><h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>è®¡ç®—æŸå¤±å‡½æ•°ï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/19_dl.jpg?raw=true" width="400" alt="" align="center" /><p>æ‰¾ä¸€ä¸ªæœ€å°åŒ–æŸå¤±å‡½æ•°çš„å‡½æ•°ï¼Œå³æ‰¾ä¸€ç»„å‚æ•°å¯ä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/leeml/20_dl.jpg?raw=true" width="400" alt="" align="center" /><h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><p>å¦‚ä½•å¯»æ‰¾è¿™æ ·çš„å‚æ•°ï¼Ÿâ€”â€”æ¢¯åº¦ä¸‹é™ã€‚</p><h3 id="Backpropagation-åå‘ä¼ æ’­"><a href="#Backpropagation-åå‘ä¼ æ’­" class="headerlink" title="Backpropagation/åå‘ä¼ æ’­"></a>Backpropagation/åå‘ä¼ æ’­</h3><p>å¦‚ä½•è®¡ç®—æ¢¯åº¦ï¼Ÿâ€”â€”åå‘ä¼ æ’­ç®—æ³•ã€‚</p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ <a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=2">https://www.bilibili.com/video/BV1Wv411h7kN?p=2</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;å‰è¨€&quot;&gt;&lt;a href=&quot;#å‰è¨€&quot; class=&quot;headerlink&quot; title=&quot;å‰è¨€&quot;&gt;&lt;/a&gt;å‰è¨€&lt;/h1&gt;&lt;p&gt;æœ¬æ–‡å­¦ä¹ çš„è¯¾ç¨‹æ˜¯ï¼šæå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ Lecture01 æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç®€ä»‹ &lt;a href=&quot;https://www.bil</summary>
      
    
    
    
    <category term="02 äººå·¥æ™ºèƒ½" scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="æå®æ¯…æœºå™¨å­¦ä¹ " scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="machine learning" scheme="http://example.com/tags/machine-learning/"/>
    
    <category term="regression" scheme="http://example.com/tags/regression/"/>
    
  </entry>
  
  <entry>
    <title>Summary Transformerè¯¾ç¨‹æ€»ç»“</title>
    <link href="http://example.com/nlp-transformer-summary/"/>
    <id>http://example.com/nlp-transformer-summary/</id>
    <published>2021-09-30T07:44:01.000Z</published>
    <updated>2021-10-15T07:00:47.781Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æˆ‘çš„èƒŒæ™¯"><a href="#æˆ‘çš„èƒŒæ™¯" class="headerlink" title="æˆ‘çš„èƒŒæ™¯"></a>æˆ‘çš„èƒŒæ™¯</h1><p>ç¬¬ä¸€æ¬¡å‚åŠ Datawhaleç»„é˜Ÿå­¦ä¹ è¯¾ç¨‹ï¼Œæˆ‘çš„ç›¸å…³çŸ¥è¯†èƒŒæ™¯æ˜¯ï¼š</p><ul><li>Transformerï¼š0åŸºç¡€</li><li>PyTorchï¼š0åŸºç¡€</li><li>NLPï¼š0.1åŸºç¡€</li><li>Pythonï¼š0åŸºç¡€</li></ul><p>ä½œä¸ºNLPæƒ…æ„Ÿåˆ†æçš„é¢†èˆªå‘˜å’ŒTransformersçš„å­¦å‘˜ï¼Œæˆ‘å°†ä»è¯¾ç¨‹å†…å®¹å’Œè¿è¥ä¸¤æ–¹é¢å†™ä¸€ä¸‹è‡ªå·±çš„æ„Ÿå—å’Œæƒ³æ³•ã€‚</p><h1 id="Transformerè¯¾ç¨‹å¤§çº²"><a href="#Transformerè¯¾ç¨‹å¤§çº²" class="headerlink" title="Transformerè¯¾ç¨‹å¤§çº²"></a>Transformerè¯¾ç¨‹å¤§çº²</h1><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/transformer_xmind.png?raw=true" width="800" alt="åŸºäºTransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†" align="center" /><h1 id="è¯¾ç¨‹å†…å®¹æ–¹é¢"><a href="#è¯¾ç¨‹å†…å®¹æ–¹é¢" class="headerlink" title="è¯¾ç¨‹å†…å®¹æ–¹é¢"></a>è¯¾ç¨‹å†…å®¹æ–¹é¢</h1><ul><li>è¯¾ç¨‹å†…å®¹å¯¹é›¶åŸºç¡€å…¥é—¨çš„äººæ˜¯æ¯”è¾ƒå‹å¥½çš„ã€‚æ¯”å¦‚æˆ‘æ˜¯ç¬¬ä¸€æ¬¡å­¦ä¹ Transformerï¼Œä½†æ˜¯å›¾è§£ç³»åˆ—å¾ˆå®¹æ˜“ç†è§£ã€‚</li><li>ä½†æ˜¯æ¯ä¸ªtaskçš„å†…å®¹éš¾åº¦å·®åˆ«è¿‡å¤§ã€‚æ¯”å¦‚Task02çš„TransformeråŸè®ºæ–‡ä»£ç æ ‡æ³¨ ï¼Œå’ŒTask05 transformersæºç è®²è§£ã€‚</li><li>æ¯ä¸ªtaskçš„å·¥ä½œé‡ä¸å¹³è¡¡ï¼Œæœ‰çš„ç‰¹åˆ«å¤šï¼Œæœ‰çš„ç›¸å¯¹å°‘ã€‚</li><li>ç¬¬å››ç« å¯ä»¥ä»»é€‰ä¸€ä¸ªä»»åŠ¡åº”ç”¨ï¼ŒæŠŠæ›´å¤šæ—¶é—´ç•™ç»™å­¦ä¹ å¦‚ä½•ä½¿ç”¨huggingfaceçš„transformersã€‚ï¼ˆå°±æ˜¯é‚£ä¸ªå®˜æ–¹è¯¾ç¨‹ï¼‰</li></ul><h1 id="è¯¾ç¨‹è¿è¥æ–¹é¢"><a href="#è¯¾ç¨‹è¿è¥æ–¹é¢" class="headerlink" title="è¯¾ç¨‹è¿è¥æ–¹é¢"></a>è¯¾ç¨‹è¿è¥æ–¹é¢</h1><ul><li>ä¼˜ç§€é˜Ÿå‘˜å’Œä¼˜ç§€é˜Ÿé•¿è¯„é€‰æ ‡å‡†éœ€è¦ç»Ÿä¸€</li><li>è¡¥å¡è§„åˆ™éœ€è¦ç»Ÿä¸€</li><li>é€æ­¥å®Œå–„è¯¾ç¨‹ä½“ç³»</li><li>å°ç¨‹åºï¼Œç”¨èµ·æ¥ä¸æ˜¯å¾ˆæ–¹ä¾¿</li><li>ï¼ˆè„‘æ´1ï¼‰æ¯æ¬¡æ‰“å¡ä¹‹åé©¬ä¸Šè¿›è¡Œä½œä¸šè¯„å®¡å’Œåé¦ˆï¼ˆè¿‡äºè€—è´¹åŠ©æ•™ç²¾åŠ›ï¼‰</li><li>ï¼ˆè„‘æ´2ï¼‰ç»™æ¯ä¸ªå°ç»„æˆ–ä¸ªäººå®‰æ’ä¸€ä¸ªæœŸæœ«å¤§projectï¼Œæˆ–è€…å¸ƒç½®å¹³æ—¶ä½œä¸šï¼ˆè¿‡äºè€—è´¹å­¦å‘˜ç²¾åŠ›ï¼‰</li><li>ï¼ˆè„‘æ´3ï¼‰ç›´æ¥ç”¨ä¸€ä¸ªè¯¾ç¨‹ç®¡ç†ç³»ç»Ÿè¿›è¡Œç®¡ç†ï¼ˆç±»ä¼¼äºcanvas,é›¨è¯¾å ‚ï¼‰(é€æ¸å­¦é™¢åŒ–)</li></ul><h1 id="å‚è€ƒèµ„æ–™æ¸…å•ï¼ˆæ€»ï¼‰"><a href="#å‚è€ƒèµ„æ–™æ¸…å•ï¼ˆæ€»ï¼‰" class="headerlink" title="å‚è€ƒèµ„æ–™æ¸…å•ï¼ˆæ€»ï¼‰"></a>å‚è€ƒèµ„æ–™æ¸…å•ï¼ˆæ€»ï¼‰</h1><p>Transformeråœ¨ç½‘ä¸Šæœ‰å¾ˆå¤šå¾ˆå¤šæ•™ç¨‹ï¼Œå…¶ä¸­å…¬è®¤çš„ã€æ™®éæ€§çš„æ¯”è¾ƒå¥½çš„èµ„æ–™å¦‚ä¸‹ï¼š</p><p><strong>ç†è®ºéƒ¨åˆ†</strong><br>[1] (å¼ºæ¨)æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ <a href="https://www.bilibili.com/video/BV1Wv411h7kN?from=search&seid=17090062977285779802&spm_id_from=333.337.0.0">https://www.bilibili.com/video/BV1Wv411h7kN?from=search&amp;seid=17090062977285779802&amp;spm_id_from=333.337.0.0</a><br>[2] <strong>åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨ï¼ˆæ¶µç›–äº†å›¾è§£ç³»åˆ—ã€annotated transformerã€huggingfaceï¼‰</strong> <a href="https://github.com/datawhalechina/learn-nlp-with-transformers">https://github.com/datawhalechina/learn-nlp-with-transformers</a><br>[3] å›¾è§£transformer|The Illustrated Transformer <a href="http://jalammar.github.io/illustrated-transformer/">http://jalammar.github.io/illustrated-transformer/</a><br>[4] å›¾è§£seq2seq, attention|Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/</a></p><p><strong>ä»£ç éƒ¨åˆ†</strong><br>[5] The Annotated Transformer <a href="http://nlp.seas.harvard.edu//2018/04/03/attention.html">http://nlp.seas.harvard.edu//2018/04/03/attention.html</a><br>[6] Huggingface/transformers <a href="https://github.com/huggingface/transformers/blob/master/README_zh-hans.md">https://github.com/huggingface/transformers/blob/master/README_zh-hans.md</a></p><p><strong>è®ºæ–‡éƒ¨åˆ†</strong><br>Attention is all â€œweâ€ need.</p><p><strong>å…¶ä»–ä¸é”™çš„åšå®¢æˆ–æ•™ç¨‹</strong><br>[7] åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨â€“åœ¨çº¿é˜…è¯» <a href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a><br>[8] æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ç¬”è®°â€”â€”è‡ªæ³¨æ„åŠ›æœºåˆ¶ <a href="https://www.cnblogs.com/sykline/p/14730088.html">https://www.cnblogs.com/sykline/p/14730088.html</a><br>[9] æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ç¬”è®°â€”â€”Transformeræ¨¡å‹ <a href="https://www.cnblogs.com/sykline/p/14785552.html">https://www.cnblogs.com/sykline/p/14785552.html</a><br>[10] æå®æ¯…æœºå™¨å­¦ä¹ å­¦ä¹ ç¬”è®°â€”â€”è‡ªæ³¨æ„åŠ›æœºåˆ¶ <a href="https://blog.csdn.net/p_memory/article/details/116271274">https://blog.csdn.net/p_memory/article/details/116271274</a><br>[11] è½¦ä¸‡ç¿”-è‡ªç„¶è¯­è¨€å¤„ç†æ–°èŒƒå¼ï¼šåŸºäºé¢„è®­ç»ƒçš„æ–¹æ³•ã€è®²åº§+PPTã€‘ <a href="https://app6ca5octe2206.pc.xiaoe-tech.com/detail/v_611f48f3e4b02ac39d12246f/3?fromH5=true">https://app6ca5octe2206.pc.xiaoe-tech.com/detail/v_611f48f3e4b02ac39d12246f/3?fromH5=true</a><br>[12] è‹å‰‘æ—-ã€ŠAttention is All You Needã€‹æµ…è¯»ï¼ˆç®€ä»‹+ä»£ç ï¼‰<a href="https://spaces.ac.cn/archives/4765">https://spaces.ac.cn/archives/4765</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;æˆ‘çš„èƒŒæ™¯&quot;&gt;&lt;a href=&quot;#æˆ‘çš„èƒŒæ™¯&quot; class=&quot;headerlink&quot; title=&quot;æˆ‘çš„èƒŒæ™¯&quot;&gt;&lt;/a&gt;æˆ‘çš„èƒŒæ™¯&lt;/h1&gt;&lt;p&gt;ç¬¬ä¸€æ¬¡å‚åŠ Datawhaleç»„é˜Ÿå­¦ä¹ è¯¾ç¨‹ï¼Œæˆ‘çš„ç›¸å…³çŸ¥è¯†èƒŒæ™¯æ˜¯ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformerï¼š0åŸºç¡€&lt;/</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬29æœŸ åŸºäºtransformerçš„NLP" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/"/>
    
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="é¢„è®­ç»ƒæ¨¡å‹" scheme="http://example.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="transfomer" scheme="http://example.com/tags/transfomer/"/>
    
    <category term="æ€»ç»“" scheme="http://example.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Chapter03 PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—</title>
    <link href="http://example.com/pytorch-chap03/"/>
    <id>http://example.com/pytorch-chap03/</id>
    <published>2021-09-28T01:31:42.000Z</published>
    <updated>2021-10-14T10:04:01.506Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¬¬ä¸‰ç« -PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—"><a href="#ç¬¬ä¸‰ç« -PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—" class="headerlink" title="ç¬¬ä¸‰ç«  PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—"></a>ç¬¬ä¸‰ç«  PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—</h1><h2 id="å®Œæˆæ·±åº¦å­¦ä¹ çš„å¿…è¦éƒ¨åˆ†"><a href="#å®Œæˆæ·±åº¦å­¦ä¹ çš„å¿…è¦éƒ¨åˆ†" class="headerlink" title="å®Œæˆæ·±åº¦å­¦ä¹ çš„å¿…è¦éƒ¨åˆ†"></a>å®Œæˆæ·±åº¦å­¦ä¹ çš„å¿…è¦éƒ¨åˆ†</h2><p>æœºå™¨å­¦ä¹ ï¼š</p><ol><li>æ•°æ®é¢„å¤„ç†ï¼ˆæ•°æ®æ ¼å¼ã€æ•°æ®è½¬æ¢ã€åˆ’åˆ†æ•°æ®é›†ï¼‰</li><li>é€‰æ‹©æ¨¡å‹ï¼Œè®¾å®šæŸå¤±å’Œä¼˜åŒ–å‡½æ•°ï¼Œè®¾ç½®è¶…å‚æ•°</li><li>è®­ç»ƒæ¨¡å‹ï¼Œæ‹Ÿåˆè®­ç»ƒé›†</li><li>è¯„ä¼°æ¨¡å‹ï¼Œåœ¨å¹¶åœ¨éªŒè¯é›†/æµ‹è¯•é›†ä¸Šè®¡ç®—æ¨¡å‹è¡¨ç°</li></ol><p>æ·±åº¦å­¦ä¹ çš„æ³¨æ„äº‹é¡¹ï¼š</p><ol><li>æ•°æ®é¢„å¤„ç†ï¼ˆæ•°æ®åŠ è½½ã€æ‰¹å¤„ç†ï¼‰</li><li>é€å±‚æ­å»ºæ¨¡å‹ï¼Œç»„è£…ä¸åŒæ¨¡å—</li><li>GPUçš„é…ç½®å’Œæ“ä½œ</li></ol><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/11_dnn.jpg?raw=true" width="600" alt="" align="center" /><h2 id="åŸºæœ¬é…ç½®"><a href="#åŸºæœ¬é…ç½®" class="headerlink" title="åŸºæœ¬é…ç½®"></a>åŸºæœ¬é…ç½®</h2><p>å¯¼å…¥å¿…é¡»çš„åŒ…ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optimizer</span><br></pre></td></tr></table></figure><p>è¶…å‚æ•°è®¾ç½®ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">16</span>  <span class="comment"># batch size</span></span><br><span class="line">lr = <span class="number">1e-4</span>  <span class="comment"># åˆå§‹å­¦ä¹ ç‡</span></span><br><span class="line">max_epochs = <span class="number">100</span>  <span class="comment"># è®­ç»ƒæ¬¡æ•° </span></span><br></pre></td></tr></table></figure><p>GPUçš„è®¾ç½®ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨os.environï¼Œè¿™ç§æƒ…å†µå¦‚æœä½¿ç”¨GPUä¸éœ€è¦è®¾ç½®</span></span><br><span class="line">os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="string">&#x27;0,1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ–¹æ¡ˆäºŒï¼šä½¿ç”¨â€œdeviceâ€ï¼Œåç»­å¯¹è¦ä½¿ç”¨GPUçš„å˜é‡ç”¨.to(device)å³å¯</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:1&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="æ•°æ®åŠ è½½å’Œå¤„ç†"><a href="#æ•°æ®åŠ è½½å’Œå¤„ç†" class="headerlink" title="æ•°æ®åŠ è½½å’Œå¤„ç†"></a>æ•°æ®åŠ è½½å’Œå¤„ç†</h2><p>PyTorchæ•°æ®è¯»å…¥æ˜¯é€šè¿‡Dataset+Dataloaderçš„æ–¹å¼å®Œæˆçš„ï¼ŒDatasetå®šä¹‰å¥½æ•°æ®çš„æ ¼å¼å’Œæ•°æ®å˜æ¢å½¢å¼ï¼ŒDataloaderç”¨iterativeçš„æ–¹å¼ä¸æ–­è¯»å…¥æ‰¹æ¬¡æ•°æ®ã€‚</p><p>æˆ‘ä»¬å¯ä»¥å®šä¹‰è‡ªå·±çš„Datasetç±»æ¥å®ç°çµæ´»çš„æ•°æ®è¯»å–ï¼Œå®šä¹‰çš„ç±»éœ€è¦ç»§æ‰¿PyTorchè‡ªèº«çš„Datasetç±»ã€‚ä¸»è¦åŒ…å«ä¸‰ä¸ªå‡½æ•°ï¼š</p><ul><li><code>__init__</code>: ç”¨äºå‘ç±»ä¸­ä¼ å…¥å¤–éƒ¨å‚æ•°ï¼ŒåŒæ—¶å®šä¹‰æ ·æœ¬é›†</li><li><code>__getitem__</code>: ç”¨äºé€ä¸ªè¯»å–æ ·æœ¬é›†åˆä¸­çš„å…ƒç´ ï¼Œå¯ä»¥è¿›è¡Œä¸€å®šçš„å˜æ¢ï¼Œå¹¶å°†è¿”å›è®­ç»ƒ/éªŒè¯æ‰€éœ€çš„æ•°æ®</li><li><code>__len__</code>: ç”¨äºè¿”å›æ•°æ®é›†çš„æ ·æœ¬æ•°</li></ul><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/12_dataset.jpg?raw=true" width="600" alt="" align="center" /><ul><li>batch_sizeï¼šæ ·æœ¬æ˜¯æŒ‰â€œæ‰¹â€è¯»å…¥çš„ï¼Œbatch_sizeå°±æ˜¯æ¯æ¬¡è¯»å…¥çš„æ ·æœ¬æ•°</li><li>num_workersï¼šæœ‰å¤šå°‘ä¸ªè¿›ç¨‹ç”¨äºè¯»å–æ•°æ®</li><li>shuffleï¼šæ˜¯å¦å°†è¯»å…¥çš„æ•°æ®æ‰“ä¹±</li><li>drop_lastï¼šå¯¹äºæ ·æœ¬æœ€åä¸€éƒ¨åˆ†æ²¡æœ‰è¾¾åˆ°æ‰¹æ¬¡æ•°çš„æ ·æœ¬ï¼Œä¸å†å‚ä¸è®­ç»ƒ</li></ul><p>ä¸‹é¢æ˜¯æœ¬éƒ¨åˆ†ä»£ç åœ¨notebookä¸­çš„è¿è¡Œæƒ…å†µã€‚ä¸»è¦å‚è€ƒ PyTorchå®˜æ–¹æ•™ç¨‹ä¸­æ–‡ç‰ˆ <a href="https://pytorch123.com/SecondSection/training_a_classifier/">https://pytorch123.com/SecondSection/training_a_classifier/</a></p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/chap03.jpg?raw=true" width="" alt="" align="center" /><h2 id="æ¨¡å‹æ„å»º"><a href="#æ¨¡å‹æ„å»º" class="headerlink" title="æ¨¡å‹æ„å»º"></a>æ¨¡å‹æ„å»º</h2><h3 id="ç¥ç»ç½‘ç»œçš„æ„é€ "><a href="#ç¥ç»ç½‘ç»œçš„æ„é€ " class="headerlink" title="ç¥ç»ç½‘ç»œçš„æ„é€ "></a>ç¥ç»ç½‘ç»œçš„æ„é€ </h3><p>PyTorchä¸­ç¥ç»ç½‘ç»œæ„é€ ä¸€èˆ¬æ˜¯åŸºäº Module ç±»çš„æ¨¡å‹æ¥å®Œæˆçš„ã€‚Module ç±»æ˜¯ nn æ¨¡å—ï§©æä¾›çš„ä¸€ä¸ªæ¨¡å‹æ„é€ ç±»ï¼Œæ˜¯æ‰€æœ‰ç¥ç»â½¹ç½‘ç»œæ¨¡å—çš„åŸºç±»ï¼Œæˆ‘ä»¬å¯ä»¥ç»§æ‰¿å®ƒæ¥å®šä¹‰æˆ‘ä»¬æƒ³è¦çš„æ¨¡å‹ã€‚ä¸‹é¢ç»§æ‰¿ Module ç±»æ„é€ å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="comment"># å£°æ˜å¸¦æœ‰æ¨¡å‹å‚æ•°çš„å±‚ï¼Œè¿™é‡Œå£°æ˜äº†ä¸¤ä¸ªå…¨è¿æ¥å±‚</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">    <span class="comment"># è°ƒç”¨MLPçˆ¶ç±»Blockçš„æ„é€ å‡½æ•°æ¥è¿›è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚è¿™æ ·åœ¨æ„é€ å®ä¾‹ä¾‹æ—¶è¿˜å¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°</span></span><br><span class="line">    <span class="built_in">super</span>(MLP, self).__init__(**kwargs)</span><br><span class="line">    self.hidden = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">    self.act = nn.ReLU()</span><br><span class="line">    self.output = nn.Linear(<span class="number">256</span>,<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">   <span class="comment"># å®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥xè®¡ç®—è¿”å›æ‰€éœ€è¦çš„æ¨¡å‹è¾“å‡º</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    o = self.act(self.hidden(x))</span><br><span class="line">    <span class="keyword">return</span> self.output(o)</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥å®ä¾‹åŒ– MLP ç±»å¾—åˆ°æ¨¡å‹å˜ï¥¾ net ã€‚ä¸‹â¾¯çš„ä»£ç åˆå§‹åŒ– net å¹¶ä¼ å…¥è¾“â¼Šæ•°æ® X åšä¸€æ¬¡å‰å‘è®¡ç®—ã€‚å…¶ä¸­ï¼Œ net(X) ä¼šè°ƒç”¨ MLP ç»§æ‰¿â¾ƒè‡ª Module ç±»çš„ <strong>call</strong> å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°å°†è°ƒâ½¤ç”¨ MLP ç±»å®šä¹‰çš„forward å‡½æ•°æ¥å®Œæˆå‰å‘è®¡ç®—ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = torch.rand(<span class="number">2</span>, <span class="number">784</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X</span><br><span class="line">tensor([[<span class="number">0.3277</span>, <span class="number">0.2204</span>, <span class="number">0.5239</span>,  ..., <span class="number">0.4333</span>, <span class="number">0.1906</span>, <span class="number">0.1318</span>],</span><br><span class="line">        [<span class="number">0.9850</span>, <span class="number">0.2121</span>, <span class="number">0.8405</span>,  ..., <span class="number">0.3796</span>, <span class="number">0.2717</span>, <span class="number">0.5553</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"><span class="meta">... </span>  <span class="comment"># å£°æ˜å¸¦æœ‰æ¨¡å‹å‚æ•°çš„å±‚ï¼Œè¿™é‡Œå£°æ˜äº†ä¸¤ä¸ªå…¨è¿æ¥å±‚</span></span><br><span class="line"><span class="meta">... </span>  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line"><span class="meta">... </span>    <span class="comment"># è°ƒç”¨MLPçˆ¶ç±»Blockçš„æ„é€ å‡½æ•°æ¥è¿›è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚è¿™æ ·åœ¨æ„é€ å®ä¾‹ä¾‹æ—¶è¿˜å¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">super</span>(MLP, self).__init__(**kwargs)</span><br><span class="line"><span class="meta">... </span>    self.hidden = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line"><span class="meta">... </span>    self.act = nn.ReLU()</span><br><span class="line"><span class="meta">... </span>    self.output = nn.Linear(<span class="number">256</span>,<span class="number">10</span>)</span><br><span class="line"><span class="meta">... </span>    </span><br><span class="line"><span class="meta">... </span>   <span class="comment"># å®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥xè®¡ç®—è¿”å›æ‰€éœ€è¦çš„æ¨¡å‹è¾“å‡º</span></span><br><span class="line"><span class="meta">... </span>  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line"><span class="meta">... </span>    o = self.act(self.hidden(x))</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> self.output(o)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = MLP()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net</span><br><span class="line">MLP(</span><br><span class="line">  (hidden): Linear(in_features=<span class="number">784</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (act): ReLU()</span><br><span class="line">  (output): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net(X)</span><br><span class="line">tensor([[ <span class="number">0.1317</span>,  <span class="number">0.0702</span>,  <span class="number">0.1707</span>, -<span class="number">0.0081</span>, -<span class="number">0.2730</span>,  <span class="number">0.2837</span>,  <span class="number">0.0700</span>,  <span class="number">0.1718</span>,</span><br><span class="line">          <span class="number">0.0299</span>,  <span class="number">0.2082</span>],</span><br><span class="line">        [ <span class="number">0.1094</span>,  <span class="number">0.0936</span>,  <span class="number">0.2474</span>, -<span class="number">0.0139</span>, -<span class="number">0.1861</span>,  <span class="number">0.1846</span>,  <span class="number">0.1658</span>,  <span class="number">0.2051</span>,</span><br><span class="line">          <span class="number">0.2609</span>,  <span class="number">0.2227</span>]], grad_fn=&lt;AddmmBackward&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br></pre></td></tr></table></figure><h3 id="ç¥ç»ç½‘ç»œä¸­å¸¸è§çš„å±‚"><a href="#ç¥ç»ç½‘ç»œä¸­å¸¸è§çš„å±‚" class="headerlink" title="ç¥ç»ç½‘ç»œä¸­å¸¸è§çš„å±‚"></a>ç¥ç»ç½‘ç»œä¸­å¸¸è§çš„å±‚</h3><h4 id="ä¸å«æ¨¡å‹å‚æ•°çš„å±‚"><a href="#ä¸å«æ¨¡å‹å‚æ•°çš„å±‚" class="headerlink" title="ä¸å«æ¨¡å‹å‚æ•°çš„å±‚"></a>ä¸å«æ¨¡å‹å‚æ•°çš„å±‚</h4><p>ä¸‹â¾¯æ„é€ çš„ MyLayer ç±»é€šè¿‡ç»§æ‰¿ Module ç±»è‡ªå®šä¹‰ï¦ºä¸€ä¸ª<strong>å°†è¾“å…¥å‡æ‰å‡å€¼åè¾“å‡º</strong>çš„å±‚ã€‚è¿™ä¸ªå±‚ï§©ï¥§å«æ¨¡å‹å‚æ•°ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">MyLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line"><span class="meta">... </span>        <span class="built_in">super</span>(MyLayer, self).__init__(**kwargs)</span><br><span class="line"><span class="meta">... </span>    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> x - x.mean()  </span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>layer = MyLayer()  <span class="comment"># å®ä¾‹åŒ–è¯¥å±‚</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>layer</span><br><span class="line">MyLayer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>layer(torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], dtype=torch.<span class="built_in">float</span>))</span><br><span class="line">tensor([-<span class="number">2.</span>, -<span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br></pre></td></tr></table></figure><h4 id="å«æ¨¡å‹å‚æ•°çš„å±‚"><a href="#å«æ¨¡å‹å‚æ•°çš„å±‚" class="headerlink" title="å«æ¨¡å‹å‚æ•°çš„å±‚"></a>å«æ¨¡å‹å‚æ•°çš„å±‚</h4><p>æˆ‘ä»¬è¿˜å¯ä»¥è‡ªå®šä¹‰å«æ¨¡å‹å‚æ•°çš„è‡ªå®šä¹‰å±‚ã€‚å…¶ä¸­çš„æ¨¡å‹å‚æ•°å¯ä»¥é€šè¿‡è®­ç»ƒå­¦å‡ºã€‚</p><p>Parameter ç±»å…¶å®æ˜¯ Tensor çš„å­ç±»ï¼Œå¦‚æœä¸€ ä¸ª Tensor æ˜¯ Parameter ï¼Œé‚£ä¹ˆå®ƒä¼šâ¾ƒåŠ¨è¢«æ·»åŠ åˆ°æ¨¡å‹çš„å‚æ•°ï¦œè¡¨ï§©ã€‚æ‰€ä»¥åœ¨â¾ƒå®šä¹‰å«æ¨¡å‹å‚æ•°çš„å±‚æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥å°†å‚æ•°å®šä¹‰æˆ Parameter ï¼Œé™¤äº†ç›´æ¥å®šä¹‰æˆ Parameter ç±»å¤–ï¼Œè¿˜å¯ä»¥ä½¿â½¤ ParameterList å’Œ ParameterDict åˆ†åˆ«å®šä¹‰å‚æ•°çš„ï¦œè¡¨å’Œå­—å…¸ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyListDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyListDense, self).__init__()</span><br><span class="line">        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line">        self.params.append(nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.params)):</span><br><span class="line">            x = torch.mm(x, self.params[i])</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">      </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = MyListDense()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(net)</span><br><span class="line">MyListDense(</span><br><span class="line">  (params): ParameterList(</span><br><span class="line">      (<span class="number">0</span>): Parameter containing: [torch.FloatTensor of size 4x4]</span><br><span class="line">      (<span class="number">1</span>): Parameter containing: [torch.FloatTensor of size 4x4]</span><br><span class="line">      (<span class="number">2</span>): Parameter containing: [torch.FloatTensor of size 4x4]</span><br><span class="line">      (<span class="number">3</span>): Parameter containing: [torch.FloatTensor of size 4x1]</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDictDense</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyDictDense, self).__init__()</span><br><span class="line">        self.params = nn.ParameterDict(&#123;</span><br><span class="line">                <span class="string">&#x27;linear1&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">4</span>)),</span><br><span class="line">                <span class="string">&#x27;linear2&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">        &#125;)</span><br><span class="line">        self.params.update(&#123;<span class="string">&#x27;linear3&#x27;</span>: nn.Parameter(torch.randn(<span class="number">4</span>, <span class="number">2</span>))&#125;) <span class="comment"># æ–°å¢</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, choice=<span class="string">&#x27;linear1&#x27;</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.mm(x, self.params[choice])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = MyDictDense()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(net)</span><br><span class="line">MyDictDense(</span><br><span class="line">  (params): ParameterDict(</span><br><span class="line">      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]</span><br><span class="line">      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]</span><br><span class="line">      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>ä¸‹é¢ç»™å‡ºå¸¸è§çš„ç¥ç»ç½‘ç»œçš„ä¸€äº›å±‚ï¼Œæ¯”å¦‚å·ç§¯å±‚ã€æ± åŒ–å±‚ï¼Œä»¥åŠè¾ƒä¸ºåŸºç¡€çš„AlexNetï¼ŒLeNetç­‰ã€‚</p><h4 id="äºŒç»´å·ç§¯å±‚"><a href="#äºŒç»´å·ç§¯å±‚" class="headerlink" title="äºŒç»´å·ç§¯å±‚"></a>äºŒç»´å·ç§¯å±‚</h4><p>äºŒç»´å·ç§¯å±‚å°†è¾“å…¥å’Œå·ç§¯æ ¸åšäº’ç›¸å…³è¿ç®—ï¼Œå¹¶åŠ ä¸Šä¸€ä¸ªæ ‡ï¥¾åå·®æ¥å¾—åˆ°è¾“å‡ºã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># å·ç§¯è¿ç®—ï¼ˆäºŒç»´äº’ç›¸å…³ï¼‰</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span>(<span class="params">X, K</span>):</span> </span><br><span class="line">    h, w = K.shape</span><br><span class="line">    X, K = X.<span class="built_in">float</span>(), K.<span class="built_in">float</span>()</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i: i + h, j: j + w] * K).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"><span class="comment"># äºŒç»´å·ç§¯å±‚</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv2D</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Conv2D, self).__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(kernel_size))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> corr2d(x, self.weight) + self.bias</span><br></pre></td></tr></table></figure><p>å¡«å……(padding)æ˜¯æŒ‡åœ¨è¾“â¼Šå…¥â¾¼é«˜å’Œå®½çš„ä¸¤ä¾§å¡«å……å…ƒç´ (é€šå¸¸æ˜¯0å…ƒç´ )ã€‚</p><p>åœ¨äºŒç»´äº’ç›¸å…³è¿ç®—ä¸­ï¼Œå·ç§¯çª—å£ä»è¾“å…¥æ•°ç»„çš„æœ€å·¦ä¸Šæ–¹å¼€å§‹ï¼ŒæŒ‰ä»å·¦å¾€å³ã€ä»ä¸Šå¾€ä¸‹ çš„é¡ºåºï¼Œä¾æ¬¡åœ¨è¾“â¼Šæ•°ç»„ä¸Šæ»‘åŠ¨ã€‚æˆ‘ä»¬å°†æ¯æ¬¡æ»‘åŠ¨çš„ï¨ˆæ•°å’Œï¦œæ•°ç§°ä¸ºæ­¥å¹…(stride)ã€‚</p><p>ï¼ˆskipï¼‰</p><h4 id="æ± åŒ–å±‚"><a href="#æ± åŒ–å±‚" class="headerlink" title="æ± åŒ–å±‚"></a>æ± åŒ–å±‚</h4><p>æ± åŒ–å±‚æ¯æ¬¡å¯¹è¾“å…¥æ•°æ®çš„ä¸€ä¸ªå›ºå®šå½¢çŠ¶çª—å£(â¼œç§°æ± åŒ–çª—å£)ä¸­çš„å…ƒç´ è®¡ç®—è¾“å‡ºã€‚ï¥§åŒäºå·ç§¯å±‚ï§©è®¡ç®—è¾“â¼Šå’Œæ ¸çš„äº’ç›¸å…³æ€§ï¼Œæ± åŒ–å±‚ç›´æ¥è®¡ç®—æ± åŒ–çª—å£å†…å…ƒç´ çš„æœ€å¤§å€¼æˆ–è€…å¹³å‡å€¼ã€‚è¯¥è¿ç®—ä¹Ÿ åˆ†åˆ«å«åšæœ€å¤§æ± åŒ–æˆ–å¹³å‡æ± åŒ–ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span></span><br><span class="line"><span class="meta">... </span>    p_h, p_w = pool_size</span><br><span class="line"><span class="meta">... </span>    Y = np.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line"><span class="meta">... </span>            <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line"><span class="meta">... </span>                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="built_in">max</span>()</span><br><span class="line"><span class="meta">... </span>            <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line"><span class="meta">... </span>                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> Y</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pool2d(X, (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">array([[<span class="number">4.</span>, <span class="number">5.</span>],</span><br><span class="line">       [<span class="number">7.</span>, <span class="number">8.</span>]])</span><br></pre></td></tr></table></figure><h4 id="æ¨¡å‹ç¤ºä¾‹ï¼šLeNet"><a href="#æ¨¡å‹ç¤ºä¾‹ï¼šLeNet" class="headerlink" title="æ¨¡å‹ç¤ºä¾‹ï¼šLeNet"></a>æ¨¡å‹ç¤ºä¾‹ï¼šLeNet</h4><p>ï¼ˆå¾…è¡¥å……ï¼‰</p><h4 id="æ¨¡å‹ç¤ºä¾‹ï¼šAlexNet"><a href="#æ¨¡å‹ç¤ºä¾‹ï¼šAlexNet" class="headerlink" title="æ¨¡å‹ç¤ºä¾‹ï¼šAlexNet"></a>æ¨¡å‹ç¤ºä¾‹ï¼šAlexNet</h4><p>ï¼ˆå¾…è¡¥å……ï¼‰</p><h2 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h2><p>ä¸€ä¸ªå¥½çš„è®­ç»ƒç¦»ä¸å¼€ä¼˜è´¨çš„è´Ÿåé¦ˆï¼Œè¿™é‡Œçš„æŸå¤±å‡½æ•°å°±æ˜¯æ¨¡å‹çš„è´Ÿåé¦ˆã€‚</p><p>è¿™é‡Œå°†åˆ—å‡ºPyTorchä¸­å¸¸ç”¨çš„æŸå¤±å‡½æ•°ï¼ˆä¸€èˆ¬é€šè¿‡torch.nnè°ƒç”¨ï¼‰ï¼Œå¹¶è¯¦ç»†ä»‹ç»æ¯ä¸ªæŸå¤±å‡½æ•°çš„åŠŸèƒ½ä»‹ç»ã€æ•°å­¦å…¬å¼å’Œè°ƒç”¨ä»£ç ã€‚</p><h3 id="äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°"><a href="#äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°" class="headerlink" title="äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°"></a>äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°</h3><p><code>torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction=&#39;mean&#39;)</code></p><p><strong>åŠŸèƒ½</strong>ï¼šè®¡ç®—äºŒåˆ†ç±»ä»»åŠ¡æ—¶çš„äº¤å‰ç†µï¼ˆCross Entropyï¼‰å‡½æ•°ã€‚åœ¨äºŒåˆ†ç±»ä¸­ï¼Œlabelæ˜¯{0,1}ã€‚å¯¹äºè¿›å…¥äº¤å‰ç†µå‡½æ•°çš„inputä¸ºæ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œinputä¸ºsigmoidæ¿€æ´»å±‚çš„è¾“å‡ºï¼Œæˆ–è€…softmaxçš„è¾“å‡ºã€‚</p><p><strong>ä¸»è¦å‚æ•°</strong>ï¼š</p><ul><li><code>weight</code>:æ¯ä¸ªç±»åˆ«çš„lossè®¾ç½®æƒå€¼</li><li><code>size_average</code>:æ•°æ®ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œè¿”å›çš„lossä¸ºå¹³å‡å€¼ï¼›ä¸ºFalseæ—¶ï¼Œè¿”å›çš„å„æ ·æœ¬çš„lossä¹‹å’Œ.</li><li><code>reduce</code>:æ•°æ®ç±»å‹ä¸ºboolï¼Œä¸ºTrueæ—¶ï¼Œlossçš„è¿”å›æ˜¯æ ‡é‡ã€‚</li></ul><h3 id="å…¶ä»–æŸå¤±å‡½æ•°"><a href="#å…¶ä»–æŸå¤±å‡½æ•°" class="headerlink" title="å…¶ä»–æŸå¤±å‡½æ•°"></a>å…¶ä»–æŸå¤±å‡½æ•°</h3><p>äº¤å‰ç†µæŸå¤±å‡½æ•°</p><p>L1æŸå¤±å‡½æ•°</p><p>MSEæŸå¤±å‡½æ•°</p><p>å¹³æ»‘L1 (Smooth L1)æŸå¤±å‡½æ•°</p><p>ç›®æ ‡æ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±</p><p>KLæ•£åº¦</p><h2 id="ä¼˜åŒ–å™¨"><a href="#ä¼˜åŒ–å™¨" class="headerlink" title="ä¼˜åŒ–å™¨"></a>ä¼˜åŒ–å™¨</h2><h3 id="ä»€ä¹ˆæ˜¯ä¼˜åŒ–å™¨"><a href="#ä»€ä¹ˆæ˜¯ä¼˜åŒ–å™¨" class="headerlink" title="ä»€ä¹ˆæ˜¯ä¼˜åŒ–å™¨"></a>ä»€ä¹ˆæ˜¯ä¼˜åŒ–å™¨</h3><p>æ·±åº¦å­¦ä¹ çš„ç›®æ ‡æ˜¯é€šè¿‡ä¸æ–­æ”¹å˜ç½‘ç»œå‚æ•°ï¼Œä½¿å¾—å‚æ•°èƒ½å¤Ÿå¯¹è¾“å…¥åšå„ç§éçº¿æ€§å˜æ¢æ‹Ÿåˆè¾“å‡ºï¼Œæœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªå‡½æ•°å»å¯»æ‰¾æœ€ä¼˜è§£ï¼Œåªä¸è¿‡è¿™ä¸ªæœ€ä¼˜è§£ä½¿ä¸€ä¸ªçŸ©é˜µã€‚é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•è®¡ç®—å‡ºæ¥è¿™ä¹ˆå¤šçš„ç³»æ•°ï¼Œæœ‰ä»¥ä¸‹ä¸¤ç§æ–¹æ³•ï¼š</p><ol><li>ç¬¬ä¸€ç§æ˜¯æœ€ç›´æ¥çš„æš´åŠ›ç©·ä¸¾ä¸€éå‚æ•°ï¼Œè¿™ç§æ–¹æ³•çš„å®æ–½å¯èƒ½æ€§åŸºæœ¬ä¸º0ï¼Œå ªæ¯”æ„šå…¬ç§»å±±plusçš„éš¾åº¦ã€‚</li><li>ä¸ºäº†ä½¿æ±‚è§£å‚æ•°è¿‡ç¨‹æ›´åŠ å¿«ï¼Œäººä»¬æå‡ºäº†ç¬¬äºŒç§åŠæ³•ï¼Œå³å°±æ˜¯æ˜¯BP+ä¼˜åŒ–å™¨é€¼è¿‘æ±‚è§£ã€‚</li></ol><p>å› æ­¤ï¼Œä¼˜åŒ–å™¨å°±æ˜¯æ ¹æ®ç½‘ç»œåå‘ä¼ æ’­çš„æ¢¯åº¦ä¿¡æ¯æ¥æ›´æ–°ç½‘ç»œçš„å‚æ•°ï¼Œä»¥èµ·åˆ°é™ä½losså‡½æ•°è®¡ç®—å€¼ï¼Œä½¿å¾—æ¨¡å‹è¾“å‡ºæ›´åŠ æ¥è¿‘çœŸå®æ ‡ç­¾ã€‚</p><h3 id="PyTorchæä¾›çš„ä¼˜åŒ–å™¨"><a href="#PyTorchæä¾›çš„ä¼˜åŒ–å™¨" class="headerlink" title="PyTorchæä¾›çš„ä¼˜åŒ–å™¨"></a>PyTorchæä¾›çš„ä¼˜åŒ–å™¨</h3><p>Pytorchå¾ˆäººæ€§åŒ–çš„ç»™æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªä¼˜åŒ–å™¨çš„åº“torch.optimï¼Œåœ¨è¿™é‡Œé¢ç»™æˆ‘ä»¬æä¾›äº†åç§ä¼˜åŒ–å™¨ã€‚</p><ul><li>torch.optim.ASGD</li><li>torch.optim.Adadelta</li><li>torch.optim.Adagrad</li><li>torch.optim.Adam</li><li>torch.optim.AdamW</li><li>torch.optim.Adamax</li><li>torch.optim.LBFGS</li><li>torch.optim.RMSprop</li><li>torch.optim.Rprop</li><li>torch.optim.SGD</li><li>torch.optim.SparseAdam</li></ul><h2 id="è®­ç»ƒä¸è¯„ä¼°"><a href="#è®­ç»ƒä¸è¯„ä¼°" class="headerlink" title="è®­ç»ƒä¸è¯„ä¼°"></a>è®­ç»ƒä¸è¯„ä¼°</h2><p>å®Œæˆäº†ä¸Šè¿°è®¾å®šåå°±å¯ä»¥åŠ è½½æ•°æ®å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ã€‚é¦–å…ˆåº”è¯¥è®¾ç½®æ¨¡å‹çš„çŠ¶æ€ï¼šå¦‚æœæ˜¯è®­ç»ƒçŠ¶æ€ï¼Œé‚£ä¹ˆæ¨¡å‹çš„å‚æ•°åº”è¯¥æ”¯æŒåå‘ä¼ æ’­çš„ä¿®æ”¹ï¼›å¦‚æœæ˜¯éªŒè¯/æµ‹è¯•çŠ¶æ€ï¼Œåˆ™ä¸åº”è¯¥ä¿®æ”¹æ¨¡å‹å‚æ•°ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.train()   <span class="comment"># è®­ç»ƒçŠ¶æ€</span></span><br><span class="line">model.<span class="built_in">eval</span>()   <span class="comment"># éªŒè¯/æµ‹è¯•çŠ¶æ€</span></span><br></pre></td></tr></table></figure><p>è®­ç»ƒè¿‡ç¨‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:  <span class="comment"># æ­¤æ—¶è¦ç”¨forå¾ªç¯è¯»å–DataLoaderä¸­çš„å…¨éƒ¨æ•°æ®ã€‚</span></span><br><span class="line">        data, label = data.cuda(), label.cuda()  <span class="comment"># ä¹‹åå°†æ•°æ®æ”¾åˆ°GPUä¸Šç”¨äºåç»­è®¡ç®—ï¼Œæ­¤å¤„ä»¥.cuda()ä¸ºä¾‹</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># å¼€å§‹ç”¨å½“å‰æ‰¹æ¬¡æ•°æ®åšè®­ç»ƒæ—¶ï¼Œåº”å½“å…ˆå°†ä¼˜åŒ–å™¨çš„æ¢¯åº¦ç½®é›¶</span></span><br><span class="line">        output = model(data)  <span class="comment"># ä¹‹åå°†dataé€å…¥æ¨¡å‹ä¸­è®­ç»ƒ</span></span><br><span class="line">        loss = criterion(label, output)   <span class="comment"># æ ¹æ®é¢„å…ˆå®šä¹‰çš„criterionè®¡ç®—æŸå¤±å‡½æ•°</span></span><br><span class="line">        loss.backward()  <span class="comment"># å°†lossåå‘ä¼ æ’­å›ç½‘ç»œ</span></span><br><span class="line">        optimizer.step()  <span class="comment"># ä½¿ç”¨ä¼˜åŒ–å™¨æ›´æ–°æ¨¡å‹å‚æ•°</span></span><br><span class="line">        train_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">    train_loss = train_loss/<span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, train_loss))</span><br></pre></td></tr></table></figure><p>éªŒè¯/æµ‹è¯•çš„æµç¨‹åŸºæœ¬ä¸è®­ç»ƒè¿‡ç¨‹ä¸€è‡´ï¼Œä¸åŒç‚¹åœ¨äºï¼š</p><ul><li>éœ€è¦é¢„å…ˆè®¾ç½®torch.no_gradï¼Œä»¥åŠå°†modelè°ƒè‡³evalæ¨¡å¼</li><li>ä¸éœ€è¦å°†ä¼˜åŒ–å™¨çš„æ¢¯åº¦ç½®é›¶</li><li>ä¸éœ€è¦å°†lossåå‘å›ä¼ åˆ°ç½‘ç»œ</li><li>ä¸éœ€è¦æ›´æ–°optimizer</li></ul><p>éªŒè¯/æµ‹è¯•è¿‡ç¨‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val</span>(<span class="params">epoch</span>):</span>       </span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    val_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> val_loader:</span><br><span class="line">            data, label = data.cuda(), label.cuda()</span><br><span class="line">            output = model(data)</span><br><span class="line">            preds = torch.argmax(output, <span class="number">1</span>)</span><br><span class="line">            loss = criterion(output, label)</span><br><span class="line">            val_loss += loss.item()*data.size(<span class="number">0</span>)</span><br><span class="line">            running_accu += torch.<span class="built_in">sum</span>(preds == label.data)</span><br><span class="line">    val_loss = val_loss/<span class="built_in">len</span>(val_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, val_loss))</span><br></pre></td></tr></table></figure><h2 id="å¯è§†åŒ–"><a href="#å¯è§†åŒ–" class="headerlink" title="å¯è§†åŒ–"></a>å¯è§†åŒ–</h2><p>åœ¨PyTorchæ·±åº¦å­¦ä¹ ä¸­ï¼Œå¯è§†åŒ–æ˜¯ä¸€ä¸ªå¯é€‰é¡¹ï¼ŒæŒ‡çš„æ˜¯æŸäº›ä»»åŠ¡åœ¨è®­ç»ƒå®Œæˆåï¼Œéœ€è¦å¯¹ä¸€äº›å¿…è¦çš„å†…å®¹è¿›è¡Œå¯è§†åŒ–ï¼Œæ¯”å¦‚åˆ†ç±»çš„ROCæ›²çº¿ï¼Œå·ç§¯ç½‘ç»œä¸­çš„å·ç§¯æ ¸ï¼Œä»¥åŠè®­ç»ƒ/éªŒè¯è¿‡ç¨‹çš„æŸå¤±å‡½æ•°æ›²çº¿ç­‰ç­‰ã€‚</p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>Datawhaleå¼€æºé¡¹ç›®ï¼šæ·±å…¥æµ…å‡ºPyTorch <a href="https://github.com/datawhalechina/thorough-pytorch/">https://github.com/datawhalechina/thorough-pytorch/</a></li><li>æå®æ¯…æœºå™¨å­¦ä¹ 2021æ˜¥-PyTorch Tutorial <a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=5">https://www.bilibili.com/video/BV1Wv411h7kN?p=5</a></li><li>åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ pytorchç‰ˆ <a href="https://zh-v2.d2l.ai/chapter_preface/index.html">https://zh-v2.d2l.ai/chapter_preface/index.html</a></li><li>PyTorchå®˜æ–¹æ•™ç¨‹ä¸­æ–‡ç‰ˆ <a href="https://pytorch123.com/SecondSection/training_a_classifier/">https://pytorch123.com/SecondSection/training_a_classifier/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ç¬¬ä¸‰ç« -PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—&quot;&gt;&lt;a href=&quot;#ç¬¬ä¸‰ç« -PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—&quot; class=&quot;headerlink&quot; title=&quot;ç¬¬ä¸‰ç«  PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—&quot;&gt;&lt;/a&gt;ç¬¬ä¸‰ç«  PyTorchçš„ä¸»è¦ç»„æˆæ¨¡å—&lt;/h1&gt;&lt;h2 id=&quot;å®Œ</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬30æœŸ æ·±å…¥æµ…å‡ºPyTorch" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC30%E6%9C%9F-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAPyTorch/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="PyTorch" scheme="http://example.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Task07 ä½¿ç”¨Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡</title>
    <link href="http://example.com/nlp-transformer-task07/"/>
    <id>http://example.com/nlp-transformer-task07/</id>
    <published>2021-09-25T08:57:45.000Z</published>
    <updated>2021-10-02T09:21:50.190Z</updated>
    
    <content type="html"><![CDATA[<p><em>è¯¥éƒ¨åˆ†çš„å†…å®¹ç¿»è¯‘è‡ªğŸ¤—HuggingFace/notebooks <a href="https://github.com/huggingface/notebooks/tree/master/examples">https://github.com/huggingface/notebooks/tree/master/examples</a></em><br><em>ä¸­æ–‡ç¿»è¯‘ï¼šDatawhale/learn-nlp-with-transformers/4.1-æ–‡æœ¬åˆ†ç±» <a href="https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1/4.1-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.md">Datawhale/learn-nlp-with-transformers/4.1-æ–‡æœ¬åˆ†ç±»</a></em></p><h1 id="å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»"><a href="#å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»" class="headerlink" title="å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»"></a>å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»</h1><p>æˆ‘ä»¬å°†ä½¿ç”¨ ğŸ¤— Transformersä»£ç åº“ä¸­çš„æ¨¡å‹æ¥è§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œä»»åŠ¡æ¥æºäºGLUE Benchmark.<br>GLUEæ¦œå•åŒ…å«äº†9ä¸ªå¥å­çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡ï¼Œåˆ†åˆ«æ˜¯ï¼š</p><ul><li>CoLA (Corpus of Linguistic Acceptability) é‰´åˆ«ä¸€ä¸ªå¥å­æ˜¯å¦è¯­æ³•æ­£ç¡®.</li><li>MNLI (Multi-Genre Natural Language Inference) ç»™å®šä¸€ä¸ªå‡è®¾ï¼Œåˆ¤æ–­å¦ä¸€ä¸ªå¥å­ä¸è¯¥å‡è®¾çš„å…³ç³»ï¼šentails, contradicts æˆ–è€… unrelatedã€‚</li><li>MRPC (Microsoft Research Paraphrase Corpus) åˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦äº’ä¸ºparaphrases.</li><li>QNLI (Question-answering Natural Language Inference) åˆ¤æ–­ç¬¬2å¥æ˜¯å¦åŒ…å«ç¬¬1å¥é—®é¢˜çš„ç­”æ¡ˆã€‚</li><li>QQP (Quora Question Pairs2) åˆ¤æ–­ä¸¤ä¸ªé—®å¥æ˜¯å¦è¯­ä¹‰ç›¸åŒã€‚</li><li>RTE (Recognizing Textual Entailment)åˆ¤æ–­ä¸€ä¸ªå¥å­æ˜¯å¦ä¸å‡è®¾æˆentailå…³ç³»ã€‚</li><li>SST-2 (Stanford Sentiment Treebank) åˆ¤æ–­ä¸€ä¸ªå¥å­çš„æƒ…æ„Ÿæ­£è´Ÿå‘.</li><li>STS-B (Semantic Textual Similarity Benchmark) åˆ¤æ–­ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼æ€§ï¼ˆåˆ†æ•°ä¸º1-5åˆ†ï¼‰ã€‚</li><li>WNLI (Winograd Natural Language Inference) Determine if a sentence with an anonymous pronoun and a sentence with this pronoun replaced are entailed or not.</li></ul><p>å¯¹äºä»¥ä¸Šä»»åŠ¡ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç®€å•çš„Datasetåº“åŠ è½½æ•°æ®é›†ï¼ŒåŒæ—¶ä½¿ç”¨transformerä¸­çš„Traineræ¥å£å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GLUE_TASKS = [<span class="string">&quot;cola&quot;</span>, <span class="string">&quot;mnli&quot;</span>, <span class="string">&quot;mnli-mm&quot;</span>, <span class="string">&quot;mrpc&quot;</span>, <span class="string">&quot;qnli&quot;</span>, <span class="string">&quot;qqp&quot;</span>, <span class="string">&quot;rte&quot;</span>, <span class="string">&quot;sst2&quot;</span>, <span class="string">&quot;stsb&quot;</span>, <span class="string">&quot;wnli&quot;</span>]</span><br></pre></td></tr></table></figure><p>This notebook is built to run on any of the tasks in the list above, with any model checkpoint from the Model Hub as long as that model has a version with a classification head. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:<br>æœ¬notebookç†è®ºä¸Šå¯ä»¥ä½¿ç”¨å„ç§å„æ ·çš„transformeræ¨¡å‹ï¼ˆæ¨¡å‹é¢æ¿ï¼‰ï¼Œè§£å†³ä»»ä½•æ–‡æœ¬åˆ†ç±»åˆ†ç±»ä»»åŠ¡ã€‚å¦‚æœæ‚¨æ‰€å¤„ç†çš„ä»»åŠ¡æœ‰æ‰€ä¸åŒï¼Œå¤§æ¦‚ç‡åªéœ€è¦å¾ˆå°çš„æ”¹åŠ¨ä¾¿å¯ä»¥ä½¿ç”¨æœ¬notebookè¿›è¡Œå¤„ç†ã€‚åŒæ—¶ï¼Œæ‚¨åº”è¯¥æ ¹æ®æ‚¨çš„GPUæ˜¾å­˜æ¥è°ƒæ•´å¾®è°ƒè®­ç»ƒæ‰€éœ€è¦çš„btach sizeå¤§å°ï¼Œé¿å…æ˜¾å­˜æº¢å‡ºã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">task = <span class="string">&quot;cola&quot;</span></span><br><span class="line">model_checkpoint = <span class="string">&quot;distilbert-base-uncased&quot;</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br></pre></td></tr></table></figure><h1 id="åŠ è½½æ•°æ®é›†"><a href="#åŠ è½½æ•°æ®é›†" class="headerlink" title="åŠ è½½æ•°æ®é›†"></a>åŠ è½½æ•°æ®é›†</h1><p>We will use the ğŸ¤— Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions <code>load_dataset</code> and <code>load_metric</code>.<br>æˆ‘ä»¬å°†ä¼šä½¿ç”¨ğŸ¤— Datasetsåº“æ¥åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼ã€‚æ•°æ®åŠ è½½å’Œè¯„æµ‹æ–¹å¼åŠ è½½åªéœ€è¦ç®€å•ä½¿ç”¨load_datasetå’Œload_metricå³å¯ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from datasets import load_dataset, load_metric</span><br></pre></td></tr></table></figure><p>Apart from mnli-mm being a special code, we can directly pass our task name to those functions. <code>load_dataset</code> will cache the dataset to avoid downloading it again the next time you run this cell.<br>é™¤äº†mnli-mmä»¥å¤–ï¼Œå…¶ä»–ä»»åŠ¡éƒ½å¯ä»¥ç›´æ¥é€šè¿‡ä»»åŠ¡åå­—è¿›è¡ŒåŠ è½½ã€‚æ•°æ®åŠ è½½ä¹‹åä¼šè‡ªåŠ¨ç¼“å­˜ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">actual_task = <span class="string">&quot;mnli&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> task</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;glue&quot;</span>, actual_task)</span><br><span class="line">metric = load_metric(<span class="string">&#x27;glue&#x27;</span>, actual_task)</span><br></pre></td></tr></table></figure><p><em>ä¸ŠèŠ‚è®²è¿‡ï¼Œè¿™é‡Œï¼Œæœ€å¥½æ‰‹åŠ¨ä¸‹è½½glue.pyå’Œgule_metric.pyï¼Œä¸ä¸‹è½½åˆ°æœ¬åœ°çš„è¯ï¼Œå®¹æ˜“å‡ºç°è¿æ¥é”™è¯¯ã€‚</em></p><p>The dataset object itself is DatasetDict, which contains one key for the training, validation and test set (with more keys for the mismatched validation and test set in the special case of mnli).<br>è¿™ä¸ªdatasetså¯¹è±¡æœ¬èº«æ˜¯ä¸€ç§DatasetDictæ•°æ®ç»“æ„.å¯¹äºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œåªéœ€è¦ä½¿ç”¨å¯¹åº”çš„keyï¼ˆtrainï¼Œvalidationï¼Œtestï¼‰å³å¯å¾—åˆ°ç›¸åº”çš„æ•°æ®ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataset</span><br><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">8551</span></span><br><span class="line">    &#125;)</span><br><span class="line">    validation: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1043</span></span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1063</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dataset[<span class="string">&quot;train&quot;</span>][<span class="number">0</span>]</span><br><span class="line">&#123;<span class="string">&#x27;sentence&#x27;</span>: <span class="string">&quot;Our friends won&#x27;t buy this analysis, let alone the next one we propose.&quot;</span>,</span><br><span class="line"><span class="string">&#x27;label&#x27;</span>: <span class="number">1</span>, </span><br><span class="line"><span class="string">&#x27;idx&#x27;</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure><p>To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset.<br>ä¸ºäº†èƒ½å¤Ÿè¿›ä¸€æ­¥ç†è§£æ•°æ®é•¿ä»€ä¹ˆæ ·å­ï¼Œä¸‹é¢çš„å‡½æ•°å°†ä»æ•°æ®é›†é‡Œéšæœºé€‰æ‹©å‡ ä¸ªä¾‹å­è¿›è¡Œå±•ç¤ºã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, HTML</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_random_elements</span>(<span class="params">dataset, num_examples=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">assert</span> num_examples &lt;= <span class="built_in">len</span>(dataset), <span class="string">&quot;Can&#x27;t pick more elements than there are in the dataset.&quot;</span></span><br><span class="line">    picks = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_examples):</span><br><span class="line">        pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">while</span> pick <span class="keyword">in</span> picks:</span><br><span class="line">            pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        picks.append(pick)</span><br><span class="line">    </span><br><span class="line">    df = pd.DataFrame(dataset[picks])</span><br><span class="line">    <span class="keyword">for</span> column, typ <span class="keyword">in</span> dataset.features.items():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(typ, datasets.ClassLabel):</span><br><span class="line">            df[column] = df[column].transform(<span class="keyword">lambda</span> i: typ.names[i])</span><br><span class="line">    display(HTML(df.to_html()))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_random_elements(dataset[<span class="string">&quot;train&quot;</span>])</span><br></pre></td></tr></table></figure><p>The metric is an instance of datasets.Metric:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>You can call its <code>compute</code> method with your predictions and labels directly and it will return a dictionary with the metric(s) value:<br>ç›´æ¥è°ƒç”¨metricçš„computeæ–¹æ³•ï¼Œä¼ å…¥labelså’Œpredictionså³å¯å¾—åˆ°metricçš„å€¼ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">fake_preds = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(<span class="number">64</span>,))</span><br><span class="line">fake_labels = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(<span class="number">64</span>,))</span><br><span class="line">metric.compute(predictions=fake_preds, references=fake_labels)</span><br></pre></td></tr></table></figure><p>Note that load_metric has loaded the proper metric associated to your task, which is:<br>æ¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡æ‰€å¯¹åº”çš„meticæœ‰æ‰€ä¸åŒï¼Œå…·ä½“å¦‚ä¸‹:</p><ul><li>for CoLA: Matthews Correlation Coefficient</li><li>for MNLI (matched or mismatched): Accuracy</li><li>for MRPC: Accuracy and F1 score</li><li>for QNLI: Accuracy</li><li>for QQP: Accuracy and F1 score</li><li>for RTE: Accuracy</li><li>for SST-2: Accuracy</li><li>for STS-B: Pearson Correlation Coefficient and Spearmanâ€™s_Rank_Correlation_Coefficient</li><li>for WNLI: Accuracy</li></ul><p>so the metric object only computes the one(s) needed for your task.</p><h1 id="æ•°æ®é¢„å¤„ç†"><a href="#æ•°æ®é¢„å¤„ç†" class="headerlink" title="æ•°æ®é¢„å¤„ç†"></a>æ•°æ®é¢„å¤„ç†</h1><p>Before we can feed those texts to our model, we need to preprocess them. This is done by a ğŸ¤— Transformers <code>Tokenizer</code> which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.<br>åœ¨å°†æ•°æ®å–‚å…¥æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚é¢„å¤„ç†çš„å·¥å…·å«Tokenizerã€‚Tokenizeré¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œtokenizeï¼Œç„¶åå°†tokensè½¬åŒ–ä¸ºé¢„æ¨¡å‹ä¸­éœ€è¦å¯¹åº”çš„token IDï¼Œå†è½¬åŒ–ä¸ºæ¨¡å‹éœ€è¦çš„è¾“å…¥æ ¼å¼ã€‚</p><p>To do all of this, we instantiate our tokenizer with the <code>AutoTokenizer.from_pretrained</code> method, which will ensure:</p><ul><li>we get a tokenizer that corresponds to the model architecture we want to use,</li><li>we download the vocabulary used when pretraining this specific checkpoint.</li></ul><p>ä¸ºäº†è¾¾åˆ°æ•°æ®é¢„å¤„ç†çš„ç›®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨AutoTokenizer.from_pretrainedæ–¹æ³•å®ä¾‹åŒ–æˆ‘ä»¬çš„tokenizerï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ï¼š</p><ul><li>æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€ä¸€å¯¹åº”çš„tokenizerã€‚</li><li>ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹checkpointå¯¹åº”çš„tokenizerçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¸‹è½½äº†æ¨¡å‹éœ€è¦çš„è¯è¡¨åº“vocabularyï¼Œå‡†ç¡®æ¥è¯´æ˜¯tokens vocabularyã€‚</li></ul><p>That vocabulary will be cached, so itâ€™s not downloaded again the next time we run the cell.<br>è¿™ä¸ªè¢«ä¸‹è½½çš„tokens vocabularyä¼šè¢«ç¼“å­˜èµ·æ¥ï¼Œä»è€Œå†æ¬¡ä½¿ç”¨çš„æ—¶å€™ä¸ä¼šé‡æ–°ä¸‹è½½ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">    </span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>You can directly call this tokenizer on one sentence or a pair of sentences:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer(<span class="string">&quot;Hello, this one sentence!&quot;</span>, <span class="string">&quot;And this sentence goes with it.&quot;</span>)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºä¸ºï¼š<br>pass</p><p>To preprocess our dataset, we will thus need the names of the columns containing the sentence(s). The following dictionary keeps track of the correspondence task to column names:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">task_to_keys = &#123;</span><br><span class="line">    <span class="string">&quot;cola&quot;</span>: (<span class="string">&quot;sentence&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    <span class="string">&quot;mnli&quot;</span>: (<span class="string">&quot;premise&quot;</span>, <span class="string">&quot;hypothesis&quot;</span>),</span><br><span class="line">    <span class="string">&quot;mnli-mm&quot;</span>: (<span class="string">&quot;premise&quot;</span>, <span class="string">&quot;hypothesis&quot;</span>),</span><br><span class="line">    <span class="string">&quot;mrpc&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;qnli&quot;</span>: (<span class="string">&quot;question&quot;</span>, <span class="string">&quot;sentence&quot;</span>),</span><br><span class="line">    <span class="string">&quot;qqp&quot;</span>: (<span class="string">&quot;question1&quot;</span>, <span class="string">&quot;question2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;rte&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;sst2&quot;</span>: (<span class="string">&quot;sentence&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    <span class="string">&quot;stsb&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;wnli&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can double check it does work on our current dataset:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sentence1_key, sentence2_key = task_to_keys[task]</span><br><span class="line"><span class="keyword">if</span> sentence2_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence1_key]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence 1: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence1_key]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence 2: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence2_key]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºä¸ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sentence: Our friends won&#x27;t buy this analysis, let alone the next one we propose.</span><br></pre></td></tr></table></figure><p>We can them write the function that will preprocess our samples. We just feed them to the <code>tokenizer</code> with the argument <code>truncation=True</code>. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_function</span>(<span class="params">examples</span>):</span></span><br><span class="line">    <span class="keyword">if</span> sentence2_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> tokenizer(examples[sentence1_key], truncation=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>preprocess_function(dataset[<span class="string">&#x27;train&#x27;</span>][:<span class="number">5</span>])</span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [[<span class="number">101</span>, <span class="number">2256</span>, <span class="number">2814</span>, <span class="number">2180</span>, <span class="number">1005</span>, <span class="number">1056</span>, <span class="number">4965</span>, <span class="number">2023</span>, <span class="number">4106</span>, <span class="number">1010</span>, <span class="number">2292</span>, <span class="number">2894</span>, <span class="number">1996</span>, <span class="number">2279</span>, <span class="number">2028</span>, <span class="number">2057</span>, <span class="number">16599</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2028</span>, <span class="number">2062</span>, <span class="number">18404</span>, <span class="number">2236</span>, <span class="number">3989</span>, <span class="number">1998</span>, <span class="number">1045</span>, <span class="number">1005</span>, <span class="number">1049</span>, <span class="number">3228</span>, <span class="number">2039</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2028</span>, <span class="number">2062</span>, <span class="number">18404</span>, <span class="number">2236</span>, <span class="number">3989</span>, <span class="number">2030</span>, <span class="number">1045</span>, <span class="number">1005</span>, <span class="number">1049</span>, <span class="number">3228</span>, <span class="number">2039</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">1996</span>, <span class="number">2062</span>, <span class="number">2057</span>, <span class="number">2817</span>, <span class="number">16025</span>, <span class="number">1010</span>, <span class="number">1996</span>, <span class="number">13675</span>, <span class="number">16103</span>, <span class="number">2121</span>, <span class="number">2027</span>, <span class="number">2131</span>, <span class="number">1012</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">2154</span>, <span class="number">2011</span>, <span class="number">2154</span>, <span class="number">1996</span>, <span class="number">8866</span>, <span class="number">2024</span>, <span class="number">2893</span>, <span class="number">14163</span>, <span class="number">8024</span>, <span class="number">3771</span>, <span class="number">1012</span>, <span class="number">102</span>]], <span class="string">&#x27;attention_mask&#x27;</span>: [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]&#125;</span><br></pre></td></tr></table></figure><p>To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the <code>map</code> method of our <code>dataset</code> object we created earlier. This will apply the function on all the elements of all the splits in <code>dataset</code>, so our training, validation and testing data will be preprocessed in one single command.<br>æ¥ä¸‹æ¥å¯¹æ•°æ®é›†datasetsé‡Œé¢çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œå¤„ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨mapå‡½æ•°ï¼Œå°†é¢„å¤„ç†å‡½æ•°prepare_train_featuresåº”ç”¨åˆ°ï¼ˆmap)æ‰€æœ‰æ ·æœ¬ä¸Šã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoded_dataset = dataset.<span class="built_in">map</span>(preprocess_function, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h1 id="å¾®è°ƒæ¨¡å‹"><a href="#å¾®è°ƒæ¨¡å‹" class="headerlink" title="å¾®è°ƒæ¨¡å‹"></a>å¾®è°ƒæ¨¡å‹</h1><p>Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about sentence classification, we use the AutoModelForSequenceClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which is always 2, except for STS-B which is a regression problem and MNLI where we have 3 labels):<br>æ—¢ç„¶æ•°æ®å·²ç»å‡†å¤‡å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦ä¸‹è½½å¹¶åŠ è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚æ—¢ç„¶æˆ‘ä»¬æ˜¯åšseq2seqä»»åŠ¡ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½è§£å†³è¿™ä¸ªä»»åŠ¡çš„æ¨¡å‹ç±»ã€‚æˆ‘ä»¬ä½¿ç”¨AutoModelForSequenceClassification è¿™ä¸ªç±»ã€‚å’Œtokenizerç›¸ä¼¼ï¼Œfrom_pretrainedæ–¹æ³•åŒæ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿä¼šå¯¹æ¨¡å‹è¿›è¡Œç¼“å­˜ï¼Œå°±ä¸ä¼šé‡å¤ä¸‹è½½æ¨¡å‹å•¦ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, TrainingArguments, Trainer</span><br><span class="line"></span><br><span class="line">num_labels = <span class="number">3</span> <span class="keyword">if</span> task.startswith(<span class="string">&quot;mnli&quot;</span>) <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">if</span> task==<span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºä¸ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: [&#x27;vocab_transform.bias&#x27;, &#x27;vocab_projector.weight&#x27;, &#x27;vocab_layer_norm.bias&#x27;, &#x27;vocab_layer_norm.weight&#x27;, &#x27;vocab_projector.bias&#x27;, &#x27;vocab_transform.weight&#x27;]</span><br><span class="line">- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).</span><br><span class="line">- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</span><br><span class="line">Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#x27;classifier.weight&#x27;, &#x27;classifier.bias&#x27;, &#x27;pre_classifier.bias&#x27;, &#x27;pre_classifier.weight&#x27;]</span><br><span class="line">You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</span><br></pre></td></tr></table></figure><p>The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we donâ€™t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do.<br>ç”±äºæˆ‘ä»¬å¾®è°ƒçš„ä»»åŠ¡æ˜¯æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œè€Œæˆ‘ä»¬åŠ è½½çš„æ˜¯é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œæ‰€ä»¥ä¼šæç¤ºæˆ‘ä»¬åŠ è½½æ¨¡å‹çš„æ—¶å€™æ‰”æ‰äº†ä¸€äº›ä¸åŒ¹é…çš„ç¥ç»ç½‘ç»œå‚æ•°ï¼ˆæ¯”å¦‚ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç¥ç»ç½‘ç»œheadè¢«æ‰”æ‰äº†ï¼ŒåŒæ—¶éšæœºåˆå§‹åŒ–äº†æ–‡æœ¬åˆ†ç±»çš„ç¥ç»ç½‘ç»œheadï¼‰ã€‚</p><p>To instantiate a <code>Trainer</code>, we will need to define two more things. The most important is the <code>TrainingArguments</code>, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:<br>ä¸ºäº†èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ªTrainerè®­ç»ƒå·¥å…·ï¼Œæˆ‘ä»¬è¿˜éœ€è¦3ä¸ªè¦ç´ ï¼Œå…¶ä¸­æœ€é‡è¦çš„æ˜¯è®­ç»ƒçš„è®¾å®š/å‚æ•° TrainingArgumentsã€‚è¿™ä¸ªè®­ç»ƒè®¾å®šåŒ…å«äº†èƒ½å¤Ÿå®šä¹‰è®­ç»ƒè¿‡ç¨‹çš„æ‰€æœ‰å±æ€§ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">metric_name = <span class="string">&quot;pearson&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="string">&quot;matthews_correlation&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;cola&quot;</span> <span class="keyword">else</span> <span class="string">&quot;accuracy&quot;</span></span><br><span class="line">model_name = model_checkpoint.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">args = TrainingArguments(</span><br><span class="line">    <span class="string">&quot;test-glue&quot;</span>,</span><br><span class="line">    evaluation_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    save_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=batch_size,</span><br><span class="line">    per_device_eval_batch_size=batch_size,</span><br><span class="line">    num_train_epochs=<span class="number">5</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">    metric_for_best_model=metric_name,</span><br><span class="line">    push_to_hub=<span class="literal">False</span>,</span><br><span class="line">    push_to_hub_model_id=<span class="string">f&quot;<span class="subst">&#123;model_name&#125;</span>-finetuned-<span class="subst">&#123;task&#125;</span>&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the <code>batch_size</code> defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. Since the best model might not be the one at the end of training, we ask the <code>Trainer</code> to load the best model it saved (according to <code>metric_name</code>) at the end of training.<br>ä¸Šé¢evaluation_strategy = â€œepochâ€å‚æ•°å‘Šè¯‰è®­ç»ƒä»£ç ï¼šæˆ‘ä»¬æ¯ä¸ªepcohä¼šåšä¸€æ¬¡éªŒè¯è¯„ä¼°ã€‚<br>ä¸Šé¢batch_sizeåœ¨è¿™ä¸ªnotebookä¹‹å‰å®šä¹‰å¥½äº†ã€‚</p><p>The last two arguments are to setup everything so we can push the model to the <code>Hub</code> at the end of training. Remove the two of them if you didnâ€™t follow the installation steps at the top of the notebook, otherwise you can change the value of <code>push_to_hub_model_id</code> to something you would prefer.<br><em>(åé¢éœ€è¦è¿æ¥åˆ°hubå®¢æˆ·ç«¯ï¼Œå¤ªéº»çƒ¦ï¼Œæ‰€ä»¥å…ˆè®¾ä¸ºFalse)</em></p><p>The last thing to define for our <code>Trainer</code> is how to compute the metrics from the predictions. We need to define a function for this, which will just use the <code>metric</code> we loaded earlier, the only preprocessing we have to do is to take the argmax of our predicted logits (our just squeeze the last axis in the case of STS-B):<br>æœ€åï¼Œç”±äºä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„è¯„æµ‹æŒ‡æ ‡ï¼Œæˆ‘ä»¬å®šä¸€ä¸ªå‡½æ•°æ¥æ ¹æ®ä»»åŠ¡åå­—å¾—åˆ°è¯„ä»·æ–¹æ³•:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">eval_pred</span>):</span></span><br><span class="line">    predictions, labels = eval_pred</span><br><span class="line">    <span class="keyword">if</span> task != <span class="string">&quot;stsb&quot;</span>:</span><br><span class="line">        predictions = np.argmax(predictions, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        predictions = predictions[:, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure><p>Then we just need to pass all of this along with our datasets to the Trainer:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">validation_key = <span class="string">&quot;validation_mismatched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation_matched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation&quot;</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure><blockquote><p>BUG:<br>ValueError: You must login to the Hugging Face hub on this computer by typing <code>transformers-cli login</code> and entering your credentials to use <code>use_auth_token=True</code>. Alternatively, you can pass your own token as the <code>use_auth_token</code> argument.<br>æŠŠargsé‡Œé¢çš„è¯¥é¡¹å‚æ•°æ”¹ä¸ºFalse   <code>push_to_hub=False,</code>ã€‚</p></blockquote><p>We can now finetune our model by just calling the <code>train</code> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure><p>è¾“å‡ºä¸ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>We can check with the <code>evaluate</code> method that our <code>Trainer</code> did reload the best model properly (if it was not the last one):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.evaluate()</span><br></pre></td></tr></table></figure><p>è¾“å‡ºä¸ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h1 id="è¶…å‚æœç´¢"><a href="#è¶…å‚æœç´¢" class="headerlink" title="è¶…å‚æœç´¢"></a>è¶…å‚æœç´¢</h1><p>The Trainer supports hyperparameter search using optuna or Ray Tune. </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install optuna</span><br><span class="line">pip install ray[tune]</span><br></pre></td></tr></table></figure><p>During hyperparameter search, the Trainer will run several trainings, so it needs to have the model defined via a function (so it can be reinitialized at each new run) instead of just having it passed. We jsut use the same function as before:<br>è¶…å‚æœç´¢æ—¶ï¼ŒTrainerå°†ä¼šè¿”å›å¤šä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ‰€ä»¥éœ€è¦ä¼ å…¥ä¸€ä¸ªå®šä¹‰å¥½çš„æ¨¡å‹ä»è€Œè®©Trainerå¯ä»¥ä¸æ–­é‡æ–°åˆå§‹åŒ–è¯¥ä¼ å…¥çš„æ¨¡å‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_init</span>():</span></span><br><span class="line">    <span class="keyword">return</span> AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br></pre></td></tr></table></figure><p>And we can instantiate our Trainer like before:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    model_init=model_init,</span><br><span class="line">    args=args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>The method we call this time is <code>hyperparameter_search</code>. Note that it can take a long time to run on the full dataset for some of the tasks. You can try to find some good hyperparameter on a portion of the training dataset by replacing the <code>train_dataset</code> line above by:<br><code>train_dataset = encoded_dataset[&quot;train&quot;].shard(index=1, num_shards=10) </code><br>for 1/10th of the dataset. Then you can run a full training on the best hyperparameters picked by the search.<br>è°ƒç”¨æ–¹æ³•hyperparameter_searchã€‚æ³¨æ„ï¼Œè¿™ä¸ªè¿‡ç¨‹å¯èƒ½å¾ˆä¹…ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆç”¨éƒ¨åˆ†æ•°æ®é›†è¿›è¡Œè¶…å‚æœç´¢ï¼Œå†è¿›è¡Œå…¨é‡è®­ç»ƒã€‚ æ¯”å¦‚ä½¿ç”¨1/10çš„æ•°æ®è¿›è¡Œæœç´¢ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_run = trainer.hyperparameter_search(n_trials=<span class="number">10</span>, direction=<span class="string">&quot;maximize&quot;</span>)</span><br></pre></td></tr></table></figure><p>The hyperparameter_search method returns a <code>BestRun</code> objects, which contains the value of the objective maximized (by default the sum of all metrics) and the hyperparameters it used for that run.<br>hyperparameter_searchä¼šè¿”å›æ•ˆæœæœ€å¥½çš„æ¨¡å‹ç›¸å…³çš„å‚æ•°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>best_run</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>To reproduce the best training, just set the hyperparameters in your TrainingArgument before creating a Trainer:<br>å°†Trainnerè®¾ç½®ä¸ºæœç´¢åˆ°çš„æœ€å¥½å‚æ•°ï¼Œè¿›è¡Œè®­ç»ƒï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> n, v <span class="keyword">in</span> best_run.hyperparameters.items():</span><br><span class="line">    <span class="built_in">setattr</span>(trainer.args, n, v)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>HuggingFace/transfomers/BERT <a href="https://huggingface.co/transformers/model_doc/bert.html#">https://huggingface.co/transformers/model_doc/bert.html#</a></li><li>åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨â€“åœ¨çº¿é˜…è¯» <a href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;em&gt;è¯¥éƒ¨åˆ†çš„å†…å®¹ç¿»è¯‘è‡ªğŸ¤—HuggingFace/notebooks &lt;a href=&quot;https://github.com/huggingface/notebooks/tree/master/examples&quot;&gt;https://github.com/huggingfa</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬29æœŸ åŸºäºtransformerçš„NLP" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="é¢„è®­ç»ƒæ¨¡å‹" scheme="http://example.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="BERT" scheme="http://example.com/tags/BERT/"/>
    
    <category term="transfomer" scheme="http://example.com/tags/transfomer/"/>
    
    <category term="æ–‡æœ¬åˆ†ç±»" scheme="http://example.com/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>Task06 BERTåº”ç”¨ã€è®­ç»ƒå’Œä¼˜åŒ–</title>
    <link href="http://example.com/nlp-transformer-task06/"/>
    <id>http://example.com/nlp-transformer-task06/</id>
    <published>2021-09-24T07:18:42.000Z</published>
    <updated>2021-10-02T09:21:45.032Z</updated>
    
    <content type="html"><![CDATA[<p><em>è¯¥éƒ¨åˆ†çš„å†…å®¹ç¿»è¯‘è‡ªğŸ¤—HuggingFaceå®˜ç½‘æ•™ç¨‹ç¬¬1éƒ¨åˆ†ï¼ˆ1-4ç« ï¼‰ï¼Œè§ <a href="https://huggingface.co/course/chapter1">https://huggingface.co/course/chapter1</a>ã€‚è¯¥ç³»åˆ—æ•™ç¨‹ç”±3å¤§éƒ¨åˆ†å…±12ç« ç»„æˆï¼ˆå¦‚å›¾ï¼‰ï¼Œå…¶ä¸­ç¬¬1éƒ¨åˆ†ä»‹ç»transformersåº“çš„ä¸»è¦æ¦‚å¿µã€æ¨¡å‹çš„å·¥ä½œåŸç†å’Œä½¿ç”¨æ–¹æ³•ã€æ€æ ·åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šå¾®è°ƒç­‰å†…å®¹ã€‚</em><br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/hf_1.png?raw=true" width="500" alt="" align="center" /></p><h1 id="ç¯å¢ƒæ­å»º"><a href="#ç¯å¢ƒæ­å»º" class="headerlink" title="ç¯å¢ƒæ­å»º"></a>ç¯å¢ƒæ­å»º</h1><p>ç®€å•çš„è¯´ï¼Œæœ‰ä¸¤ç§å¯ä»¥è·‘æ¨¡å‹ä»£ç çš„æ–¹å¼ï¼š</p><ol><li>Google Colab</li><li>æœ¬åœ°è™šæ‹Ÿç¯å¢ƒ <code>pip install transformers</code></li></ol><p>è¯¦è§ <a href="https://huggingface.co/course/chapter0?fw=pt">https://huggingface.co/course/chapter0?fw=pt</a></p><h1 id="Transformeræ¨¡å‹æ¦‚è¿°"><a href="#Transformeræ¨¡å‹æ¦‚è¿°" class="headerlink" title="Transformeræ¨¡å‹æ¦‚è¿°"></a>Transformeræ¨¡å‹æ¦‚è¿°</h1><h2 id="Transformers-å¯ä»¥åšä»€ä¹ˆï¼Ÿ"><a href="#Transformers-å¯ä»¥åšä»€ä¹ˆï¼Ÿ" class="headerlink" title="Transformers, å¯ä»¥åšä»€ä¹ˆï¼Ÿ"></a>Transformers, å¯ä»¥åšä»€ä¹ˆï¼Ÿ</h2><p>ç›®å‰å¯ç”¨çš„ä¸€äº›pipelineæ˜¯ï¼š</p><ul><li>feature-extraction è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º</li><li>fill-mask å®Œå½¢å¡«ç©º</li><li>ner (named entity recognition) å‘½åå®ä½“è¯†åˆ«</li><li>question-answering é—®ç­”</li><li>sentiment-analysis æƒ…æ„Ÿåˆ†æ</li><li>summarization æ‘˜è¦ç”Ÿæˆ</li><li>text-generation æ–‡æœ¬ç”Ÿæˆ</li><li>translation ç¿»è¯‘</li><li>zero-shot-classification é›¶æ ·æœ¬åˆ†ç±»</li></ul><p><em>pipeline: ç›´è¯‘ç®¡é“/æµæ°´çº¿ï¼Œå¯ä»¥ç†è§£ä¸ºæµç¨‹ã€‚</em></p><h2 id="Transformers-å¦‚ä½•å·¥ä½œï¼Ÿ"><a href="#Transformers-å¦‚ä½•å·¥ä½œï¼Ÿ" class="headerlink" title="Transformers, å¦‚ä½•å·¥ä½œï¼Ÿ"></a>Transformers, å¦‚ä½•å·¥ä½œï¼Ÿ</h2><h3 id="Transformerç®€å²"><a href="#Transformerç®€å²" class="headerlink" title="Transformerç®€å²"></a>Transformerç®€å²</h3><p>Transformer æ¶æ„äº 2017 å¹´ 6 æœˆæ¨å‡ºã€‚åŸå§‹ç ”ç©¶çš„é‡ç‚¹æ˜¯ç¿»è¯‘ä»»åŠ¡ã€‚éšåæ¨å‡ºäº†å‡ ä¸ªæœ‰å½±å“åŠ›çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š</p><ul><li>2018 å¹´ 6 æœˆï¼šGPTï¼Œç¬¬ä¸€ä¸ªé¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼Œç”¨äºå„ç§ NLP ä»»åŠ¡çš„å¾®è°ƒå¹¶è·å¾—æœ€å…ˆè¿›çš„ç»“æœ</li><li>2018 å¹´ 10 æœˆï¼šBERTï¼Œå¦ä¸€ä¸ªå¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨ç”Ÿæˆæ›´å¥½çš„å¥å­æ‘˜è¦</li><li>2019 å¹´ 2 æœˆï¼šGPT-2ï¼ŒGPT çš„æ”¹è¿›ï¼ˆå’Œæ›´å¤§ï¼‰ç‰ˆæœ¬</li><li>2019 å¹´ 10 æœˆï¼šDistilBERTï¼ŒBERT çš„è’¸é¦ç‰ˆæœ¬ï¼Œé€Ÿåº¦æé«˜ 60%ï¼Œå†…å­˜å‡è½» 40%ï¼Œä½†ä»ä¿ç•™ BERT 97% çš„æ€§èƒ½</li><li>2019 å¹´ 10 æœˆï¼šBART å’Œ T5ï¼Œä¸¤ä¸ªä½¿ç”¨ä¸åŸå§‹ Transformer æ¨¡å‹ç›¸åŒæ¶æ„çš„å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç¬¬ä¸€ä¸ªè¿™æ ·åšï¼‰</li><li>2020 å¹´ 5 æœˆï¼ŒGPT-3ï¼ŒGPT-2 çš„æ›´å¤§ç‰ˆæœ¬ï¼Œæ— éœ€å¾®è°ƒå³å¯åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼ˆç§°ä¸ºé›¶æ ·æœ¬å­¦ä¹ zero-shot learningï¼‰</li></ul><p>å¤§ä½“ä¸Šï¼Œå®ƒä»¬å¯ä»¥åˆ†ä¸ºä¸‰ç±»ï¼š</p><ul><li>GPTç±»ï¼ˆåˆç§°ä¸ºè‡ªå›å½’ Transformer æ¨¡å‹ï¼‰ï¼šåªä½¿ç”¨transformer-decoderéƒ¨åˆ†</li><li>BERTç±»ï¼ˆåˆç§°ä¸ºè‡ªç¼–ç  Transformer æ¨¡å‹ï¼‰ï¼šåªä½¿ç”¨transformer-encoderéƒ¨åˆ†</li><li>BART/T5ç±»ï¼ˆåˆç§°ä¸ºåºåˆ—åˆ°åºåˆ— Transformer æ¨¡å‹ï¼‰ï¼šä½¿ç”¨Transformer-encoder-decoderéƒ¨åˆ†</li></ul><p>å®ƒä»¬çš„åˆ†ç±»ã€å…·ä½“æ¨¡å‹ã€ä¸»è¦åº”ç”¨ä»»åŠ¡å¦‚ä¸‹ï¼š<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/hf_2.jpg?raw=true" width="800" alt="" align="center" /></p><p>å…¶ä»–éœ€è¦çŸ¥é“çš„ï¼š</p><ul><li>Transformersæ˜¯è¯­è¨€æ¨¡å‹</li><li>Transformersæ˜¯å¤§æ¨¡å‹</li><li>Transformersçš„åº”ç”¨é€šè¿‡é¢„è®­ç»ƒå’Œå¾®è°ƒä¸¤ä¸ªè¿‡ç¨‹</li></ul><h3 id="åè¯è§£é‡Šï¼šArchitectureå’ŒCheckpoints"><a href="#åè¯è§£é‡Šï¼šArchitectureå’ŒCheckpoints" class="headerlink" title="åè¯è§£é‡Šï¼šArchitectureå’ŒCheckpoints"></a>åè¯è§£é‡Šï¼šArchitectureå’ŒCheckpoints</h3><p><strong>Architecture/æ¶æ„</strong>ï¼šå®šä¹‰äº†æ¨¡å‹çš„åŸºæœ¬ç»“æ„å’ŒåŸºæœ¬è¿ç®—ã€‚<br><strong>Checkpoints/æ£€æŸ¥ç‚¹</strong>ï¼šæ¨¡å‹çš„æŸä¸ªè®­ç»ƒçŠ¶æ€ï¼ŒåŠ è½½æ­¤checkpointä¼šåŠ è½½æ­¤æ—¶çš„æƒé‡ã€‚è®­ç»ƒæ—¶å¯ä»¥é€‰æ‹©è‡ªåŠ¨ä¿å­˜checkpointã€‚æ¨¡å‹åœ¨è®­ç»ƒæ—¶å¯ä»¥è®¾ç½®è‡ªåŠ¨ä¿å­˜äºæŸä¸ªæ—¶é—´ç‚¹ï¼ˆæ¯”å¦‚æ¨¡å‹è®­ç»ƒäº†ä¸€è½®epochï¼Œæ›´æ–°äº†å‚æ•°ï¼Œå°†è¿™ä¸ªçŠ¶æ€çš„æ¨¡å‹ä¿å­˜ä¸‹æ¥ï¼Œä¸ºä¸€ä¸ªcheckpointã€‚ï¼‰ æ‰€ä»¥æ¯ä¸ªcheckpointå¯¹åº”æ¨¡å‹çš„ä¸€ä¸ªçŠ¶æ€ï¼Œä¸€ç»„æƒé‡ã€‚</p><h1 id="ä½¿ç”¨Transformers"><a href="#ä½¿ç”¨Transformers" class="headerlink" title="ä½¿ç”¨Transformers"></a>ä½¿ç”¨Transformers</h1><h2 id="3ä¸ªå¤„ç†æ­¥éª¤"><a href="#3ä¸ªå¤„ç†æ­¥éª¤" class="headerlink" title="3ä¸ªå¤„ç†æ­¥éª¤"></a>3ä¸ªå¤„ç†æ­¥éª¤</h2><p>å°†ä¸€äº›æ–‡æœ¬ä¼ é€’åˆ°pipelineæ—¶æ¶‰åŠ3ä¸ªä¸»è¦æ­¥éª¤ï¼š</p><ol><li>æ–‡æœ¬è¢«é¢„å¤„ç†ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼ã€‚</li><li>é¢„å¤„ç†åçš„è¾“å…¥ä¼ é€’ç»™æ¨¡å‹ã€‚</li><li>æ¨¡å‹çš„é¢„æµ‹ç»“æœè¢«åå¤„ç†ä¸ºäººç±»å¯ä»¥ç†è§£çš„æ ¼å¼ã€‚</li></ol><p>Pipelineå°†3ä¸ªæ­¥éª¤ç»„åˆåœ¨ä¸€èµ·ï¼šé¢„å¤„ç†/Tokenizerã€é€šè¿‡æ¨¡å‹ä¼ é€’è¾“å…¥/Modelå’Œåå¤„ç†/Post-Processingï¼š<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/hf_3.png?raw=true" width="800" alt="" align="center" /></p><h2 id="Tokenizer-é¢„å¤„ç†"><a href="#Tokenizer-é¢„å¤„ç†" class="headerlink" title="Tokenizer/é¢„å¤„ç†"></a>Tokenizer/é¢„å¤„ç†</h2><p>Tokenizerçš„ä½œç”¨ï¼š</p><ul><li>å°†è¾“å…¥æ‹†åˆ†ä¸ºç§°ä¸ºtokençš„å•è¯ã€å­è¯/subwordæˆ–ç¬¦å·/symbolsï¼ˆå¦‚æ ‡ç‚¹ç¬¦å·ï¼‰</li><li>å°†æ¯ä¸ªtokenæ˜ å°„åˆ°ä¸€ä¸ªæ•´æ•°</li><li>æ·»åŠ å¯èƒ½å¯¹æ¨¡å‹æœ‰ç”¨çš„å…¶ä»–è¾“å…¥</li></ul><h2 id="Going-Through-Models-ç©¿è¿‡æ¨¡å‹"><a href="#Going-Through-Models-ç©¿è¿‡æ¨¡å‹" class="headerlink" title="Going Through Models/ç©¿è¿‡æ¨¡å‹"></a>Going Through Models/ç©¿è¿‡æ¨¡å‹</h2><h3 id="æ¨¡å‹å®ä¾‹åŒ–"><a href="#æ¨¡å‹å®ä¾‹åŒ–" class="headerlink" title="æ¨¡å‹å®ä¾‹åŒ–"></a>æ¨¡å‹å®ä¾‹åŒ–</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModel</span><br><span class="line"></span><br><span class="line">checkpoint = <span class="string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span></span><br><span class="line">model = AutoModel.from_pretrained(checkpoint)</span><br></pre></td></tr></table></figure><p>åœ¨è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬ä¸‹è½½äº†åœ¨pipelineä¸­ä½¿ç”¨çš„ç›¸åŒæ£€æŸ¥ç‚¹ï¼ˆå®é™…ä¸Šå·²ç»ç¼“å­˜ï¼‰å¹¶å°†æ¨¡å‹å®ä¾‹åŒ–ã€‚</p><h3 id="æ¨¡å‹çš„è¾“å‡ºï¼šé«˜ç»´å‘é‡"><a href="#æ¨¡å‹çš„è¾“å‡ºï¼šé«˜ç»´å‘é‡" class="headerlink" title="æ¨¡å‹çš„è¾“å‡ºï¼šé«˜ç»´å‘é‡"></a>æ¨¡å‹çš„è¾“å‡ºï¼šé«˜ç»´å‘é‡</h3><p>æ¨¡å‹çš„è¾“å‡ºå‘é‡é€šå¸¸æœ‰ä¸‰ä¸ªç»´åº¦ï¼š</p><ul><li>Batch size: ä¸€æ¬¡å¤„ç†çš„åºåˆ—æ•°</li><li>Sequence length: åºåˆ—å‘é‡çš„é•¿åº¦</li><li>Hidden size: æ¯ä¸ªæ¨¡å‹è¾“å…¥å¤„ç†åçš„å‘é‡ç»´åº¦ï¼ˆhidden state vectorï¼‰</li></ul><h3 id="Model-Headsï¼šä¸ºäº†å¤„ç†ä¸åŒçš„ä»»åŠ¡"><a href="#Model-Headsï¼šä¸ºäº†å¤„ç†ä¸åŒçš„ä»»åŠ¡" class="headerlink" title="Model Headsï¼šä¸ºäº†å¤„ç†ä¸åŒçš„ä»»åŠ¡"></a>Model Headsï¼šä¸ºäº†å¤„ç†ä¸åŒçš„ä»»åŠ¡</h3><p>Model heads:å°†éšè—çŠ¶æ€çš„é«˜ç»´å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å®ƒä»¬æŠ•å½±åˆ°ä¸åŒçš„ç»´åº¦ä¸Šã€‚å®ƒä»¬é€šå¸¸ç”±ä¸€ä¸ªæˆ–å‡ ä¸ªçº¿æ€§å±‚ç»„æˆã€‚<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/hf_4.png?raw=true" width="800" alt="è¿™ä¸ªå›¾è¡¨ç¤ºäº†Pipelineç¬¬äºŒæ­¥åœ¨ç»è¿‡æ¨¡å‹æ—¶å‘ç”Ÿçš„äº‹æƒ…ã€‚" align="center" /><br>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œç´«è‰²ä»£è¡¨å‘é‡ï¼Œç²‰è‰²ä»£è¡¨æ¨¡ç»„ï¼ŒEmbeddings+layersè¡¨ç¤ºTransformerçš„æ¶æ„ï¼Œç»è¿‡è¿™å±‚æ¶æ„åçš„è¾“å‡ºé€å…¥Model Headè¿›è¡Œå¤„ç†ï¼Œä»è€Œåº”ç”¨åˆ°ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ã€‚<br>ğŸ¤— Transformers ä¸­æœ‰è®¸å¤šä¸åŒçš„Headæ¶æ„å¯ç”¨ï¼Œæ¯ä¸€ç§æ¶æ„éƒ½å›´ç»•ç€å¤„ç†ç‰¹å®šä»»åŠ¡è€Œè®¾è®¡ã€‚ ä¸‹é¢åˆ—ä¸¾äº†éƒ¨åˆ†Model headsï¼š</p><ul><li>*Model (retrieve the hidden states)</li><li>*ForCausalLM</li><li>*ForMaskedLM</li><li>*ForMultipleChoice</li><li>*ForQuestionAnswering</li><li>*ForSequenceClassification</li><li>*ForTokenClassification</li><li>and others ğŸ¤—</li></ul><h2 id="Post-processing-åå¤„ç†"><a href="#Post-processing-åå¤„ç†" class="headerlink" title="Post-processing/åå¤„ç†"></a>Post-processing/åå¤„ç†</h2><p>ä»æ¨¡å‹ä¸­è·å¾—çš„ä½œä¸ºè¾“å‡ºçš„å€¼æœ¬èº«å¹¶ä¸ä¸€å®šæœ‰æ„ä¹‰ã€‚è¦è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œå®ƒä»¬éœ€è¦ç»è¿‡ä¸€ä¸ª SoftMax å±‚ã€‚</p><h1 id="å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹"><a href="#å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹" class="headerlink" title="å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹"></a>å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹</h1><h2 id="æ•°æ®å¤„ç†"><a href="#æ•°æ®å¤„ç†" class="headerlink" title="æ•°æ®å¤„ç†"></a>æ•°æ®å¤„ç†</h2><p>åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨MRPCï¼ˆMicrosoft Research Praphrase Corpusï¼‰æ•°æ®é›†ä½œä¸ºç¤ºä¾‹ã€‚è¯¥DataSetç”±5,801å¯¹å¥å­ç»„æˆï¼Œæ ‡ç­¾æŒ‡ç¤ºå®ƒä»¬æ˜¯å¦æ˜¯åŒä¹‰å¥ï¼ˆå³ä¸¤ä¸ªå¥å­æ˜¯å¦è¡¨ç¤ºç›¸åŒçš„æ„æ€ï¼‰ã€‚ æˆ‘ä»¬é€‰æ‹©å®ƒæ˜¯å› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå°å‹æ•°æ®é›†ï¼Œå› æ­¤å¯ä»¥è½»æ¾è®­ç»ƒã€‚</p><h3 id="ä»Hubä¸ŠåŠ è½½æ•°æ®é›†"><a href="#ä»Hubä¸ŠåŠ è½½æ•°æ®é›†" class="headerlink" title="ä»Hubä¸ŠåŠ è½½æ•°æ®é›†"></a>ä»Hubä¸ŠåŠ è½½æ•°æ®é›†</h3><p>Hubä¸ä»…åŒ…å«æ¨¡å‹ï¼Œè¿˜å«æœ‰å¤šç§è¯­è¨€çš„datasetsã€‚<br>ä¾‹å¦‚ï¼ŒMRPCæ•°æ®é›†æ˜¯æ„æˆ GLUE benchmarkçš„ 10 ä¸ªæ•°æ®é›†ä¹‹ä¸€ã€‚GLUEï¼ˆGeneral Language Understanding Evaluationï¼‰æ˜¯ä¸€ä¸ªå¤šä»»åŠ¡çš„è‡ªç„¶è¯­è¨€ç†è§£åŸºå‡†å’Œåˆ†æå¹³å°ã€‚GLUEåŒ…å«ä¹é¡¹NLUä»»åŠ¡ï¼Œè¯­è¨€å‡ä¸ºè‹±è¯­ã€‚GLUEä¹é¡¹ä»»åŠ¡æ¶‰åŠåˆ°è‡ªç„¶è¯­è¨€æ¨æ–­ã€æ–‡æœ¬è•´å«ã€æƒ…æ„Ÿåˆ†æã€è¯­ä¹‰ç›¸ä¼¼ç­‰å¤šä¸ªä»»åŠ¡ã€‚åƒBERTã€XLNetã€RoBERTaã€ERINEã€T5ç­‰çŸ¥åæ¨¡å‹éƒ½ä¼šåœ¨æ­¤åŸºå‡†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚</p><p>ğŸ¤— Datasetsåº“æä¾›äº†ä¸€ä¸ªéå¸¸ç®€å•çš„å‘½ä»¤æ¥ä¸‹è½½å’Œç¼“å­˜Hubä¸Šçš„datasetã€‚ æˆ‘ä»¬å¯ä»¥åƒè¿™æ ·ä¸‹è½½ MRPC æ•°æ®é›†ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>raw_datasets = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>raw_datasets</span><br></pre></td></tr></table></figure><p>è¾“å‡ºå¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence1&#x27;</span>, <span class="string">&#x27;sentence2&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">3668</span></span><br><span class="line">    &#125;)</span><br><span class="line">    validation: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence1&#x27;</span>, <span class="string">&#x27;sentence2&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">408</span></span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [<span class="string">&#x27;sentence1&#x27;</span>, <span class="string">&#x27;sentence2&#x27;</span>, <span class="string">&#x27;label&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>],</span><br><span class="line">        num_rows: <span class="number">1725</span></span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>è¿™æ ·å°±å¾—åˆ°ä¸€ä¸ªDatasetDictå¯¹è±¡ï¼ŒåŒ…å«è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œè®­ç»ƒé›†ä¸­æœ‰3,668 ä¸ªå¥å­å¯¹ï¼ŒéªŒè¯é›†ä¸­æœ‰408å¯¹ï¼Œæµ‹è¯•é›†ä¸­æœ‰1,725 å¯¹ã€‚æ¯ä¸ªå¥å­å¯¹åŒ…å«å››ä¸ªå­—æ®µï¼šâ€™sentence1â€™, â€˜sentence2â€™, â€˜labelâ€™å’Œ â€˜idxâ€™ã€‚</p><p>æˆ‘ä»¬å¯ä»¥é€šè¿‡ç´¢å¼•è®¿é—®raw_datasets çš„å¥å­å¯¹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>raw_train_dataset = raw_datasets[<span class="string">&quot;train&quot;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>raw_train_dataset[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>è¾“å‡ºå¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;sentence1&#x27;</span>: <span class="string">&#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;sentence2&#x27;</span>: <span class="string">&#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;label&#x27;</span>: <span class="number">1</span>, </span><br><span class="line"><span class="string">&#x27;idx&#x27;</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥é€šè¿‡featuresè·å¾—æ•°æ®é›†çš„å­—æ®µç±»å‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>raw_train_dataset.features</span><br></pre></td></tr></table></figure><p>è¾“å‡ºå¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="string">&#x27;string&#x27;</span>, <span class="built_in">id</span>=<span class="literal">None</span>), </span><br><span class="line"><span class="string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="string">&#x27;string&#x27;</span>, <span class="built_in">id</span>=<span class="literal">None</span>), </span><br><span class="line"><span class="string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="number">2</span>, names=[<span class="string">&#x27;not_equivalent&#x27;</span>, <span class="string">&#x27;equivalent&#x27;</span>], names_file=<span class="literal">None</span>, <span class="built_in">id</span>=<span class="literal">None</span>), </span><br><span class="line"><span class="string">&#x27;idx&#x27;</span>: Value(dtype=<span class="string">&#x27;int32&#x27;</span>, <span class="built_in">id</span>=<span class="literal">None</span>)&#125;</span><br></pre></td></tr></table></figure><blockquote><p>TIPSï¼š</p><ol><li>æ²¡æœ‰æ•°æ®é›†çš„è¯é¦–å…ˆå®‰è£…ä¸€ä¸‹ï¼š<code>pip install datasets</code></li><li>è¿™é‡Œå¾ˆå®¹æ˜“å‡ºç°è¿æ¥é”™è¯¯ï¼Œè§£å†³æ–¹æ³•å¦‚ä¸‹ï¼š<a href="https://blog.csdn.net/qq_20849045/article/details/117462846?utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1.no_search_link">https://blog.csdn.net/qq_20849045/article/details/117462846?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link</a></li></ol></blockquote><h3 id="æ•°æ®é›†é¢„å¤„ç†"><a href="#æ•°æ®é›†é¢„å¤„ç†" class="headerlink" title="æ•°æ®é›†é¢„å¤„ç†"></a>æ•°æ®é›†é¢„å¤„ç†</h3><p>é€šè¿‡æ•°æ®é›†é¢„å¤„ç†ï¼Œæˆ‘ä»¬å°†æ–‡æœ¬è½¬æ¢æˆæ¨¡å‹èƒ½ç†è§£çš„å‘é‡ã€‚è¿™ä¸ªè¿‡ç¨‹é€šè¿‡Tokenizerå®ç°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>checkpoint = <span class="string">&quot;bert-base-uncased&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenized_sentences_1 = tokenizer(raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence1&quot;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenized_sentences_2 = tokenizer(raw_datasets[<span class="string">&quot;train&quot;</span>][<span class="string">&quot;sentence2&quot;</span>])</span><br></pre></td></tr></table></figure><p>ï¼ˆTODOï¼‰</p><h2 id="ä½¿ç”¨Trainer-APIå¾®è°ƒä¸€ä¸ªæ¨¡å‹"><a href="#ä½¿ç”¨Trainer-APIå¾®è°ƒä¸€ä¸ªæ¨¡å‹" class="headerlink" title="ä½¿ç”¨Trainer APIå¾®è°ƒä¸€ä¸ªæ¨¡å‹"></a>ä½¿ç”¨Trainer APIå¾®è°ƒä¸€ä¸ªæ¨¡å‹</h2><h3 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h3><h3 id="è¯„ä¼°å‡½æ•°"><a href="#è¯„ä¼°å‡½æ•°" class="headerlink" title="è¯„ä¼°å‡½æ•°"></a>è¯„ä¼°å‡½æ•°</h3><h1 id="è¡¥å……éƒ¨åˆ†"><a href="#è¡¥å……éƒ¨åˆ†" class="headerlink" title="è¡¥å……éƒ¨åˆ†"></a>è¡¥å……éƒ¨åˆ†</h1><h2 id="ä¸ºä»€ä¹ˆ4ä¸­ç”¨Traineræ¥å¾®è°ƒæ¨¡å‹ï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆ4ä¸­ç”¨Traineræ¥å¾®è°ƒæ¨¡å‹ï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆ4ä¸­ç”¨Traineræ¥å¾®è°ƒæ¨¡å‹ï¼Ÿ"></a>ä¸ºä»€ä¹ˆ4ä¸­ç”¨Traineræ¥å¾®è°ƒæ¨¡å‹ï¼Ÿ</h2><h2 id="Training-Argumentsä¸»è¦å‚æ•°"><a href="#Training-Argumentsä¸»è¦å‚æ•°" class="headerlink" title="Training Argumentsä¸»è¦å‚æ•°"></a>Training Argumentsä¸»è¦å‚æ•°</h2><h2 id="ä¸åŒæ¨¡å‹çš„åŠ è½½æ–¹å¼"><a href="#ä¸åŒæ¨¡å‹çš„åŠ è½½æ–¹å¼" class="headerlink" title="ä¸åŒæ¨¡å‹çš„åŠ è½½æ–¹å¼"></a>ä¸åŒæ¨¡å‹çš„åŠ è½½æ–¹å¼</h2><h2 id="Dynamic-Paddingâ€”â€”åŠ¨æ€å¡«å……æŠ€æœ¯"><a href="#Dynamic-Paddingâ€”â€”åŠ¨æ€å¡«å……æŠ€æœ¯" class="headerlink" title="Dynamic Paddingâ€”â€”åŠ¨æ€å¡«å……æŠ€æœ¯"></a>Dynamic Paddingâ€”â€”åŠ¨æ€å¡«å……æŠ€æœ¯</h2><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨â€“åœ¨çº¿é˜…è¯» <a href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a></li><li>Huggingfaceå®˜æ–¹æ•™ç¨‹ <a href="https://huggingface.co/course/chapter1">https://huggingface.co/course/chapter1</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;em&gt;è¯¥éƒ¨åˆ†çš„å†…å®¹ç¿»è¯‘è‡ªğŸ¤—HuggingFaceå®˜ç½‘æ•™ç¨‹ç¬¬1éƒ¨åˆ†ï¼ˆ1-4ç« ï¼‰ï¼Œè§ &lt;a href=&quot;https://huggingface.co/course/chapter1&quot;&gt;https://huggingface.co/course/chapter1&lt;/a&gt;ã€‚è¯¥ç³»</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬29æœŸ åŸºäºtransformerçš„NLP" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="é¢„è®­ç»ƒæ¨¡å‹" scheme="http://example.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="BERT" scheme="http://example.com/tags/BERT/"/>
    
    <category term="transfomer" scheme="http://example.com/tags/transfomer/"/>
    
  </entry>
  
  <entry>
    <title>Task05 ç¼–å†™BERTæ¨¡å‹</title>
    <link href="http://example.com/nlp-transformer-task05/"/>
    <id>http://example.com/nlp-transformer-task05/</id>
    <published>2021-09-20T19:01:35.000Z</published>
    <updated>2021-10-02T09:21:40.680Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>æœ¬éƒ¨åˆ†æ˜¯BERTæºç çš„è§£è¯»ï¼Œæ¥è‡ªHuggingFace/transfomers/BERT[1]ã€‚<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/bert_1.png?raw=true" width="600" alt="" align="center" /></p><p>å¦‚å›¾æ‰€ç¤ºï¼Œä»£ç ç»“æ„å’Œä½œç”¨å¦‚ä¸‹ï¼š</p><ul><li>BertTokenizer é¢„å¤„ç†å’Œåˆ‡è¯</li><li>BertModel<ul><li>BertEmbeddings è¯åµŒå…¥</li><li>BertEncoder<ul><li>BertAttention æ³¨æ„åŠ›æœºåˆ¶</li><li>BertIntermediate å…¨è¿æ¥å’Œæ¿€æ´»å‡½æ•°</li><li>BertOutput å…¨è¿æ¥ã€æ®‹å·®é“¾æ¥å’Œæ­£åˆ™åŒ–</li></ul></li><li>BertPooler å–å‡º[CLS]å¯¹åº”çš„å‘é‡ï¼Œç„¶åé€šè¿‡å…¨è¿æ¥å±‚å’Œæ¿€æ´»å‡½æ•°åè¾“å‡ºç»“æœ</li></ul></li></ul><h1 id="BERTçš„å®ç°"><a href="#BERTçš„å®ç°" class="headerlink" title="BERTçš„å®ç°"></a>BERTçš„å®ç°</h1><h2 id="BertConfig"><a href="#BertConfig" class="headerlink" title="BertConfig"></a>BertConfig</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">classtransformers.BertConfig(vocab_size=<span class="number">30522</span>, hidden_size=<span class="number">768</span>, </span><br><span class="line">    num_hidden_layers=<span class="number">12</span>, num_attention_heads=<span class="number">12</span>, intermediate_size=<span class="number">3072</span>, </span><br><span class="line">    hidden_act=<span class="string">&#x27;gelu&#x27;</span>, hidden_dropout_prob=<span class="number">0.1</span>, attention_probs_dropout_prob=<span class="number">0.1</span></span><br><span class="line">    , max_position_embeddings=<span class="number">512</span>, type_vocab_size=<span class="number">2</span>, initializer_range=<span class="number">0.02</span>, </span><br><span class="line">    layer_norm_eps=<span class="number">1e-12</span>, pad_token_id=<span class="number">0</span>, gradient_checkpointing=<span class="literal">False</span>, </span><br><span class="line">    position_embedding_type=<span class="string">&#x27;absolute&#x27;</span>, use_cache=<span class="literal">True</span>, classifier_dropout=<span class="literal">None</span>,</span><br><span class="line">     **kwargs)</span><br></pre></td></tr></table></figure><p>è¿™æ˜¯å­˜å‚¨BertModelï¼ˆTorch.nn.Moduleçš„å­ç±»ï¼‰æˆ–TFBertModelï¼ˆtf.keras.Modelçš„å­ç±»ï¼‰é…ç½®çš„é…ç½®ç±»ã€‚å®ƒç”¨äºæ ¹æ®æŒ‡å®šçš„å‚æ•°æ¥å®ä¾‹åŒ–BERTæ¨¡å‹ï¼Œå®šä¹‰æ¨¡å‹æ¶æ„ã€‚</p><p>é…ç½®å¯¹è±¡ä»PretrainedConfigç»§æ‰¿ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚</p><p>å‚æ•°ï¼š</p><ul><li>vocab_size: BERTæ¨¡å‹çš„è¯æ±‡é‡ï¼Œå®šä¹‰äº†èƒ½è¢«inputs_idsè¡¨ç¤ºçš„tokenæ•°é‡ã€‚</li><li>hidden_size: </li></ul><h2 id="BertTokenizer"><a href="#BertTokenizer" class="headerlink" title="BertTokenizer"></a>BertTokenizer</h2><h2 id="BertModel"><a href="#BertModel" class="headerlink" title="BertModel"></a>BertModel</h2><h1 id="BERTçš„åº”ç”¨"><a href="#BERTçš„åº”ç”¨" class="headerlink" title="BERTçš„åº”ç”¨"></a>BERTçš„åº”ç”¨</h1><h2 id="BertForPreTraining"><a href="#BertForPreTraining" class="headerlink" title="BertForPreTraining"></a>BertForPreTraining</h2><h2 id="BertForNextSentencePrediction"><a href="#BertForNextSentencePrediction" class="headerlink" title="BertForNextSentencePrediction"></a>BertForNextSentencePrediction</h2><h2 id="BertForSequenceClassification"><a href="#BertForSequenceClassification" class="headerlink" title="BertForSequenceClassification"></a>BertForSequenceClassification</h2><h2 id="BertForMultipleChoice"><a href="#BertForMultipleChoice" class="headerlink" title="BertForMultipleChoice"></a>BertForMultipleChoice</h2><h2 id="BertForTokenClassification"><a href="#BertForTokenClassification" class="headerlink" title="BertForTokenClassification"></a>BertForTokenClassification</h2><h2 id="BertForQuestionAnswering"><a href="#BertForQuestionAnswering" class="headerlink" title="BertForQuestionAnswering"></a>BertForQuestionAnswering</h2><h1 id="BERTçš„è®­ç»ƒå’Œä¼˜åŒ–"><a href="#BERTçš„è®­ç»ƒå’Œä¼˜åŒ–" class="headerlink" title="BERTçš„è®­ç»ƒå’Œä¼˜åŒ–"></a>BERTçš„è®­ç»ƒå’Œä¼˜åŒ–</h1><h2 id="Pre-Training"><a href="#Pre-Training" class="headerlink" title="Pre-Training"></a>Pre-Training</h2><h2 id="Fine-Tuning"><a href="#Fine-Tuning" class="headerlink" title="Fine-Tuning"></a>Fine-Tuning</h2><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>HuggingFace/transfomers/BERT <a href="https://huggingface.co/transformers/model_doc/bert.html#">https://huggingface.co/transformers/model_doc/bert.html#</a></li><li>åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨â€“åœ¨çº¿é˜…è¯» <a href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h1&gt;&lt;p&gt;æœ¬éƒ¨åˆ†æ˜¯BERTæºç çš„è§£è¯»ï¼Œæ¥è‡ªHuggingFace/transfomers/BERT[1</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬29æœŸ åŸºäºtransformerçš„NLP" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="é¢„è®­ç»ƒæ¨¡å‹" scheme="http://example.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="BERT" scheme="http://example.com/tags/BERT/"/>
    
    <category term="transfomer" scheme="http://example.com/tags/transfomer/"/>
    
  </entry>
  
  <entry>
    <title>Task04 å­¦ä¹ GPT</title>
    <link href="http://example.com/nlp-transformer-task04/"/>
    <id>http://example.com/nlp-transformer-task04/</id>
    <published>2021-09-19T12:02:17.000Z</published>
    <updated>2021-10-02T09:21:36.582Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ä»è¯­è¨€æ¨¡å‹è¯´èµ·"><a href="#ä»è¯­è¨€æ¨¡å‹è¯´èµ·" class="headerlink" title="ä»è¯­è¨€æ¨¡å‹è¯´èµ·"></a>ä»è¯­è¨€æ¨¡å‹è¯´èµ·</h1><h2 id="è‡ªç¼–ç è¯­è¨€æ¨¡å‹ï¼ˆauto-encoderï¼‰"><a href="#è‡ªç¼–ç è¯­è¨€æ¨¡å‹ï¼ˆauto-encoderï¼‰" class="headerlink" title="è‡ªç¼–ç è¯­è¨€æ¨¡å‹ï¼ˆauto-encoderï¼‰"></a>è‡ªç¼–ç è¯­è¨€æ¨¡å‹ï¼ˆauto-encoderï¼‰</h2><p>è‡ªç¼–ç è¯­è¨€æ¨¡å‹é€šè¿‡éšæœºMaskè¾“å…¥çš„éƒ¨åˆ†å•è¯ï¼Œç„¶åé¢„è®­ç»ƒçš„ç›®æ ‡æ˜¯é¢„æµ‹è¢«Maskçš„å•è¯ï¼Œä¸ä»…å¯ä»¥èå…¥ä¸Šæ–‡ä¿¡æ¯ï¼Œè¿˜å¯ä»¥è‡ªç„¶çš„èå…¥ä¸‹æ–‡ä¿¡æ¯ã€‚ex. BERT.</p><ul><li>ä¼˜ç‚¹ï¼šè‡ªç„¶åœ°èå…¥åŒå‘è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶çœ‹åˆ°è¢«é¢„æµ‹å•è¯çš„ä¸Šæ–‡å’Œä¸‹æ–‡</li><li>ç¼ºç‚¹ï¼šè®­ç»ƒå’Œé¢„æµ‹ä¸ä¸€è‡´ã€‚è®­ç»ƒçš„æ—¶å€™è¾“å…¥å¼•å…¥äº†[Mask]æ ‡è®°ï¼Œä½†æ˜¯åœ¨é¢„æµ‹é˜¶æ®µå¾€å¾€æ²¡æœ‰è¿™ä¸ª[Mask]æ ‡è®°ï¼Œå¯¼è‡´é¢„è®­ç»ƒé˜¶æ®µå’ŒFine-tuningé˜¶æ®µä¸ä¸€è‡´ã€‚</li></ul><h2 id="è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆauto-regressiveï¼‰"><a href="#è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆauto-regressiveï¼‰" class="headerlink" title="è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆauto-regressiveï¼‰"></a>è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆauto-regressiveï¼‰</h2><p>è¯­è¨€æ¨¡å‹æ ¹æ®è¾“å…¥å¥å­çš„ä¸€éƒ¨åˆ†æ–‡æœ¬æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚ex. GPT-2</p><ul><li>ä¼˜ç‚¹ï¼šå¯¹äºç”Ÿæˆç±»çš„NLPä»»åŠ¡ï¼Œæ¯”å¦‚æ–‡æœ¬æ‘˜è¦ï¼Œæœºå™¨ç¿»è¯‘ç­‰ï¼Œä»å·¦å‘å³çš„ç”Ÿæˆå†…å®¹ï¼Œå¤©ç„¶å’Œè‡ªå›å½’è¯­è¨€æ¨¡å‹å¥‘åˆã€‚</li><li>ç¼ºç‚¹ï¼šç”±äºä¸€èˆ¬æ˜¯ä»å·¦åˆ°å³ï¼ˆå½“ç„¶ä¹Ÿå¯èƒ½ä»å³åˆ°å·¦ï¼‰ï¼Œæ‰€ä»¥åªèƒ½åˆ©ç”¨ä¸Šæ–‡æˆ–è€…ä¸‹æ–‡çš„ä¿¡æ¯ï¼Œä¸èƒ½åŒæ—¶åˆ©ç”¨ä¸Šæ–‡å’Œä¸‹æ–‡çš„ä¿¡æ¯ã€‚</li></ul><h1 id="Transformer-BERT-GPT-2çš„å…³ç³»"><a href="#Transformer-BERT-GPT-2çš„å…³ç³»" class="headerlink" title="Transformer, BERT, GPT-2çš„å…³ç³»"></a>Transformer, BERT, GPT-2çš„å…³ç³»</h1><p>Transformerçš„Encoderè¿›åŒ–æˆäº†BERTï¼ŒDecoderè¿›åŒ–æˆäº†GPT2ã€‚</p><p>å¦‚æœè¦ä½¿ç”¨Transformeræ¥è§£å†³è¯­è¨€æ¨¡å‹ä»»åŠ¡ï¼Œå¹¶ä¸éœ€è¦å®Œæ•´çš„Encoderéƒ¨åˆ†å’ŒDecoderéƒ¨åˆ†ï¼Œäºæ˜¯åœ¨åŸå§‹Transformerä¹‹åçš„è®¸å¤šç ”ç©¶å·¥ä½œä¸­ï¼Œäººä»¬å°è¯•åªä½¿ç”¨Transformer Encoderæˆ–è€…Decoderè¿›è¡Œé¢„è®­ç»ƒã€‚æ¯”å¦‚BERTåªä½¿ç”¨äº†Encoderéƒ¨åˆ†è¿›è¡Œmasked language modelï¼ˆè‡ªç¼–ç ï¼‰è®­ç»ƒï¼ŒGPT-2ä¾¿æ˜¯åªä½¿ç”¨äº†Decoderéƒ¨åˆ†è¿›è¡Œè‡ªå›å½’ï¼ˆauto regressiveï¼‰è¯­è¨€æ¨¡å‹è®­ç»ƒã€‚</p><h1 id="GPT-2æ¦‚è¿°"><a href="#GPT-2æ¦‚è¿°" class="headerlink" title="GPT-2æ¦‚è¿°"></a>GPT-2æ¦‚è¿°</h1><h2 id="æ¨¡å‹çš„è¾“å…¥"><a href="#æ¨¡å‹çš„è¾“å…¥" class="headerlink" title="æ¨¡å‹çš„è¾“å…¥"></a>æ¨¡å‹çš„è¾“å…¥</h2><p>è¾“å…¥çš„å¤„ç†åˆ†ä¸ºä¸¤æ­¥ï¼štoken embedding + position encodingã€‚å³:</p><ol><li>åœ¨åµŒå…¥çŸ©é˜µä¸­æŸ¥æ‰¾è¾“å…¥çš„å•è¯çš„å¯¹åº”çš„embeddingå‘é‡</li><li>èå…¥ä½ç½®ç¼–ç </li></ol><h2 id="Decoderå±‚"><a href="#Decoderå±‚" class="headerlink" title="Decoderå±‚"></a>Decoderå±‚</h2><p>æ¯ä¸€å±‚decoderçš„ç»„æˆï¼šMasked Self-Attention + Feed Forward Neural Network</p><p>Self-Attentionæ‰€åšçš„äº‹æƒ…æ˜¯ï¼šå®ƒé€šè¿‡å¯¹å¥å­ç‰‡æ®µä¸­æ¯ä¸ªè¯çš„ç›¸å…³æ€§æ‰“åˆ†ï¼Œå¹¶å°†è¿™äº›è¯çš„è¡¨ç¤ºå‘é‡æ ¹æ®ç›¸å…³æ€§åŠ æƒæ±‚å’Œï¼Œä»è€Œè®©æ¨¡å‹èƒ½å¤Ÿå°†è¯å’Œå…¶ä»–ç›¸å…³è¯å‘é‡çš„ä¿¡æ¯èåˆèµ·æ¥ã€‚</p><p>Masked Self-Attentionåšçš„æ˜¯ï¼šå°†maskä½ç½®å¯¹åº”çš„çš„attention scoreå˜æˆä¸€ä¸ªéå¸¸å°çš„æ•°å­—æˆ–è€…0ï¼Œè®©å…¶ä»–å•è¯å†self attentionçš„æ—¶å€™ï¼ˆåŠ æƒæ±‚å’Œçš„æ—¶å€™ï¼‰ä¸è€ƒè™‘è¿™äº›å•è¯ã€‚</p><h2 id="æ¨¡å‹çš„è¾“å‡º"><a href="#æ¨¡å‹çš„è¾“å‡º" class="headerlink" title="æ¨¡å‹çš„è¾“å‡º"></a>æ¨¡å‹çš„è¾“å‡º</h2><p>å½“æ¨¡å‹é¡¶éƒ¨çš„Decoderå±‚äº§ç”Ÿè¾“å‡ºå‘é‡æ—¶ï¼Œæ¨¡å‹ä¼šå°†è¿™ä¸ªå‘é‡ä¹˜ä»¥ä¸€ä¸ªå·¨å¤§çš„åµŒå…¥çŸ©é˜µï¼ˆvocab size x embedding sizeï¼‰æ¥è®¡ç®—è¯¥å‘é‡å’Œæ‰€æœ‰å•è¯embeddingå‘é‡çš„ç›¸å…³å¾—åˆ†ã€‚è¿™ä¸ªç›¸ä¹˜çš„ç»“æœï¼Œè¢«è§£é‡Šä¸ºæ¨¡å‹è¯æ±‡è¡¨ä¸­æ¯ä¸ªè¯çš„åˆ†æ•°ï¼Œç»è¿‡softmaxä¹‹åè¢«è½¬æ¢æˆæ¦‚ç‡ã€‚</p><p>æˆ‘ä»¬å¯ä»¥é€‰æ‹©æœ€é«˜åˆ†æ•°çš„ tokenï¼ˆtop_k=1ï¼‰ï¼Œä¹Ÿå¯ä»¥åŒæ—¶è€ƒè™‘å…¶ä»–è¯ï¼ˆtop kï¼‰ã€‚å‡è®¾æ¯ä¸ªä½ç½®è¾“å‡ºkä¸ªtokenï¼Œå‡è®¾æ€»å…±è¾“å‡ºnä¸ªtokenï¼Œé‚£ä¹ˆåŸºäºnä¸ªå•è¯çš„è”åˆæ¦‚ç‡é€‰æ‹©çš„è¾“å‡ºåºåˆ—ä¼šæ›´å¥½ã€‚</p><p>æ¨¡å‹å®Œæˆä¸€æ¬¡è¿­ä»£ï¼Œè¾“å‡ºä¸€ä¸ªå•è¯ã€‚æ¨¡å‹ä¼šç»§ç»­è¿­ä»£ï¼Œç›´åˆ°æ‰€æœ‰çš„å•è¯éƒ½å·²ç»ç”Ÿæˆï¼Œæˆ–è€…ç›´åˆ°è¾“å‡ºäº†è¡¨ç¤ºå¥å­æœ«å°¾çš„tokenã€‚</p><h1 id="å…³äºSelf-Attention-Masked-Self-Attention"><a href="#å…³äºSelf-Attention-Masked-Self-Attention" class="headerlink" title="å…³äºSelf-Attention, Masked Self-Attention"></a>å…³äºSelf-Attention, Masked Self-Attention</h1><h2 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h2><p>Self-Attention ä¸»è¦é€šè¿‡ 3 ä¸ªæ­¥éª¤æ¥å®ç°ï¼š</p><ol><li>ä¸ºæ¯ä¸ªè·¯å¾„åˆ›å»º Queryã€Keyã€Value çŸ©é˜µã€‚</li><li>å¯¹äºæ¯ä¸ªè¾“å…¥çš„tokenï¼Œä½¿ç”¨å®ƒçš„Queryå‘é‡ä¸ºæ‰€æœ‰å…¶ä»–çš„Keyå‘é‡è¿›è¡Œæ‰“åˆ†ã€‚</li><li>å°† Value å‘é‡ä¹˜ä»¥å®ƒä»¬å¯¹åº”çš„åˆ†æ•°åæ±‚å’Œã€‚</li></ol><h2 id="Masked-Self-Attention"><a href="#Masked-Self-Attention" class="headerlink" title="Masked Self-Attention"></a>Masked Self-Attention</h2><p>åœ¨Self-Attentionçš„ç¬¬2æ­¥ï¼ŒæŠŠæœªæ¥çš„ token è¯„åˆ†è®¾ç½®ä¸º0ï¼Œå› æ­¤æ¨¡å‹ä¸èƒ½çœ‹åˆ°æœªæ¥çš„è¯ã€‚</p><p>è¿™ä¸ªå±è”½ï¼ˆmaskingï¼‰ç»å¸¸ç”¨ä¸€ä¸ªçŸ©é˜µæ¥å®ç°ï¼Œç§°ä¸º attention maskçŸ©é˜µã€‚<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/mask_1.jpg?raw=true" width="600" alt="" align="center" /><br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/mask_2.jpg?raw=true" width="600" alt="" align="center" /></p><h2 id="GPT-2ä¸­çš„Self-Attention"><a href="#GPT-2ä¸­çš„Self-Attention" class="headerlink" title="GPT-2ä¸­çš„Self-Attention"></a>GPT-2ä¸­çš„Self-Attention</h2><p>(skip)</p><h1 id="è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„åº”ç”¨"><a href="#è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„åº”ç”¨" class="headerlink" title="è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„åº”ç”¨"></a>è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„åº”ç”¨</h1><p>åº”ç”¨åœ¨ä¸‹æ¸¸å¹¶å–å¾—ä¸é”™æ•ˆæœçš„NLPä»»åŠ¡æœ‰ï¼šæœºå™¨ç¿»è¯‘ã€æ‘˜è¦ç”Ÿæˆã€éŸ³ä¹ç”Ÿæˆã€‚<em>ï¼ˆå¯è§ï¼Œä¸»è¦æ˜¯è·Ÿé¢„è®­ç»ƒä»»åŠ¡ç›¸ä¼¼çš„ç”Ÿæˆç±»ä»»åŠ¡ã€‚ï¼‰</em></p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨â€“åœ¨çº¿é˜…è¯» <a href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ä»è¯­è¨€æ¨¡å‹è¯´èµ·&quot;&gt;&lt;a href=&quot;#ä»è¯­è¨€æ¨¡å‹è¯´èµ·&quot; class=&quot;headerlink&quot; title=&quot;ä»è¯­è¨€æ¨¡å‹è¯´èµ·&quot;&gt;&lt;/a&gt;ä»è¯­è¨€æ¨¡å‹è¯´èµ·&lt;/h1&gt;&lt;h2 id=&quot;è‡ªç¼–ç è¯­è¨€æ¨¡å‹ï¼ˆauto-encoderï¼‰&quot;&gt;&lt;a href=&quot;#è‡ªç¼–ç è¯­è¨€æ¨¡å‹ï¼ˆauto</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬29æœŸ åŸºäºtransformerçš„NLP" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="é¢„è®­ç»ƒæ¨¡å‹" scheme="http://example.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="GPT" scheme="http://example.com/tags/GPT/"/>
    
  </entry>
  
  <entry>
    <title>Chapter01-02 PyTorchçš„ç®€ä»‹å’Œå®‰è£…ã€PyTorchåŸºç¡€çŸ¥è¯†</title>
    <link href="http://example.com/pytorch-chap01-02/"/>
    <id>http://example.com/pytorch-chap01-02/</id>
    <published>2021-09-18T02:26:03.000Z</published>
    <updated>2021-10-13T11:05:03.457Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¬¬ä¸€ç« -PyTorchçš„ç®€ä»‹å’Œå®‰è£…"><a href="#ç¬¬ä¸€ç« -PyTorchçš„ç®€ä»‹å’Œå®‰è£…" class="headerlink" title="ç¬¬ä¸€ç«  PyTorchçš„ç®€ä»‹å’Œå®‰è£…"></a>ç¬¬ä¸€ç«  PyTorchçš„ç®€ä»‹å’Œå®‰è£…</h1><h2 id="PyTorchç®€ä»‹"><a href="#PyTorchç®€ä»‹" class="headerlink" title="PyTorchç®€ä»‹"></a>PyTorchç®€ä»‹</h2><p>PyTorchæ˜¯ç”±Facebookäººå·¥æ™ºèƒ½ç ”ç©¶å°ç»„å¼€å‘çš„ä¸€ç§åŸºäºLuaç¼–å†™çš„Torchåº“çš„Pythonå®ç°çš„æ·±åº¦å­¦ä¹ åº“ï¼Œç›®å‰è¢«å¹¿æ³›åº”ç”¨äºå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œï¼Œè€Œéšç€Caffe2é¡¹ç›®å¹¶å…¥Pytorchï¼Œ Pytorchå¼€å§‹å½±å“åˆ°TensorFlowåœ¨æ·±åº¦å­¦ä¹ åº”ç”¨æ¡†æ¶é¢†åŸŸçš„åœ°ä½ã€‚æ€»çš„æ¥è¯´ï¼ŒPyTorchæ˜¯å½“å‰éš¾å¾—çš„ç®€æ´ä¼˜é›…ä¸”é«˜æ•ˆå¿«é€Ÿçš„æ¡†æ¶ã€‚å› æ­¤æœ¬è¯¾ç¨‹æˆ‘ä»¬é€‰æ‹©äº†PyTorchæ¥è¿›è¡Œå¼€æºå­¦ä¹ ã€‚</p><h2 id="PyTorchçš„å®‰è£…"><a href="#PyTorchçš„å®‰è£…" class="headerlink" title="PyTorchçš„å®‰è£…"></a>PyTorchçš„å®‰è£…</h2><p>PyTorchå®˜ç½‘ï¼š<a href="https://pytorch.org/">https://pytorch.org/</a></p><h2 id="PyTorchçš„å‘å±•å’Œä¼˜åŠ¿"><a href="#PyTorchçš„å‘å±•å’Œä¼˜åŠ¿" class="headerlink" title="PyTorchçš„å‘å±•å’Œä¼˜åŠ¿"></a>PyTorchçš„å‘å±•å’Œä¼˜åŠ¿</h2><p>â€œAll in Pytorchâ€.</p><h2 id="PyTorch-VS-TensorFlow"><a href="#PyTorch-VS-TensorFlow" class="headerlink" title="PyTorch VS TensorFlow"></a>PyTorch VS TensorFlow</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/03_torch_vs_tf.jpg?raw=true" width="600" alt="" align="center" /><h1 id="ç¬¬äºŒç« -PyTorchçš„åŸºç¡€çŸ¥è¯†"><a href="#ç¬¬äºŒç« -PyTorchçš„åŸºç¡€çŸ¥è¯†" class="headerlink" title="ç¬¬äºŒç«  PyTorchçš„åŸºç¡€çŸ¥è¯†"></a>ç¬¬äºŒç«  PyTorchçš„åŸºç¡€çŸ¥è¯†</h1><h2 id="Tensor-å¼ é‡"><a href="#Tensor-å¼ é‡" class="headerlink" title="Tensor/å¼ é‡"></a>Tensor/å¼ é‡</h2><p>å¼ é‡æ˜¯åŸºäºå‘é‡å’ŒçŸ©é˜µçš„æ¨å¹¿ï¼Œæ¯”å¦‚æˆ‘ä»¬å¯ä»¥å°†æ ‡é‡è§†ä¸ºé›¶é˜¶å¼ é‡ï¼ŒçŸ¢é‡å¯ä»¥è§†ä¸ºä¸€é˜¶å¼ é‡ï¼ŒçŸ©é˜µå°±æ˜¯äºŒé˜¶å¼ é‡ã€‚</p><ul><li>0ç»´å¼ é‡/æ ‡é‡ æ ‡é‡æ˜¯1ä¸ªæ•°å­—</li><li>1ç»´å¼ é‡/å‘é‡ 1ç»´å¼ é‡ç§°ä¸ºâ€œå‘é‡â€</li><li>2ç»´å¼ é‡ 2ç»´å¼ é‡ç§°ä¸ºâ€œçŸ©é˜µâ€</li><li>3ç»´å¼ é‡ æ—¶é—´åºåˆ—æ•°æ®ã€è‚¡ä»·ã€æ–‡æœ¬æ•°æ®ã€å½©è‰²å›¾ç‰‡(RGB)</li><li>4ç»´=å›¾åƒ</li><li>5ç»´=è§†é¢‘</li></ul><p>åœ¨PyTorchä¸­ï¼Œ torch.Tensor æ˜¯å­˜å‚¨å’Œå˜æ¢æ•°æ®çš„ä¸»è¦å·¥å…·ã€‚</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/04_tensor.jpg?raw=true" width="600" alt="" align="center" /><h3 id="tensor-æ„é€ "><a href="#tensor-æ„é€ " class="headerlink" title="tensor-æ„é€ "></a>tensor-æ„é€ </h3><p>åˆ›å»ºä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„çŸ©é˜µï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">4</span>, <span class="number">3</span>)  <span class="comment"># æ„é€ å¼ é‡</span></span><br><span class="line"><span class="built_in">print</span>(x.size())  <span class="comment"># è·å–ç»´åº¦ä¿¡æ¯</span></span><br><span class="line"><span class="built_in">print</span>(x.shape)  <span class="comment"># è·å–ç»´åº¦ä¿¡æ¯</span></span><br></pre></td></tr></table></figure><p>è¿˜æœ‰ä¸€äº›å¸¸è§çš„æ„é€ Tensorçš„å‡½æ•°ï¼š<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/01_tensor_1.jpg?raw=true" width="400" alt="" align="center" /></p><p>PyTorchä¸­çš„Tensoræ”¯æŒè¶…è¿‡ä¸€ç™¾ç§æ“ä½œï¼ŒåŒ…æ‹¬è½¬ç½®ã€ç´¢å¼•ã€åˆ‡ç‰‡ã€æ•°å­¦è¿ç®—ã€çº¿æ€§ä»£æ•°ã€éšæœºæ•°ç­‰ç­‰ï¼Œå¯å‚è€ƒå®˜æ–¹æ–‡æ¡£ã€‚</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/05_tensor.jpg?raw=true" width="600" alt="" align="center" /><h3 id="tensor-squeeze-å¢åŠ -åˆ é™¤ä¸€ä¸ªç»´åº¦"><a href="#tensor-squeeze-å¢åŠ -åˆ é™¤ä¸€ä¸ªç»´åº¦" class="headerlink" title="tensor-squeeze å¢åŠ /åˆ é™¤ä¸€ä¸ªç»´åº¦"></a>tensor-squeeze å¢åŠ /åˆ é™¤ä¸€ä¸ªç»´åº¦</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/06_tensor.jpg?raw=true" width="600" alt="" align="center" /><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/07_tensor.jpg?raw=true" width="600" alt="" align="center" /><h3 id="tensor-transpose-è½¬ç½®"><a href="#tensor-transpose-è½¬ç½®" class="headerlink" title="tensor-transpose è½¬ç½®"></a>tensor-transpose è½¬ç½®</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/08_tensor.jpg?raw=true" width="600" alt="" align="center" /><h3 id="tensor-cat-concatenateå¤šä¸ªtensor"><a href="#tensor-cat-concatenateå¤šä¸ªtensor" class="headerlink" title="tensor-cat concatenateå¤šä¸ªtensor"></a>tensor-cat concatenateå¤šä¸ªtensor</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/09_tensor.jpg?raw=true" width="600" alt="" align="center" /><h2 id="è‡ªåŠ¨æ±‚å¯¼-è‡ªåŠ¨å¾®åˆ†"><a href="#è‡ªåŠ¨æ±‚å¯¼-è‡ªåŠ¨å¾®åˆ†" class="headerlink" title="è‡ªåŠ¨æ±‚å¯¼/è‡ªåŠ¨å¾®åˆ†"></a>è‡ªåŠ¨æ±‚å¯¼/è‡ªåŠ¨å¾®åˆ†</h2><p>PyTorchä¸­ï¼Œæ‰€æœ‰ç¥ç»ç½‘ç»œçš„æ ¸å¿ƒæ˜¯autogradåŒ…ã€‚autogradåŒ…ä¸ºå¼ é‡ä¸Šçš„æ‰€æœ‰æ“ä½œæä¾›äº†è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ã€‚</p><h3 id="How-to-Calculate-Gradient"><a href="#How-to-Calculate-Gradient" class="headerlink" title="How to Calculate Gradient"></a>How to Calculate Gradient</h3><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/10_tensor.jpg?raw=true" width="600" alt="" align="center" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([[<span class="number">1.</span>, <span class="number">0.</span>], [-<span class="number">1.</span>, <span class="number">1.</span>]], requires_grad = <span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [-<span class="number">1.</span>,  <span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = x.<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]], grad_fn=&lt;PowBackward0&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = z.<span class="built_in">sum</span>()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z</span><br><span class="line">tensor(<span class="number">3.</span>, grad_fn=&lt;SumBackward0&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.backward()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z</span><br><span class="line">tensor(<span class="number">3.</span>, grad_fn=&lt;SumBackward0&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.grad</span><br><span class="line">tensor([[ <span class="number">2.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [-<span class="number">2.</span>,  <span class="number">2.</span>]])</span><br></pre></td></tr></table></figure><h2 id="å¹¶è¡Œè®¡ç®—ç®€ä»‹"><a href="#å¹¶è¡Œè®¡ç®—ç®€ä»‹" class="headerlink" title="å¹¶è¡Œè®¡ç®—ç®€ä»‹"></a>å¹¶è¡Œè®¡ç®—ç®€ä»‹</h2><p>åœ¨åˆ©ç”¨PyTorchåšæ·±åº¦å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œå¯èƒ½ä¼šé‡åˆ°æ•°æ®é‡è¾ƒå¤§æ— æ³•åœ¨å•å—GPUä¸Šå®Œæˆï¼Œæˆ–è€…éœ€è¦æå‡è®¡ç®—é€Ÿåº¦çš„åœºæ™¯ï¼Œè¿™æ—¶å°±éœ€è¦ç”¨åˆ°å¹¶è¡Œè®¡ç®—ã€‚<br>GPUçš„å‡ºç°è®©æˆ‘ä»¬å¯ä»¥è®­ç»ƒçš„æ›´å¿«ï¼Œæ›´å¥½ã€‚PyTorchå¯ä»¥åœ¨ç¼–å†™å®Œæ¨¡å‹ä¹‹åï¼Œè®©å¤šä¸ªGPUæ¥å‚ä¸è®­ç»ƒã€‚</p><p><code>CUDA</code>æ˜¯æˆ‘ä»¬ä½¿ç”¨GPUçš„æä¾›å•†â€”â€”NVIDIAæä¾›çš„GPUå¹¶è¡Œè®¡ç®—æ¡†æ¶ã€‚å¯¹äºGPUæœ¬èº«çš„ç¼–ç¨‹ï¼Œä½¿ç”¨çš„æ˜¯<code>CUDA</code>è¯­è¨€æ¥å®ç°çš„ã€‚ä½†æ˜¯ï¼Œåœ¨æˆ‘ä»¬ä½¿ç”¨PyTorchç¼–å†™æ·±åº¦å­¦ä¹ ä»£ç æ—¶ï¼Œä½¿ç”¨çš„<code>CUDA</code>åˆæ˜¯å¦ä¸€ä¸ªæ„æ€ã€‚åœ¨PyTorchä½¿ç”¨ <code>CUDA</code>è¡¨ç¤ºè¦å¼€å§‹è¦æ±‚æˆ‘ä»¬çš„æ¨¡å‹æˆ–è€…æ•°æ®å¼€å§‹ä½¿ç”¨GPUäº†ã€‚</p><p>åœ¨ç¼–å†™ç¨‹åºä¸­ï¼Œå½“æˆ‘ä»¬ä½¿ç”¨äº† <code>cuda()</code> æ—¶ï¼Œå…¶åŠŸèƒ½æ˜¯è®©æˆ‘ä»¬çš„æ¨¡å‹æˆ–è€…æ•°æ®è¿ç§»åˆ°GPUå½“ä¸­ï¼Œé€šè¿‡GPUå¼€å§‹è®¡ç®—ã€‚</p><p>ä¸åŒçš„æ•°æ®åˆ†å¸ƒåˆ°ä¸åŒçš„è®¾å¤‡ä¸­ï¼Œæ‰§è¡Œç›¸åŒçš„ä»»åŠ¡(Data parallelism):<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/02_pc_1.png?raw=true" width="250" alt="" align="center" /></p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>Datawhaleå¼€æºé¡¹ç›®ï¼šæ·±å…¥æµ…å‡ºPyTorch <a href="https://github.com/datawhalechina/thorough-pytorch/">https://github.com/datawhalechina/thorough-pytorch/</a></li><li>æå®æ¯…æœºå™¨å­¦ä¹ 2021æ˜¥-PyTorch Tutorial <a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=5">https://www.bilibili.com/video/BV1Wv411h7kN?p=5</a></li><li>What is a gpu and do you need one in deep learning <a href="https://towardsdatascience.com/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d">https://towardsdatascience.com/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d</a></li><li>åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ pytorchç‰ˆ <a href="https://zh-v2.d2l.ai/chapter_preface/index.html">https://zh-v2.d2l.ai/chapter_preface/index.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ç¬¬ä¸€ç« -PyTorchçš„ç®€ä»‹å’Œå®‰è£…&quot;&gt;&lt;a href=&quot;#ç¬¬ä¸€ç« -PyTorchçš„ç®€ä»‹å’Œå®‰è£…&quot; class=&quot;headerlink&quot; title=&quot;ç¬¬ä¸€ç«  PyTorchçš„ç®€ä»‹å’Œå®‰è£…&quot;&gt;&lt;/a&gt;ç¬¬ä¸€ç«  PyTorchçš„ç®€ä»‹å’Œå®‰è£…&lt;/h1&gt;&lt;h2 id=&quot;PyTor</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬30æœŸ æ·±å…¥æµ…å‡ºPyTorch" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC30%E6%9C%9F-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAPyTorch/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="PyTorch" scheme="http://example.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Task03 å­¦ä¹ BERT</title>
    <link href="http://example.com/nlp-transformer-task03/"/>
    <id>http://example.com/nlp-transformer-task03/</id>
    <published>2021-09-17T01:44:18.000Z</published>
    <updated>2021-10-02T09:21:28.431Z</updated>
    
    <content type="html"><![CDATA[<h1 id="BERTç®€ä»‹"><a href="#BERTç®€ä»‹" class="headerlink" title="BERTç®€ä»‹"></a>BERTç®€ä»‹</h1><p>BERTé¦–å…ˆåœ¨å¤§è§„æ¨¡æ— ç›‘ç£è¯­æ–™ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨é¢„è®­ç»ƒå¥½çš„å‚æ•°åŸºç¡€ä¸Šå¢åŠ ä¸€ä¸ªä¸ä»»åŠ¡ç›¸å…³çš„ç¥ç»ç½‘ç»œå±‚ï¼Œå¹¶åœ¨è¯¥ä»»åŠ¡çš„æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒè®­ï¼Œæœ€ç»ˆå–å¾—å¾ˆå¥½çš„æ•ˆæœã€‚<strong>BERTçš„è¿™ä¸ªè®­ç»ƒè¿‡ç¨‹å¯ä»¥ç®€è¿°ä¸ºï¼šé¢„è®­ç»ƒï¼ˆpre-trainï¼‰+å¾®è°ƒï¼ˆfine-tune/fine-tuningï¼‰ï¼Œå·²ç»æˆä¸ºæœ€è¿‘å‡ å¹´æœ€æµè¡Œçš„NLPè§£å†³æ–¹æ¡ˆçš„èŒƒå¼ã€‚</strong></p><h2 id="å¦‚ä½•ç›´æ¥åº”ç”¨BERT"><a href="#å¦‚ä½•ç›´æ¥åº”ç”¨BERT" class="headerlink" title="å¦‚ä½•ç›´æ¥åº”ç”¨BERT"></a>å¦‚ä½•ç›´æ¥åº”ç”¨BERT</h2><ol><li>ä¸‹è½½åœ¨æ— ç›‘ç£è¯­æ–™ä¸Šé¢„è®­ç»ƒå¥½çš„BERTæ¨¡å‹ï¼Œä¸€èˆ¬æ¥è¯´å¯¹åº”äº†3ä¸ªæ–‡ä»¶ï¼šBERTæ¨¡å‹é…ç½®æ–‡ä»¶ï¼ˆç”¨æ¥ç¡®å®šTransformerçš„å±‚æ•°ï¼Œéšè—å±‚å¤§å°ç­‰ï¼‰ï¼ŒBERTæ¨¡å‹å‚æ•°ï¼ŒBERTè¯è¡¨ï¼ˆBERTæ‰€èƒ½å¤„ç†çš„æ‰€æœ‰tokenï¼‰ã€‚</li><li>é’ˆå¯¹ç‰¹å®šä»»åŠ¡éœ€è¦ï¼Œåœ¨BERTæ¨¡å‹ä¸Šå¢åŠ ä¸€ä¸ªä»»åŠ¡ç›¸å…³çš„ç¥ç»ç½‘ç»œï¼Œæ¯”å¦‚ä¸€ä¸ªç®€å•çš„åˆ†ç±»å™¨ï¼Œç„¶ååœ¨ç‰¹å®šä»»åŠ¡ç›‘ç£æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒè®­ç»ƒã€‚ï¼ˆå¾®è°ƒçš„ä¸€ç§ç†è§£ï¼šå­¦ä¹ ç‡è¾ƒå°ï¼Œè®­ç»ƒepochæ•°é‡è¾ƒå°‘ï¼Œå¯¹æ¨¡å‹æ•´ä½“å‚æ•°è¿›è¡Œè½»å¾®è°ƒæ•´ï¼‰</li></ol><h2 id="BERTçš„ç»“æ„"><a href="#BERTçš„ç»“æ„" class="headerlink" title="BERTçš„ç»“æ„"></a>BERTçš„ç»“æ„</h2><p><strong>BERTæ¨¡å‹ç»“æ„åŸºæœ¬ä¸Šå°±æ˜¯Transformerçš„encoderéƒ¨åˆ†ã€‚</strong></p><h2 id="BERTçš„è¾“å…¥å’Œè¾“å‡º"><a href="#BERTçš„è¾“å…¥å’Œè¾“å‡º" class="headerlink" title="BERTçš„è¾“å…¥å’Œè¾“å‡º"></a>BERTçš„è¾“å…¥å’Œè¾“å‡º</h2><p>BERTæ¨¡å‹è¾“å…¥æœ‰ä¸€ç‚¹ç‰¹æ®Šçš„åœ°æ–¹æ˜¯åœ¨ä¸€å¥è¯æœ€å¼€å§‹æ‹¼æ¥äº†ä¸€ä¸ª[CLS] tokenï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚è¿™ä¸ªç‰¹æ®Šçš„[CLS] tokenç»è¿‡BERTå¾—åˆ°çš„å‘é‡è¡¨ç¤ºé€šå¸¸è¢«ç”¨ä½œå½“å‰çš„å¥å­è¡¨ç¤ºã€‚æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ç¬¬1ä¸ªä½ç½®çš„å‘é‡è¾“å‡ºï¼ˆå¯¹åº”çš„æ˜¯[CLS]ï¼‰ä¼ å…¥classifierç½‘ç»œï¼Œç„¶åè¿›è¡Œåˆ†ç±»ä»»åŠ¡ã€‚</p><h1 id="BERTçš„é¢„è®­ç»ƒä»»åŠ¡"><a href="#BERTçš„é¢„è®­ç»ƒä»»åŠ¡" class="headerlink" title="BERTçš„é¢„è®­ç»ƒä»»åŠ¡"></a>BERTçš„é¢„è®­ç»ƒä»»åŠ¡</h1><p>BERTæ˜¯ä¸€ä¸ªå¤šä»»åŠ¡æ¨¡å‹ï¼Œå®ƒçš„ä»»åŠ¡æ˜¯ç”±ä¸¤ä¸ªè‡ªç›‘ç£ä»»åŠ¡ç»„æˆã€‚</p><h2 id="Masked-Language-Modelï¼ˆMLMï¼‰"><a href="#Masked-Language-Modelï¼ˆMLMï¼‰" class="headerlink" title="Masked Language Modelï¼ˆMLMï¼‰"></a>Masked Language Modelï¼ˆMLMï¼‰</h2><p>MLMï¼šå°†è¾“å…¥æ–‡æœ¬åºåˆ—çš„éƒ¨åˆ†ï¼ˆ15%ï¼‰å•è¯éšæœºMaskæ‰ï¼Œè®©BERTæ¥é¢„æµ‹è¿™äº›è¢«Maskçš„è¯è¯­ã€‚<em>ï¼ˆå¯ä»¥è¯´æ˜¯å®Œå½¢å¡«ç©ºï¼‰</em></p><blockquote><p>Masked Language Modelï¼ˆMLMï¼‰å’Œæ ¸å¿ƒæ€æƒ³å–è‡ªWilson Tayloråœ¨1953å¹´å‘è¡¨çš„ä¸€ç¯‡è®ºæ–‡ã€Šcloze procedure: A new tool for measuring readabilityã€‹ã€‚æ‰€è°“MLMæ˜¯æŒ‡åœ¨è®­ç»ƒçš„æ—¶å€™éšå³ä»è¾“å…¥é¢„æ–™ä¸Šmaskæ‰ä¸€äº›å•è¯ï¼Œç„¶åé€šè¿‡çš„ä¸Šä¸‹æ–‡é¢„æµ‹è¯¥å•è¯ï¼Œè¯¥ä»»åŠ¡éå¸¸åƒæˆ‘ä»¬åœ¨ä¸­å­¦æ—¶æœŸç»å¸¸åšçš„å®Œå½¢å¡«ç©ºã€‚æ­£å¦‚ä¼ ç»Ÿçš„è¯­è¨€æ¨¡å‹ç®—æ³•å’ŒRNNåŒ¹é…é‚£æ ·ï¼ŒMLMçš„è¿™ä¸ªæ€§è´¨å’ŒTransformerçš„ç»“æ„æ˜¯éå¸¸åŒ¹é…çš„ã€‚</p></blockquote><h2 id="Next-Sentence-Predictionï¼ˆNSPï¼‰"><a href="#Next-Sentence-Predictionï¼ˆNSPï¼‰" class="headerlink" title="Next Sentence Predictionï¼ˆNSPï¼‰"></a>Next Sentence Predictionï¼ˆNSPï¼‰</h2><p>NSPï¼šåˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦æ˜¯ç›¸é‚»å¥å­ã€‚å³ï¼Œè¾“å…¥æ˜¯sentence Aå’Œsentence Bï¼Œç»è¿‡BERTç¼–ç ä¹‹åï¼Œä½¿ç”¨CLS tokençš„å‘é‡è¡¨ç¤ºæ¥é¢„æµ‹ä¸¤ä¸ªå¥å­æ˜¯å¦æ˜¯ç›¸é‚»å¥å­ã€‚</p><blockquote><p>Next Sentence Predictionï¼ˆNSPï¼‰çš„ä»»åŠ¡æ˜¯åˆ¤æ–­å¥å­Bæ˜¯å¦æ˜¯å¥å­Açš„ä¸‹æ–‡ã€‚å¦‚æœæ˜¯çš„è¯è¾“å‡ºâ€™IsNextâ€˜ï¼Œå¦åˆ™è¾“å‡ºâ€™NotNextâ€˜ã€‚è®­ç»ƒæ•°æ®çš„ç”Ÿæˆæ–¹å¼æ˜¯ä»å¹³è¡Œè¯­æ–™ä¸­éšæœºæŠ½å–çš„è¿ç»­ä¸¤å¥è¯ï¼Œå…¶ä¸­50%ä¿ç•™æŠ½å–çš„ä¸¤å¥è¯ï¼Œå®ƒä»¬ç¬¦åˆIsNextå…³ç³»ï¼Œå¦å¤–50%çš„ç¬¬äºŒå¥è¯æ˜¯éšæœºä»é¢„æ–™ä¸­æå–çš„ï¼Œå®ƒä»¬çš„å…³ç³»æ˜¯NotNextçš„ã€‚è¿™ä¸ªå…³ç³»ä¿å­˜åœ¨[CLS]ç¬¦å·ä¸­ã€‚</p></blockquote><h1 id="BERTçš„åº”ç”¨"><a href="#BERTçš„åº”ç”¨" class="headerlink" title="BERTçš„åº”ç”¨"></a>BERTçš„åº”ç”¨</h1><h2 id="ç‰¹å¾æå–"><a href="#ç‰¹å¾æå–" class="headerlink" title="ç‰¹å¾æå–"></a>ç‰¹å¾æå–</h2><p>ç”±äºBERTæ¨¡å‹å¯ä»¥å¾—åˆ°è¾“å…¥åºåˆ—æ‰€å¯¹åº”çš„æ‰€æœ‰tokençš„å‘é‡è¡¨ç¤ºï¼Œå› æ­¤ä¸ä»…å¯ä»¥ä½¿ç”¨æœ€åä¸€ç¨‹BERTçš„è¾“å‡ºè¿æ¥ä¸Šä»»åŠ¡ç½‘ç»œè¿›è¡Œå¾®è°ƒï¼Œè¿˜å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™äº›tokençš„å‘é‡å½“ä½œç‰¹å¾ã€‚æ¯”å¦‚ï¼Œå¯ä»¥ç›´æ¥æå–æ¯ä¸€å±‚encoderçš„tokenè¡¨ç¤ºå½“ä½œç‰¹å¾ï¼Œè¾“å…¥ç°æœ‰çš„ç‰¹å®šä»»åŠ¡ç¥ç»ç½‘ç»œä¸­è¿›è¡Œè®­ç»ƒã€‚</p><h2 id="Pretrain-Fine-tune"><a href="#Pretrain-Fine-tune" class="headerlink" title="Pretrain + Fine tune"></a>Pretrain + Fine tune</h2><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨â€“åœ¨çº¿é˜…è¯» <a href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a></li><li>æå®æ¯…æœºå™¨å­¦ä¹ 2019-ELMO,BERT,GPT <a href="https://www.bilibili.com/video/BV1Gb411n7dE?p=61">https:// www.bilibili.com/video/BV1Gb411n7dE?p=61</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;BERTç®€ä»‹&quot;&gt;&lt;a href=&quot;#BERTç®€ä»‹&quot; class=&quot;headerlink&quot; title=&quot;BERTç®€ä»‹&quot;&gt;&lt;/a&gt;BERTç®€ä»‹&lt;/h1&gt;&lt;p&gt;BERTé¦–å…ˆåœ¨å¤§è§„æ¨¡æ— ç›‘ç£è¯­æ–™ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨é¢„è®­ç»ƒå¥½çš„å‚æ•°åŸºç¡€ä¸Šå¢åŠ ä¸€ä¸ªä¸ä»»åŠ¡ç›¸å…³çš„ç¥ç»ç½‘ç»œå±‚ï¼Œå¹¶åœ¨è¯¥</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬29æœŸ åŸºäºtransformerçš„NLP" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="é¢„è®­ç»ƒæ¨¡å‹" scheme="http://example.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="BERT" scheme="http://example.com/tags/BERT/"/>
    
  </entry>
  
  <entry>
    <title>Task02 å­¦ä¹ Attentioinå’ŒTransformer</title>
    <link href="http://example.com/nlp-transformer-task02/"/>
    <id>http://example.com/nlp-transformer-task02/</id>
    <published>2021-09-17T01:09:24.000Z</published>
    <updated>2021-10-02T09:21:22.586Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h1><h2 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h2><p>seq2seqæ˜¯ä¸€ç§å¸¸è§çš„NLPæ¨¡å‹ç»“æ„ï¼Œå…¨ç§°æ˜¯ï¼šsequence to sequenceï¼Œç¿»è¯‘ä¸ºâ€œåºåˆ—åˆ°åºåˆ—â€ã€‚é¡¾åæ€ä¹‰ï¼šä»ä¸€ä¸ªæ–‡æœ¬åºåˆ—å¾—åˆ°ä¸€ä¸ªæ–°çš„æ–‡æœ¬åºåˆ—ã€‚å…¸å‹çš„ä»»åŠ¡æœ‰ï¼šæœºå™¨ç¿»è¯‘ä»»åŠ¡ï¼Œæ–‡æœ¬æ‘˜è¦ä»»åŠ¡ã€‚</p><p>seq2seqæ¨¡å‹ç”±ç¼–ç å™¨ï¼ˆencoderï¼‰å’Œè§£ç å™¨ï¼ˆdecoderï¼‰ç»„æˆï¼Œç¼–ç å™¨ç”¨æ¥åˆ†æè¾“å…¥åºåˆ—ï¼Œè§£ç å™¨ç”¨æ¥ç”Ÿæˆè¾“å‡ºåºåˆ—ã€‚ç¼–ç å™¨ä¼šå¤„ç†è¾“å…¥åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼ŒæŠŠè¿™äº›ä¿¡æ¯è½¬æ¢æˆä¸ºä¸€ä¸ªèƒŒæ™¯å‘é‡ï¼ˆcontext vectorï¼‰ã€‚å½“æˆ‘ä»¬å¤„ç†å®Œæ•´ä¸ªè¾“å…¥åºåˆ—åï¼Œç¼–ç å™¨æŠŠèƒŒæ™¯å‘é‡å‘é€ç»™è§£ç å™¨ï¼Œè§£ç å™¨é€šè¿‡èƒŒæ™¯å‘é‡ä¸­çš„ä¿¡æ¯ï¼Œé€ä¸ªå…ƒç´ è¾“å‡ºæ–°çš„åºåˆ—ã€‚</p><p><strong>åœ¨transformeræ¨¡å‹ä¹‹å‰ï¼Œseq2seqä¸­çš„ç¼–ç å™¨å’Œè§£ç å™¨ä¸€èˆ¬é‡‡ç”¨å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰</strong>ï¼Œè™½ç„¶éå¸¸ç»å…¸ï¼Œä½†æ˜¯å±€é™æ€§ä¹Ÿéå¸¸å¤§ã€‚æœ€å¤§çš„å±€é™æ€§å°±åœ¨äºç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´çš„å”¯ä¸€è”ç³»å°±æ˜¯ä¸€ä¸ªå›ºå®šé•¿åº¦çš„contextå‘é‡ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç¼–ç å™¨è¦å°†æ•´ä¸ªåºåˆ—çš„ä¿¡æ¯å‹ç¼©è¿›ä¸€ä¸ªå›ºå®šé•¿åº¦çš„å‘é‡ä¸­ã€‚è¿™æ ·åšå­˜åœ¨ä¸¤ä¸ªå¼Šç«¯ï¼š</p><ul><li>è¯­ä¹‰å‘é‡å¯èƒ½æ— æ³•å®Œå…¨è¡¨ç¤ºæ•´ä¸ªåºåˆ—çš„ä¿¡æ¯</li><li>å…ˆè¾“å…¥åˆ°ç½‘ç»œçš„å†…å®¹æºå¸¦çš„ä¿¡æ¯ä¼šè¢«åè¾“å…¥çš„ä¿¡æ¯è¦†ç›–æ‰ï¼Œè¾“å…¥åºåˆ—è¶Šé•¿ï¼Œè¿™ä¸ªç°è±¡å°±è¶Šä¸¥é‡</li></ul><h2 id="Attention-1"><a href="#Attention-1" class="headerlink" title="Attention"></a>Attention</h2><p>ä¸ºäº†è§£å†³seq2seqæ¨¡å‹ä¸­çš„ä¸¤ä¸ªå¼Šç«¯ï¼ŒBahdanauç­‰äººåœ¨è®ºæ–‡ã€ŠNeural Machine Translation by Jointly Learning to Align and Translateã€‹ä¸­æå‡ºä½¿ç”¨Attentionæœºåˆ¶ï¼Œä½¿å¾—seq2seqæ¨¡å‹å¯ä»¥æœ‰åŒºåˆ†åº¦ã€æœ‰é‡ç‚¹åœ°å…³æ³¨è¾“å…¥åºåˆ—ï¼Œä»è€Œæå¤§åœ°æé«˜äº†æœºå™¨ç¿»è¯‘çš„è´¨é‡ã€‚</p><p>ä¸€ä¸ªæœ‰æ³¨æ„åŠ›æœºåˆ¶çš„seq2seqä¸ç»å…¸çš„seq2seqä¸»è¦æœ‰2ç‚¹ä¸åŒï¼š</p><ol><li>é¦–å…ˆï¼Œç¼–ç å™¨ä¼šæŠŠæ›´å¤šçš„æ•°æ®ä¼ é€’ç»™è§£ç å™¨ã€‚ç¼–ç å™¨æŠŠæ‰€æœ‰æ—¶é—´æ­¥çš„ hidden stateï¼ˆéšè—å±‚çŠ¶æ€ï¼‰ä¼ é€’ç»™è§£ç å™¨ï¼Œè€Œä¸æ˜¯åªä¼ é€’æœ€åä¸€ä¸ª hidden stateï¼ˆéšè—å±‚çŠ¶æ€ï¼‰</li><li>æ³¨æ„åŠ›æ¨¡å‹çš„è§£ç å™¨åœ¨äº§ç”Ÿè¾“å‡ºä¹‹å‰ï¼Œåšäº†ä¸€ä¸ªé¢å¤–çš„attentionå¤„ç†</li></ol><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><h2 id="æ¨¡å‹æ¶æ„"><a href="#æ¨¡å‹æ¶æ„" class="headerlink" title="æ¨¡å‹æ¶æ„"></a>æ¨¡å‹æ¶æ„</h2><p>transformeråŸè®ºæ–‡çš„æ¶æ„å›¾ï¼š</p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/trm_1.png?raw=true" width="400" alt="" align="center" /><p>ä¸€ä¸ªæ›´æ¸…æ™°çš„æ¶æ„å›¾ï¼š<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/trm_2.png?raw=true" width="600" alt="" align="center" /></p><p>ä»è¾“å…¥åˆ°è¾“å‡ºæ‹†å¼€çœ‹å°±æ˜¯ï¼š</p><ul><li>INPUTï¼šinput vector + position encoding</li><li>ENCODERsï¼ˆÃ—6ï¼‰ï¼Œand each encoder includesï¼š<ul><li>input</li><li>multi-head self-attention</li><li>residual connection&amp;norm</li><li>full-connected network</li><li>residual connection&amp;norm</li><li>output</li></ul></li><li>DECODERsï¼ˆÃ—6ï¼‰ï¼Œand each decoder includesï¼š<ul><li>input </li><li>Masked multihead self-attention</li><li>residual connection&amp;norm</li><li>multi-head self-attention</li><li>residual connection&amp;norm</li><li>full-connected network</li><li>residual connection&amp;norm</li><li>output</li></ul></li><li>OUTPUTï¼š<ul><li>output (decoderâ€™s)</li><li>linear layer</li><li>softmax layer</li><li>output</li></ul></li></ul><h2 id="æ¨¡å‹è¾“å…¥"><a href="#æ¨¡å‹è¾“å…¥" class="headerlink" title="æ¨¡å‹è¾“å…¥"></a>æ¨¡å‹è¾“å…¥</h2><h3 id="è¯å‘é‡"><a href="#è¯å‘é‡" class="headerlink" title="è¯å‘é‡"></a>è¯å‘é‡</h3><p>å’Œå¸¸è§çš„NLPä»»åŠ¡ä¸€æ ·ï¼Œæˆ‘ä»¬é¦–å…ˆä¼šä½¿ç”¨è¯åµŒå…¥ç®—æ³•ï¼ˆembeddingï¼‰ï¼Œå°†è¾“å…¥æ–‡æœ¬åºåˆ—çš„æ¯ä¸ªè¯è½¬æ¢ä¸ºä¸€ä¸ªè¯å‘é‡ã€‚</p><h3 id="ä½ç½®å‘é‡"><a href="#ä½ç½®å‘é‡" class="headerlink" title="ä½ç½®å‘é‡"></a>ä½ç½®å‘é‡</h3><p>Transformeræ¨¡å‹å¯¹æ¯ä¸ªè¾“å…¥çš„è¯å‘é‡éƒ½åŠ ä¸Šäº†ä¸€ä¸ªä½ç½®å‘é‡ã€‚è¿™äº›å‘é‡æœ‰åŠ©äºç¡®å®šæ¯ä¸ªå•è¯çš„ä½ç½®ç‰¹å¾ï¼Œæˆ–è€…å¥å­ä¸­ä¸åŒå•è¯ä¹‹é—´çš„è·ç¦»ç‰¹å¾ã€‚è¯å‘é‡åŠ ä¸Šä½ç½®å‘é‡èƒŒåçš„ç›´è§‰æ˜¯ï¼šå°†è¿™äº›è¡¨ç¤ºä½ç½®çš„å‘é‡æ·»åŠ åˆ°è¯å‘é‡ä¸­ï¼Œå¾—åˆ°çš„æ–°å‘é‡ï¼Œå¯ä»¥ä¸ºæ¨¡å‹æä¾›æ›´å¤šæœ‰æ„ä¹‰çš„ä¿¡æ¯ï¼Œæ¯”å¦‚è¯çš„ä½ç½®ï¼Œè¯ä¹‹é—´çš„è·ç¦»ç­‰ã€‚</p><p><em>ï¼ˆç”Ÿæˆä½ç½®ç¼–ç å‘é‡çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼‰</em></p><h2 id="ç¼–ç å™¨å’Œè§£ç å™¨"><a href="#ç¼–ç å™¨å’Œè§£ç å™¨" class="headerlink" title="ç¼–ç å™¨å’Œè§£ç å™¨"></a>ç¼–ç å™¨å’Œè§£ç å™¨</h2><p><em>æ³¨ï¼š1. ç¼–ç å™¨å’Œè§£ç å™¨ä¸­æœ‰ç›¸ä¼¼çš„æ¨¡å—å’Œç»“æ„ï¼Œæ‰€ä»¥åˆå¹¶åˆ°ä¸€èµ·ä»‹ç»ã€‚</em><br><em>2. æœ¬éƒ¨åˆ†æŒ‰ç…§æå®æ¯…è€å¸ˆçš„Attentionï¼ŒTransformeréƒ¨åˆ†çš„è¯¾ç¨‹PPTæ¥ï¼Œå› ä¸ºleeçš„è¯¾ç¨‹å¯¹æ–°æ‰‹æ›´å‹å¥½ã€‚</em></p><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>self-attentionå¯¹äºæ¯ä¸ªå‘é‡éƒ½ä¼šè€ƒè™‘æ•´ä¸ªsequenceçš„ä¿¡æ¯åè¾“å‡ºä¸€ä¸ªå‘é‡ï¼Œself-attentionç»“æ„å¦‚ä¸‹ï¼š<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/04_attention_1.png?raw=true" width="600" alt="" align="center" /><br>FCï¼šFully-connected network å…¨è¿æ¥ç½‘ç»œ<br>ai: è¾“å…¥å˜é‡ã€‚å¯èƒ½æ˜¯æ•´ä¸ªç½‘ç»œçš„è¾“å…¥ï¼Œä¹Ÿå¯èƒ½æ˜¯æŸä¸ªéšè—å±‚çš„è¾“å‡º<br>bi: è€ƒè™‘æ•´ä¸ªsequenceä¿¡æ¯åçš„è¾“å‡ºå˜é‡</p><p>çŸ©é˜µè®¡ç®—ï¼š<br><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/13_matrix_4.jpg?raw=true" width="300" alt="" align="center" /><br>ç›®æ ‡ï¼šæ ¹æ®è¾“å…¥å‘é‡çŸ©é˜µIï¼Œè®¡ç®—è¾“å‡ºå‘é‡çŸ©é˜µOã€‚çŸ©é˜µè¿ç®—è¿‡ç¨‹ï¼š</p><ol><li>çŸ©é˜µIåˆ†åˆ«ä¹˜ä»¥Wq, Wk, Wvï¼ˆå‚æ•°çŸ©é˜µï¼Œéœ€è¦æ¨¡å‹è¿›è¡Œå­¦ä¹ ï¼‰ï¼Œå¾—åˆ°çŸ©é˜µQ, K, Vã€‚</li><li>çŸ©é˜µKçš„è½¬ç½®ä¹˜ä»¥Qï¼Œå¾—åˆ°æ³¨æ„åŠ›æƒé‡çŸ©é˜µAï¼Œå½’ä¸€åŒ–å¾—åˆ°çŸ©é˜µAâ€™ã€‚</li><li>çŸ©é˜µVä¹˜çŸ©é˜µAâ€˜ï¼Œå¾—åˆ°è¾“å‡ºå‘é‡çŸ©é˜µOã€‚</li></ol><h3 id="Multi-Head-Self-Attention"><a href="#Multi-Head-Self-Attention" class="headerlink" title="Multi Head Self-Attention"></a>Multi Head Self-Attention</h3><p><em>ç®€å•åœ°è¯´ï¼Œå¤šäº†å‡ ç»„Qï¼ŒKï¼ŒVã€‚åœ¨Self-Attentionä¸­ï¼Œæˆ‘ä»¬æ˜¯ä½¿ç”¨ğ‘å»å¯»æ‰¾ä¸ä¹‹ç›¸å…³çš„ğ‘˜ï¼Œä½†æ˜¯è¿™ä¸ªç›¸å…³æ€§å¹¶ä¸ä¸€å®šæœ‰ä¸€ç§ã€‚é‚£å¤šç§ç›¸å…³æ€§ä½“ç°åˆ°è®¡ç®—æ–¹å¼ä¸Šå°±æ˜¯æœ‰å¤šä¸ªçŸ©é˜µğ‘ï¼Œä¸åŒçš„ğ‘è´Ÿè´£ä»£è¡¨ä¸åŒçš„ç›¸å…³æ€§ã€‚</em></p><p>Transformer çš„è®ºæ–‡é€šè¿‡å¢åŠ å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆä¸€ç»„æ³¨æ„åŠ›ç§°ä¸ºä¸€ä¸ª attention headï¼‰ï¼Œè¿›ä¸€æ­¥å®Œå–„äº†Self-Attentionã€‚è¿™ç§æœºåˆ¶ä»å¦‚ä¸‹ä¸¤ä¸ªæ–¹é¢å¢å¼ºäº†attentionå±‚çš„èƒ½åŠ›ï¼š</p><ul><li>å®ƒæ‰©å±•äº†æ¨¡å‹å…³æ³¨ä¸åŒä½ç½®çš„èƒ½åŠ›ã€‚</li><li>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶èµ‹äºˆattentionå±‚å¤šä¸ªâ€œå­è¡¨ç¤ºç©ºé—´â€ã€‚</li></ul><h3 id="æ®‹å·®é“¾æ¥å’Œå½’ä¸€åŒ–"><a href="#æ®‹å·®é“¾æ¥å’Œå½’ä¸€åŒ–" class="headerlink" title="æ®‹å·®é“¾æ¥å’Œå½’ä¸€åŒ–"></a>æ®‹å·®é“¾æ¥å’Œå½’ä¸€åŒ–</h3><p>æ®‹å·®é“¾æ¥ï¼šä¸€ç§æŠŠinputå‘é‡å’Œoutputå‘é‡ç›´æ¥åŠ èµ·æ¥çš„æ¶æ„ã€‚<br>å½’ä¸€åŒ–ï¼šæŠŠæ•°æ®æ˜ å°„åˆ°0ï½1èŒƒå›´ä¹‹å†…å¤„ç†ã€‚</p><h2 id="æ¨¡å‹è¾“å‡º"><a href="#æ¨¡å‹è¾“å‡º" class="headerlink" title="æ¨¡å‹è¾“å‡º"></a>æ¨¡å‹è¾“å‡º</h2><h3 id="çº¿æ€§å±‚å’Œsoftmax"><a href="#çº¿æ€§å±‚å’Œsoftmax" class="headerlink" title="çº¿æ€§å±‚å’Œsoftmax"></a>çº¿æ€§å±‚å’Œsoftmax</h3><p>Decoder æœ€ç»ˆçš„è¾“å‡ºæ˜¯ä¸€ä¸ªå‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ æ˜¯æµ®ç‚¹æ•°ã€‚æˆ‘ä»¬æ€ä¹ˆæŠŠè¿™ä¸ªå‘é‡è½¬æ¢ä¸ºå•è¯å‘¢ï¼Ÿè¿™æ˜¯çº¿æ€§å±‚å’Œsoftmaxå®Œæˆçš„ã€‚</p><p>çº¿æ€§å±‚å°±æ˜¯ä¸€ä¸ªæ™®é€šçš„å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œå¯ä»¥æŠŠè§£ç å™¨è¾“å‡ºçš„å‘é‡ï¼Œæ˜ å°„åˆ°ä¸€ä¸ªæ›´å¤§çš„å‘é‡ï¼Œè¿™ä¸ªå‘é‡ç§°ä¸º logits å‘é‡ï¼šå‡è®¾æˆ‘ä»¬çš„æ¨¡å‹æœ‰ 10000 ä¸ªè‹±è¯­å•è¯ï¼ˆæ¨¡å‹çš„è¾“å‡ºè¯æ±‡è¡¨ï¼‰ï¼Œæ­¤ logits å‘é‡ä¾¿ä¼šæœ‰ 10000 ä¸ªæ•°å­—ï¼Œæ¯ä¸ªæ•°è¡¨ç¤ºä¸€ä¸ªå•è¯çš„åˆ†æ•°ã€‚</p><p>ç„¶åï¼ŒSoftmax å±‚ä¼šæŠŠè¿™äº›åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆæŠŠæ‰€æœ‰çš„åˆ†æ•°è½¬æ¢ä¸ºæ­£æ•°ï¼Œå¹¶ä¸”åŠ èµ·æ¥ç­‰äº 1ï¼‰ã€‚ç„¶åé€‰æ‹©æœ€é«˜æ¦‚ç‡çš„é‚£ä¸ªæ•°å­—å¯¹åº”çš„è¯ï¼Œå°±æ˜¯è¿™ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºå•è¯ã€‚</p><h3 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h3><p>Transformerè®­ç»ƒçš„æ—¶å€™ï¼Œéœ€è¦å°†è§£ç å™¨çš„è¾“å‡ºå’Œlabelä¸€åŒé€å…¥æŸå¤±å‡½æ•°ï¼Œä»¥è·å¾—lossï¼Œæœ€ç»ˆæ¨¡å‹æ ¹æ®lossè¿›è¡Œæ–¹å‘ä¼ æ’­ã€‚</p><p>åªè¦Transformerè§£ç å™¨é¢„æµ‹äº†ç»„æ¦‚ç‡ï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠè¿™ç»„æ¦‚ç‡å’Œæ­£ç¡®çš„è¾“å‡ºæ¦‚ç‡åšå¯¹æ¯”ï¼Œç„¶åä½¿ç”¨åå‘ä¼ æ’­æ¥è°ƒæ•´æ¨¡å‹çš„æƒé‡ï¼Œä½¿å¾—è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒæ›´åŠ æ¥è¿‘æ•´æ•°è¾“å‡ºã€‚</p><p>é‚£æˆ‘ä»¬è¦æ€ä¹ˆæ¯”è¾ƒä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒå‘¢ï¼Ÿï¼šæˆ‘ä»¬å¯ä»¥ç®€å•çš„ç”¨ä¸¤ç»„æ¦‚ç‡å‘é‡çš„çš„ç©ºé—´è·ç¦»ä½œä¸ºlossï¼ˆå‘é‡ç›¸å‡ï¼Œç„¶åæ±‚å¹³æ–¹å’Œï¼Œå†å¼€æ–¹ï¼‰ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥ä½¿ç”¨äº¤å‰ç†µ(cross-entropy)]å’ŒKL æ•£åº¦(Kullbackâ€“Leibler divergence)ã€‚</p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p><strong>ç†è®ºéƒ¨åˆ†</strong><br>[1] (å¼ºæ¨)æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ <a href="https://www.bilibili.com/video/BV1Wv411h7kN?from=search&seid=17090062977285779802&spm_id_from=333.337.0.0">https://www.bilibili.com/video/BV1Wv411h7kN?from=search&amp;seid=17090062977285779802&amp;spm_id_from=333.337.0.0</a><br>[2] <strong>åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨ï¼ˆæ¶µç›–äº†å›¾è§£ç³»åˆ—ã€annotated transformerã€huggingfaceï¼‰</strong> <a href="https://github.com/datawhalechina/learn-nlp-with-transformers">https://github.com/datawhalechina/learn-nlp-with-transformers</a><br>[3] å›¾è§£transformer|The Illustrated Transformer <a href="http://jalammar.github.io/illustrated-transformer/">http://jalammar.github.io/illustrated-transformer/</a><br>[4] å›¾è§£seq2seq, attention|Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/</a></p><p><strong>ä»£ç éƒ¨åˆ†</strong><br>[5] The Annotated Transformer <a href="http://nlp.seas.harvard.edu//2018/04/03/attention.html">http://nlp.seas.harvard.edu//2018/04/03/attention.html</a><br>[6] Huggingface/transformers <a href="https://github.com/huggingface/transformers/blob/master/README_zh-hans.md">https://github.com/huggingface/transformers/blob/master/README_zh-hans.md</a></p><p><strong>è®ºæ–‡éƒ¨åˆ†</strong><br>Attention is all â€œweâ€ need.</p><p><strong>å…¶ä»–ä¸é”™çš„åšå®¢æˆ–æ•™ç¨‹</strong><br>[7] åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨â€“åœ¨çº¿é˜…è¯» <a href="https://datawhalechina.github.io/learn-nlp-with-transformers/#/">https://datawhalechina.github.io/learn-nlp-with-transformers/#/</a><br>[8] æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ç¬”è®°â€”â€”è‡ªæ³¨æ„åŠ›æœºåˆ¶ <a href="https://www.cnblogs.com/sykline/p/14730088.html">https://www.cnblogs.com/sykline/p/14730088.html</a><br>[9] æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹ç¬”è®°â€”â€”Transformeræ¨¡å‹ <a href="https://www.cnblogs.com/sykline/p/14785552.html">https://www.cnblogs.com/sykline/p/14785552.html</a><br>[10] æå®æ¯…æœºå™¨å­¦ä¹ å­¦ä¹ ç¬”è®°â€”â€”è‡ªæ³¨æ„åŠ›æœºåˆ¶ <a href="https://blog.csdn.net/p_memory/article/details/116271274">https://blog.csdn.net/p_memory/article/details/116271274</a><br>[11] è½¦ä¸‡ç¿”-è‡ªç„¶è¯­è¨€å¤„ç†æ–°èŒƒå¼ï¼šåŸºäºé¢„è®­ç»ƒçš„æ–¹æ³•ã€è®²åº§+PPTã€‘ <a href="https://app6ca5octe2206.pc.xiaoe-tech.com/detail/v_611f48f3e4b02ac39d12246f/3?fromH5=true">https://app6ca5octe2206.pc.xiaoe-tech.com/detail/v_611f48f3e4b02ac39d12246f/3?fromH5=true</a><br>[12] è‹å‰‘æ—-ã€ŠAttention is All You Needã€‹æµ…è¯»ï¼ˆç®€ä»‹+ä»£ç ï¼‰<a href="https://spaces.ac.cn/archives/4765">https://spaces.ac.cn/archives/4765</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Attention&quot;&gt;&lt;a href=&quot;#Attention&quot; class=&quot;headerlink&quot; title=&quot;Attention&quot;&gt;&lt;/a&gt;Attention&lt;/h1&gt;&lt;h2 id=&quot;seq2seq&quot;&gt;&lt;a href=&quot;#seq2seq&quot; class=&quot;he</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬29æœŸ åŸºäºtransformerçš„NLP" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="é¢„è®­ç»ƒæ¨¡å‹" scheme="http://example.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="attention" scheme="http://example.com/tags/attention/"/>
    
    <category term="transfomer" scheme="http://example.com/tags/transfomer/"/>
    
  </entry>
  
  <entry>
    <title>Task01 NLPå­¦ä¹ æ¦‚è§ˆ</title>
    <link href="http://example.com/nlp-transformer-task01/"/>
    <id>http://example.com/nlp-transformer-task01/</id>
    <published>2021-09-12T16:14:06.000Z</published>
    <updated>2021-10-02T09:21:16.372Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NLPæ€ç»´å¯¼å›¾-æœ€è¿‘æ›´æ–°æ—¥æœŸï¼š2021-09-13"><a href="#NLPæ€ç»´å¯¼å›¾-æœ€è¿‘æ›´æ–°æ—¥æœŸï¼š2021-09-13" class="headerlink" title="NLPæ€ç»´å¯¼å›¾(æœ€è¿‘æ›´æ–°æ—¥æœŸï¼š2021-09-13)"></a>NLPæ€ç»´å¯¼å›¾(æœ€è¿‘æ›´æ–°æ—¥æœŸï¼š2021-09-13)</h1><img src="https://github.com/chuxiaoyu/blog_image/blob/master/nlp/NLP.png?raw=true" width="900" alt="" align="center" /><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>Datawhale-åŸºäºtransformersçš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å…¥é—¨ <a href="https://github.com/datawhalechina/learn-nlp-with-transformers">https://github.com/datawhalechina/learn-nlp-with-transformers</a></li><li>ã€Šè‡ªç„¶è¯­è¨€å¤„ç†-åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ã€‹ <a href="https://item.jd.com/13344628.html">https://item.jd.com/13344628.html</a></li><li>åˆ˜çŸ¥è¿œè€å¸ˆ-NLPç ”ç©¶å…¥é—¨ä¹‹é“ <a href="https://github.com/zibuyu/research_tao">https://github.com/zibuyu/research_tao</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;NLPæ€ç»´å¯¼å›¾-æœ€è¿‘æ›´æ–°æ—¥æœŸï¼š2021-09-13&quot;&gt;&lt;a href=&quot;#NLPæ€ç»´å¯¼å›¾-æœ€è¿‘æ›´æ–°æ—¥æœŸï¼š2021-09-13&quot; class=&quot;headerlink&quot; title=&quot;NLPæ€ç»´å¯¼å›¾(æœ€è¿‘æ›´æ–°æ—¥æœŸï¼š2021-09-13)&quot;&gt;&lt;/a&gt;NLPæ€ç»´å¯¼å›¾(æœ€è¿‘</summary>
      
    
    
    
    <category term="04 ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ç¬¬29æœŸ åŸºäºtransformerçš„NLP" scheme="http://example.com/categories/04-%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/%E7%AC%AC29%E6%9C%9F-%E5%9F%BA%E4%BA%8Etransformer%E7%9A%84NLP/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="ç»„é˜Ÿå­¦ä¹ " scheme="http://example.com/tags/%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="é¢„è®­ç»ƒæ¨¡å‹" scheme="http://example.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>CS61A Week1 Comupter_Science, Functions</title>
    <link href="http://example.com/cs61a-week1/"/>
    <id>http://example.com/cs61a-week1/</id>
    <published>2021-09-01T08:46:52.000Z</published>
    <updated>2021-09-17T01:51:24.035Z</updated>
    
    <content type="html"><![CDATA[<h2 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h2><blockquote><p>CS61Aä½œä¸º61ç³»åˆ—åŸºç¡€è¯¾ç¨‹çš„ç¬¬ä¸€é—¨è¯¾ç¨‹ï¼Œæ˜¯ä¸€é—¨è®¡ç®—æœºå…¥é—¨å¯¼è®ºè¯¾ç¨‹ï¼Œä¼¯å…‹åˆ©å¤§ä¸€æ–°ç”Ÿçš„ç¬¬ä¸€é—¨è®¡ç®—æœºè¯¾ç¨‹ã€‚è¯¥è¯¾ç¨‹ä¸»è¦ä½¿ç”¨Pythonè¯­è¨€ï¼Œç®€è¦ä»‹ç»äº†è®¡ç®—æœºçš„å„ç§æ¦‚å¿µï¼ŒèŒƒå›´å¹¿è€Œæ¶‰çŒä¸æ·±ï¼ŒåŒ…æ‹¬é«˜é˜¶å‡½æ•°ï¼ŒæŠ½è±¡ï¼Œé€’å½’å’Œæ ‘ï¼ŒOOPï¼Œç®€å•çš„SQLè¯­å¥ï¼ŒSchemeè¯­æ³•å’Œè§£é‡Šå™¨ç­‰æ¦‚å¿µã€‚</p><p>ç›®å‰æ¨èçš„è¯¾ç¨‹æ˜¯20å¹´ç§‹å­£å­¦æœŸ(fa20)çš„è¯¾ç¨‹ã€‚</p><p>â€”â€”åæ ¡å…¬å¼€è¯¾ç¨‹è¯„ä»·ç½‘ <a href="https://conanhujinming.github.io/comments-for-awesome-courses/UC%20BerkeleyCS61A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E4%B8%8E%E8%A7%A3%E9%87%8A/">åæ ¡å…¬å¼€è¯¾ç¨‹è¯„ä»·ç½‘-cs61a</a></p></blockquote><h2 id="æ–‡æ¡£ç»„ç»‡"><a href="#æ–‡æ¡£ç»„ç»‡" class="headerlink" title="æ–‡æ¡£ç»„ç»‡"></a>æ–‡æ¡£ç»„ç»‡</h2><p>å¯¹åº”ä¸åŒæ•™å­¦å†…å®¹ï¼Œæ–‡æ¡£ç»„ç»‡å¦‚ä¸‹ï¼š</p><img src="/images/cs61a/01/zuzhi.jpg" width = "200" alt="" align="center" /><ul><li>0_è¯¾ä»¶ï¼šlecture</li><li>1_ä»£ç ï¼šlectureä»£ç </li><li>2_ç¬”è®°ï¼šå­¦ä¹ ç¬”è®°<ul><li>ä½¿ç”¨markdown</li><li>å†…å®¹åŒ…æ‹¬ï¼šWeekxå†…å®¹(x=week number), Lecture Notes, Lab Notes, Homework Notes</li></ul></li><li>3_å®éªŒï¼šlab</li><li>4_ä½œä¸šï¼šhomework</li><li>5_é¡¹ç›®ï¼šproject</li></ul><h2 id="Week1å†…å®¹"><a href="#Week1å†…å®¹" class="headerlink" title="Week1å†…å®¹"></a>Week1å†…å®¹</h2><img src="/images/cs61a/01/00.jpg" alt="" align="center" /><p>Week1ä¸»è¦å†…å®¹ï¼š</p><ul><li><p>Lecture01 Computer Science; Lecture02 Functions ä»‹ç»è®¡ç®—æœºç§‘å­¦å’Œå‡½æ•°åŸºç¡€çŸ¥è¯†</p></li><li><p>Lab00: Getting Started å®‰è£…Python3ï¼Œç»ˆç«¯çš„ä½¿ç”¨ï¼Œå¸¸ç”¨å‘½ä»¤è¡Œï¼Œæ–‡æ¡£æµ‹è¯•ï¼ˆdoctestï¼‰çš„ä½¿ç”¨ï¼Œæµ‹è¯•å’Œæäº¤ä½¿ç”¨OKç³»ç»Ÿ</p><img src="/images/cs61a/01/02.jpg" width = "500" alt="" align="center" /></li><li><p>HW01: Variables &amp; Functions, Controlã€‚æŒæ¡å‡½æ•°ç‰¹æ€§</p></li></ul><h2 id="Lecture-Notes"><a href="#Lecture-Notes" class="headerlink" title="Lecture Notes"></a>Lecture Notes</h2><h3 id="What-is-Computer-Science"><a href="#What-is-Computer-Science" class="headerlink" title="What is Computer Science"></a>What is Computer Science</h3><img src="/images/cs61a/01/01.jpg" alt="" width = "700" align="center" /><p>è®¡ç®—æœºç§‘å­¦æ˜¯ä¸€é—¨å®šä¹‰å’Œè§£å†³è®¡ç®—é—®é¢˜çš„æ–¹æ³•å’ŒæŠ€æœ¯çš„å­¦ç§‘ã€‚å®ƒçš„åˆ†æ”¯ç»“æ„å‚è€ƒCSRankingçš„åˆ†ç±»æ–¹å¼ï¼ˆ <a href="http://csrankings.org/#/index?all&world">http://csrankings.org/#/index?all&amp;world</a>ï¼‰ï¼Œå¤§æ¦‚å¯ä»¥åˆ†ä¸ºäººå·¥æ™ºèƒ½ï¼ˆè®¡ç®—æœºè§†è§‰ã€æœºå™¨å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€ä¿¡æ¯æ£€ç´¢â€¦ï¼‰ã€ç³»ç»Ÿï¼ˆè®¡ç®—æœºç»“æ„ã€ç½‘ç»œã€å®‰å…¨ã€æ•°æ®åº“ã€æ“ä½œç³»ç»Ÿã€åˆ†å¸ƒå¼â€¦ï¼‰ã€ç†è®ºï¼ˆç®—æ³•å’Œå¤æ‚åº¦ã€formal methodâ€¦ï¼‰ã€äº¤å‰ï¼ˆè®¡ç®—ç”Ÿç‰©/ç”Ÿç‰©è®¡ç®—ã€äººæœºäº¤äº’ã€æœºå™¨äººâ€¦ï¼‰ç­‰æ–¹å‘ã€‚</p><h3 id="Anatomy-of-a-Call-Expression-Operator-Operand"><a href="#Anatomy-of-a-Call-Expression-Operator-Operand" class="headerlink" title="Anatomy of a Call Expression: Operator, Operand"></a>Anatomy of a Call Expression: Operator, Operand</h3><img src="/images/cs61a/01/03.jpg" width = "700" alt="" align="center" /><blockquote><p>åœ¨ç¨‹å¼èªè¨€ä¸­, æŒ‡ç¤ºç¨‹å¼é€²è¡Œé‹ç®—(è¨ˆç®—ã€æ¯”è¼ƒæˆ–é€£çµ) çš„ç¬¦è™Ÿ, ç¨±ç‚ºoperators (é‹ç®—å­), è¢«é‹ç®—çš„è³‡æ–™ç¨±ç‚ºoperands (é‹ç®—å…ƒ), ä¸€å¥ä¸­æœ‰operators åŠoperands å°±ç¨±ç‚ºexpressionã€‚</p></blockquote><h3 id="Environment-Diagrams"><a href="#Environment-Diagrams" class="headerlink" title="Environment Diagrams"></a>Environment Diagrams</h3><img src="/images/cs61a/01/04.jpg" width = "700" alt="" align="center" /><p>Environment Diagrams Tools: <a href="http://pythontutor.com/composingprograms.html#mode=edit">http://pythontutor.com/composingprograms.html#mode=edit</a></p><h3 id="Defining-Functions"><a href="#Defining-Functions" class="headerlink" title="Defining Functions"></a>Defining Functions</h3><img src="/images/cs61a/01/05.jpg" alt="" width = "700" align="center" /><img src="/images/cs61a/01/06.jpg" alt="" width = "700" align="center" /><img src="/images/cs61a/01/07.jpg" alt="" width = "700" align="center" /><p>è¿™é‡Œæ¶‰åŠåˆ°å…¨å±€å˜é‡ï¼ˆGlobal Variableï¼‰å’Œå±€éƒ¨å˜é‡ï¼ˆLocal Variableï¼‰çš„é—®é¢˜ï¼Œå…¨å±€å˜é‡æ˜¯æ•´ä¸ªç¨‹åºéƒ½å¯è®¿é—®çš„å˜é‡ï¼Œç”Ÿå­˜æœŸä»ç¨‹åºå¼€å§‹åˆ°ç¨‹åºç»“æŸï¼›å±€éƒ¨å˜é‡å­˜åœ¨äºæ¨¡å—ä¸­(æ¯”å¦‚æŸä¸ªå‡½æ•°)ï¼Œåªæœ‰åœ¨æ¨¡å—ä¸­æ‰å¯ä»¥è®¿é—®ï¼Œç”Ÿå­˜æœŸä»æ¨¡å—å¼€å§‹åˆ°æ¨¡å—ç»“æŸã€‚ç®€å•çš„è¯´ï¼Œ</p><ul><li>å…¨å±€å˜é‡ï¼šåœ¨æ¨¡å—å†…ã€åœ¨æ‰€æœ‰å‡½æ•°çš„å¤–é¢ã€åœ¨classå¤–é¢</li><li>å±€éƒ¨å˜é‡ï¼šåœ¨å‡½æ•°å†…ã€åœ¨classçš„æ–¹æ³•å†…</li></ul><h2 id="Lab-Notes"><a href="#Lab-Notes" class="headerlink" title="Lab Notes"></a>Lab Notes</h2><p>å¸¸ç”¨å‘½ä»¤:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ls: lists all files in the current directory</span><br><span class="line">cd &lt;path to directory&gt;: change into the specified directory</span><br><span class="line">mkdir &lt;directory name&gt;: make a new directory with the given name</span><br><span class="line">mv &lt;source path&gt; &lt;destination path&gt;: move the file at the given source to the given destination</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python3 xxx.py # è¿è¡Œç¨‹åº</span><br><span class="line">python3 -i xxx.py # è¿è¡Œç¨‹åºå¹¶æ‰“å¼€äº¤äº’å¼ä¼šè¯</span><br><span class="line">python3 -m doctest xxx.py # è¿è¡Œæ–‡æ¡£æµ‹è¯•</span><br><span class="line">python3 -m doctest - xxx.py # è¿è¡Œæ–‡æ¡£æµ‹è¯•å¹¶æ˜¾ç¤ºæ ·ä¾‹</span><br></pre></td></tr></table></figure><h2 id="Homework-Notes"><a href="#Homework-Notes" class="headerlink" title="Homework Notes"></a>Homework Notes</h2><h3 id="Bug"><a href="#Bug" class="headerlink" title="Bug"></a>Bug</h3><p><code>TypeError: &#39;int&#39; object is not callable</code></p><p>ä¿®æ”¹ç¨‹åºåå°±å¯ä»¥äº†ã€‚</p><h3 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h3><p>Q5: If Function vs Statement</p><img src="/images/cs61a/01/hwp01.jpg" alt="" align="center" /><p>whileâ€¦<br><img src="/images/cs61a/01/hwp02.jpg" alt=""  width="200" align="left" /><br><br><br><br></p><h2 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h2><ul><li>cs61a 20fall å®˜ç½‘ <a href="https://inst.eecs.berkeley.edu/~cs61a/fa20/">https://inst.eecs.berkeley.edu/~cs61a/fa20/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;å‰è¨€&quot;&gt;&lt;a href=&quot;#å‰è¨€&quot; class=&quot;headerlink&quot; title=&quot;å‰è¨€&quot;&gt;&lt;/a&gt;å‰è¨€&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;CS61Aä½œä¸º61ç³»åˆ—åŸºç¡€è¯¾ç¨‹çš„ç¬¬ä¸€é—¨è¯¾ç¨‹ï¼Œæ˜¯ä¸€é—¨è®¡ç®—æœºå…¥é—¨å¯¼è®ºè¯¾ç¨‹ï¼Œä¼¯å…‹åˆ©å¤§ä¸€æ–°ç”Ÿçš„ç¬¬ä¸€é—¨è®¡ç®—æœºè¯¾ç¨‹ã€‚è¯¥è¯¾ç¨‹ä¸»è¦</summary>
      
    
    
    
    <category term="01 è®¡ç®—æœºåŸºç¡€" scheme="http://example.com/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CS61A è®¡ç®—æœºç¨‹åºçš„æ„é€ ä¸è§£é‡Š" scheme="http://example.com/categories/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/CS61A-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E4%B8%8E%E8%A7%A3%E9%87%8A/"/>
    
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
    <category term="CSå…¬å¼€è¯¾" scheme="http://example.com/tags/CS%E5%85%AC%E5%BC%80%E8%AF%BE/"/>
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="function" scheme="http://example.com/tags/function/"/>
    
  </entry>
  
  <entry>
    <title>å…¬å¼ä¹‹ç¾-EVERYTHING IS EPHEMERAL BUT FORMULA IS ETERNAL</title>
    <link href="http://example.com/formula/"/>
    <id>http://example.com/formula/</id>
    <published>2021-08-04T12:27:54.000Z</published>
    <updated>2021-09-27T02:33:41.405Z</updated>
    
    <content type="html"><![CDATA[<p>ä¸€ä¸ªæœ‰ç‚¹æ„æ€çš„ç§‘æ™®ä¹¦ï¼Œå°¤å…¶åœ¨ä¸æƒ³å†™è®ºæ–‡çš„æ—¶å€™ï¼Œå®æ„¿å»çœ‹å‹¾è‚¡å®šç†çš„Nç§æ¨å¯¼ä¹Ÿä¸æ„¿æ„ç¢°è®ºæ–‡ã€‚æ›´å¥½ç©çš„æ˜¯ï¼Œè¿™é‡Œé¢çš„æ’å›¾è¦æ¯”å†…å®¹æ›´æ²¡æœ‰äº‰è®®çš„è·å¾—ä¸€è‡´å¥½è¯„ã€‚</p><blockquote><p>1854å¹´ä¹‹å‰ï¼Œæ¬§æ´²æ•°å­¦å®¶ç¿è‹¥æ˜Ÿè¾°ï¼Œç¬›å¡å„¿ã€æ‹‰æ ¼æœ—æ—¥ã€ç‰›é¡¿ã€è´å¶æ–¯ã€æ‹‰æ™®æ‹‰æ–¯ã€æŸ¯è¥¿ã€å‚…é‡Œå¶ã€ä¼½ç½—ç“¦ç­‰ï¼Œæ— ä¸€ä¸æ˜¯æ•°å­¦å¤©æ‰ã€‚<br>1854â€”1935å¹´ï¼Œé«˜æ–¯ã€é»æ›¼ç­‰äººåœ¨æ•°å­¦ç•Œé¢†è¢–ç¾¤ä¼¦ï¼Œå¾·å›½å–ä»£è‹±æ³•æˆä¸ºä¸–ç•Œçš„æ•°å­¦ä¸­å¿ƒã€‚<br>1935å¹´ä¹‹åï¼Œå¸Œç‰¹å‹’ç»™ç¾å›½é€ä¸Šâ€œç§‘å­¦å¤§ç¤¼åŒ…â€ï¼šå“¥å¾·å°”ã€çˆ±å› æ–¯å¦ã€å¾·æ‹œã€å†¯.è¯ºä¾æ›¼ã€è´¹ç±³ã€å†¯.å¡é—¨ã€å¤–å°”â€¦â€¦å¾ˆå¤šç§‘å­¦å®¶é€ƒè‡³åŒ—ç¾ï¼Œæ•°å­¦å¤§æœ¬è¥ä»å¾·å›½è½¬å‘ç¾å›½ï¼Œç¾å›½æˆä¸ºä¸–ç•Œçš„æ•°å­¦ä¸­å¿ƒã€‚</p></blockquote><blockquote><p>å¤å¸Œè…Šå‡ ä½•å­¦å®¶é˜¿æ³¢æ´›å°¼ä¹Œæ–¯æ€»ç»“äº†åœ†é”¥æ›²çº¿ç†è®ºï¼Œä¸€åƒå¤šå¹´åï¼Œå¾·å›½å¤©æ–‡å­¦å®¶å¼€æ™®å‹’æ‰å°†å…¶åº”ç”¨äºè¡Œæ˜Ÿè½¨é“ï¼›é«˜æ–¯è¢«è®¤ä¸ºæœ€æ—©å‘ç°éæ¬§å‡ ä½•ï¼ŒåŠä¸ªä¸–çºªåï¼Œç”±ä»–å¼Ÿå­åˆ›ç«‹çš„é»æ›¼å‡ ä½•æˆä¸ºå¹¿ä¹‰ç›¸å¯¹è®ºçš„æ•°å­¦åŸºç¡€ã€‚ä¼´éšç€æ æ†åŸç†ã€ç‰›é¡¿ä¸‰å¤§å®šå¾‹ã€éº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ã€é¦™å†œå…¬å¼ã€è´å¶æ–¯å®šç†ç­‰ï¼Œäººç±»å‘è’¸æ±½æ—¶ä»£ã€ç”µåŠ›æ—¶ä»£ã€ä¿¡æ¯æ—¶ä»£ä¹ƒè‡³äººå·¥æ™ºèƒ½æ—¶ä»£å¾å¾è¿ˆè¿›ã€‚</p></blockquote><h2 id="1-1-2ï¼šæ•°å­¦çš„æº¯æº"><a href="#1-1-2ï¼šæ•°å­¦çš„æº¯æº" class="headerlink" title="1+1=2ï¼šæ•°å­¦çš„æº¯æº"></a>1+1=2ï¼šæ•°å­¦çš„æº¯æº</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/00-1plus1.jpg?raw=true" width="600" alt="" align="center" /><h2 id="å‹¾è‚¡å®šç†ï¼šæ•°ä¸å½¢çš„ç»“åˆ"><a href="#å‹¾è‚¡å®šç†ï¼šæ•°ä¸å½¢çš„ç»“åˆ" class="headerlink" title="å‹¾è‚¡å®šç†ï¼šæ•°ä¸å½¢çš„ç»“åˆ"></a>å‹¾è‚¡å®šç†ï¼šæ•°ä¸å½¢çš„ç»“åˆ</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/01-gougudingli.jpg?raw=true" width="600" alt="" align="center" /><h2 id="è´¹é©¬å¤§å®šç†ï¼šå›°æ‰°äººç±»358å¹´"><a href="#è´¹é©¬å¤§å®šç†ï¼šå›°æ‰°äººç±»358å¹´" class="headerlink" title="è´¹é©¬å¤§å®šç†ï¼šå›°æ‰°äººç±»358å¹´"></a>è´¹é©¬å¤§å®šç†ï¼šå›°æ‰°äººç±»358å¹´</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/02-feima.jpg?raw=true" width="600" alt="" align="center" /><h2 id="ç‰›é¡¿-è±å¸ƒå°¼èŒ¨å…¬å¼ï¼šæ— ç©·å°çš„ç§˜å¯†"><a href="#ç‰›é¡¿-è±å¸ƒå°¼èŒ¨å…¬å¼ï¼šæ— ç©·å°çš„ç§˜å¯†" class="headerlink" title="ç‰›é¡¿-è±å¸ƒå°¼èŒ¨å…¬å¼ï¼šæ— ç©·å°çš„ç§˜å¯†"></a>ç‰›é¡¿-è±å¸ƒå°¼èŒ¨å…¬å¼ï¼šæ— ç©·å°çš„ç§˜å¯†</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/03-weijifen.jpg?raw=true" width="600" alt="" align="center" /><h2 id="ä¸‡æœ‰å¼•åŠ›ï¼šä»æ··æ²Œåˆ°å…‰æ˜"><a href="#ä¸‡æœ‰å¼•åŠ›ï¼šä»æ··æ²Œåˆ°å…‰æ˜" class="headerlink" title="ä¸‡æœ‰å¼•åŠ›ï¼šä»æ··æ²Œåˆ°å…‰æ˜"></a>ä¸‡æœ‰å¼•åŠ›ï¼šä»æ··æ²Œåˆ°å…‰æ˜</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/04-wanyouyinli.jpg?raw=true" width="600" alt="" align="center" /><h2 id="æ¬§æ‹‰å…¬å¼ï¼šæœ€ç¾çš„ç­‰å¼"><a href="#æ¬§æ‹‰å…¬å¼ï¼šæœ€ç¾çš„ç­‰å¼" class="headerlink" title="æ¬§æ‹‰å…¬å¼ï¼šæœ€ç¾çš„ç­‰å¼"></a>æ¬§æ‹‰å…¬å¼ï¼šæœ€ç¾çš„ç­‰å¼</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/05-oula.jpg?raw=true" width="600" alt="" align="center" /><h2 id="ä¼½ç½—ç“¦ç†è®ºï¼šæ— è§£çš„æ–¹ç¨‹"><a href="#ä¼½ç½—ç“¦ç†è®ºï¼šæ— è§£çš„æ–¹ç¨‹" class="headerlink" title="ä¼½ç½—ç“¦ç†è®ºï¼šæ— è§£çš„æ–¹ç¨‹"></a>ä¼½ç½—ç“¦ç†è®ºï¼šæ— è§£çš„æ–¹ç¨‹</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/06-jialuowa.jpg?raw=true" width="600" alt="" align="center" /><h2 id="å±é™©çš„é»æ›¼çŒœæƒ³"><a href="#å±é™©çš„é»æ›¼çŒœæƒ³" class="headerlink" title="å±é™©çš„é»æ›¼çŒœæƒ³"></a>å±é™©çš„é»æ›¼çŒœæƒ³</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/07-liman.jpg?raw=true" width="600" alt="" align="center" /><h2 id="ç†µå¢å®šå¾‹ï¼šå¯‚ç­æ˜¯å®‡å®™å®¿å‘½ï¼Ÿ"><a href="#ç†µå¢å®šå¾‹ï¼šå¯‚ç­æ˜¯å®‡å®™å®¿å‘½ï¼Ÿ" class="headerlink" title="ç†µå¢å®šå¾‹ï¼šå¯‚ç­æ˜¯å®‡å®™å®¿å‘½ï¼Ÿ"></a>ç†µå¢å®šå¾‹ï¼šå¯‚ç­æ˜¯å®‡å®™å®¿å‘½ï¼Ÿ</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/08-shang.jpg?raw=true" width="600" alt="" align="center" /><h2 id="éº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ç»„ï¼šè®©é»‘æš—æ¶ˆå¤±"><a href="#éº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ç»„ï¼šè®©é»‘æš—æ¶ˆå¤±" class="headerlink" title="éº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ç»„ï¼šè®©é»‘æš—æ¶ˆå¤±"></a>éº¦å…‹æ–¯éŸ¦æ–¹ç¨‹ç»„ï¼šè®©é»‘æš—æ¶ˆå¤±</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/09-mksw.jpg?raw=true" width="600" alt="" align="center" /><h2 id="è´¨èƒ½æ–¹ç¨‹ï¼šå¼€å¯æ½˜å¤šæ‹‰çš„é­”ç›’"><a href="#è´¨èƒ½æ–¹ç¨‹ï¼šå¼€å¯æ½˜å¤šæ‹‰çš„é­”ç›’" class="headerlink" title="è´¨èƒ½æ–¹ç¨‹ï¼šå¼€å¯æ½˜å¤šæ‹‰çš„é­”ç›’"></a>è´¨èƒ½æ–¹ç¨‹ï¼šå¼€å¯æ½˜å¤šæ‹‰çš„é­”ç›’</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/10-zhineng.jpg?raw=true" width="600" alt="" align="center" /><h2 id="è–›å®šè°”æ–¹ç¨‹ï¼šçŒ«ä¸é‡å­ä¸–ç•Œ"><a href="#è–›å®šè°”æ–¹ç¨‹ï¼šçŒ«ä¸é‡å­ä¸–ç•Œ" class="headerlink" title="è–›å®šè°”æ–¹ç¨‹ï¼šçŒ«ä¸é‡å­ä¸–ç•Œ"></a>è–›å®šè°”æ–¹ç¨‹ï¼šçŒ«ä¸é‡å­ä¸–ç•Œ</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/11-uedinge.jpg?raw=true" width="600" alt="" align="center" /><h2 id="ç‹„æ‹‰å…‹æ–¹ç¨‹ï¼šåç‰©è´¨çš„â€œå…ˆçŸ¥â€"><a href="#ç‹„æ‹‰å…‹æ–¹ç¨‹ï¼šåç‰©è´¨çš„â€œå…ˆçŸ¥â€" class="headerlink" title="ç‹„æ‹‰å…‹æ–¹ç¨‹ï¼šåç‰©è´¨çš„â€œå…ˆçŸ¥â€"></a>ç‹„æ‹‰å…‹æ–¹ç¨‹ï¼šåç‰©è´¨çš„â€œå…ˆçŸ¥â€</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/12-dilake.jpg?raw=true" width="600" alt="" align="center" /><h2 id="æ¨-ç±³å°”æ–¯è§„èŒƒåœºè®ºï¼šå¤§ç»Ÿä¸€ä¹‹è·¯"><a href="#æ¨-ç±³å°”æ–¯è§„èŒƒåœºè®ºï¼šå¤§ç»Ÿä¸€ä¹‹è·¯" class="headerlink" title="æ¨-ç±³å°”æ–¯è§„èŒƒåœºè®ºï¼šå¤§ç»Ÿä¸€ä¹‹è·¯"></a>æ¨-ç±³å°”æ–¯è§„èŒƒåœºè®ºï¼šå¤§ç»Ÿä¸€ä¹‹è·¯</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/13-yang.jpg?raw=true" width="600" alt="" align="center" /><h2 id="é¦™å†œå…¬å¼ï¼š5GèƒŒåçš„ä¸»å®°"><a href="#é¦™å†œå…¬å¼ï¼š5GèƒŒåçš„ä¸»å®°" class="headerlink" title="é¦™å†œå…¬å¼ï¼š5GèƒŒåçš„ä¸»å®°"></a>é¦™å†œå…¬å¼ï¼š5GèƒŒåçš„ä¸»å®°</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/14-xiangnong.jpg?raw=true" width="600" alt="" align="center" /><h2 id="å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯æ–¹ç¨‹ï¼šé‡‘èâ€œå·«å¸ˆâ€"><a href="#å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯æ–¹ç¨‹ï¼šé‡‘èâ€œå·«å¸ˆâ€" class="headerlink" title="å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯æ–¹ç¨‹ï¼šé‡‘èâ€œå·«å¸ˆâ€"></a>å¸ƒè±å…‹-æ–¯ç§‘å°”æ–¯æ–¹ç¨‹ï¼šé‡‘èâ€œå·«å¸ˆâ€</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/15-bulaike.jpg?raw=true" width="600" alt="" align="center" /><h2 id="æªæ¢°ï¼šå¼¹é“é‡Œçš„â€œæŠ€æœ¯å“²å­¦â€"><a href="#æªæ¢°ï¼šå¼¹é“é‡Œçš„â€œæŠ€æœ¯å“²å­¦â€" class="headerlink" title="æªæ¢°ï¼šå¼¹é“é‡Œçš„â€œæŠ€æœ¯å“²å­¦â€"></a>æªæ¢°ï¼šå¼¹é“é‡Œçš„â€œæŠ€æœ¯å“²å­¦â€</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/16-qiangxie.jpg?raw=true" width="600" alt="" align="center" /><h2 id="èƒ¡å…‹å®šå¾‹ï¼šæœºæ¢°è¡¨çš„å¿ƒè„"><a href="#èƒ¡å…‹å®šå¾‹ï¼šæœºæ¢°è¡¨çš„å¿ƒè„" class="headerlink" title="èƒ¡å…‹å®šå¾‹ï¼šæœºæ¢°è¡¨çš„å¿ƒè„"></a>èƒ¡å…‹å®šå¾‹ï¼šæœºæ¢°è¡¨çš„å¿ƒè„</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/17-huke.jpg?raw=true" width="600" alt="" align="center" /><h2 id="æ··æ²Œç†è®ºï¼šä¸€åªè´è¶å¼•å‘çš„æ€è€ƒ"><a href="#æ··æ²Œç†è®ºï¼šä¸€åªè´è¶å¼•å‘çš„æ€è€ƒ" class="headerlink" title="æ··æ²Œç†è®ºï¼šä¸€åªè´è¶å¼•å‘çš„æ€è€ƒ"></a>æ··æ²Œç†è®ºï¼šä¸€åªè´è¶å¼•å‘çš„æ€è€ƒ</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/18-hundun.jpg?raw=true" width="600" alt="" align="center" /><h2 id="å‡¯åˆ©å…¬å¼ï¼šèµŒåœºä¸Šçš„æœ€å¤§èµ¢å®¶"><a href="#å‡¯åˆ©å…¬å¼ï¼šèµŒåœºä¸Šçš„æœ€å¤§èµ¢å®¶" class="headerlink" title="å‡¯åˆ©å…¬å¼ï¼šèµŒåœºä¸Šçš„æœ€å¤§èµ¢å®¶"></a>å‡¯åˆ©å…¬å¼ï¼šèµŒåœºä¸Šçš„æœ€å¤§èµ¢å®¶</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/19-kaili.jpg?raw=true" width="600" alt="" align="center" /><h2 id="è´å¶æ–¯å®šç†ï¼šAIå¦‚ä½•æ€è€ƒï¼Ÿ"><a href="#è´å¶æ–¯å®šç†ï¼šAIå¦‚ä½•æ€è€ƒï¼Ÿ" class="headerlink" title="è´å¶æ–¯å®šç†ï¼šAIå¦‚ä½•æ€è€ƒï¼Ÿ"></a>è´å¶æ–¯å®šç†ï¼šAIå¦‚ä½•æ€è€ƒï¼Ÿ</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/20-beiyesi.jpg?raw=true" width="600" alt="" align="center" /><h2 id="ä¸‰ä½“é—®é¢˜ï¼šæŒ¥ä¹‹ä¸å»çš„ä¹Œäº‘"><a href="#ä¸‰ä½“é—®é¢˜ï¼šæŒ¥ä¹‹ä¸å»çš„ä¹Œäº‘" class="headerlink" title="ä¸‰ä½“é—®é¢˜ï¼šæŒ¥ä¹‹ä¸å»çš„ä¹Œäº‘"></a>ä¸‰ä½“é—®é¢˜ï¼šæŒ¥ä¹‹ä¸å»çš„ä¹Œäº‘</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/21-santi.jpg?raw=true" width="600" alt="" align="center" /><h2 id="æ¤­åœ†æ›²çº¿æ–¹ç¨‹ï¼šæ¯”ç‰¹å¸çš„åŸºçŸ³"><a href="#æ¤­åœ†æ›²çº¿æ–¹ç¨‹ï¼šæ¯”ç‰¹å¸çš„åŸºçŸ³" class="headerlink" title="æ¤­åœ†æ›²çº¿æ–¹ç¨‹ï¼šæ¯”ç‰¹å¸çš„åŸºçŸ³"></a>æ¤­åœ†æ›²çº¿æ–¹ç¨‹ï¼šæ¯”ç‰¹å¸çš„åŸºçŸ³</h2><img src="https://github.com/chuxiaoyu/blog_image/blob/master/formula/22-bitcoin.jpg?raw=true" width="600" alt="" align="center" /><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li>ã€Šå…¬å¼ä¹‹ç¾ã€‹<a href="https://book.douban.com/subject/35218287/">https://book.douban.com/subject/35218287/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;ä¸€ä¸ªæœ‰ç‚¹æ„æ€çš„ç§‘æ™®ä¹¦ï¼Œå°¤å…¶åœ¨ä¸æƒ³å†™è®ºæ–‡çš„æ—¶å€™ï¼Œå®æ„¿å»çœ‹å‹¾è‚¡å®šç†çš„Nç§æ¨å¯¼ä¹Ÿä¸æ„¿æ„ç¢°è®ºæ–‡ã€‚æ›´å¥½ç©çš„æ˜¯ï¼Œè¿™é‡Œé¢çš„æ’å›¾è¦æ¯”å†…å®¹æ›´æ²¡æœ‰äº‰è®®çš„è·å¾—ä¸€è‡´å¥½è¯„ã€‚&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1854å¹´ä¹‹å‰ï¼Œæ¬§æ´²æ•°å­¦å®¶ç¿è‹¥æ˜Ÿè¾°ï¼Œç¬›å¡å„¿ã€æ‹‰æ ¼æœ—æ—¥ã€ç‰›é¡¿ã€è´å¶æ–¯ã€æ‹‰æ™®æ‹‰æ–¯ã€æŸ¯è¥¿ã€å‚…</summary>
      
    
    
    
    <category term="æ²‰æ€å½•" scheme="http://example.com/categories/%E6%B2%89%E6%80%9D%E5%BD%95/"/>
    
    
    <category term="é˜…è¯»" scheme="http://example.com/tags/%E9%98%85%E8%AF%BB/"/>
    
    <category term="math" scheme="http://example.com/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>NLPä¹‹æ–‡æœ¬è¡¨ç¤º</title>
    <link href="http://example.com/nlp-text-representation/"/>
    <id>http://example.com/nlp-text-representation/</id>
    <published>2021-07-31T11:48:54.000Z</published>
    <updated>2021-11-24T09:49:10.494Z</updated>
    
    <content type="html"><![CDATA[<p>ï¼ˆæŒ–å‘å¾…å¡«â€¦ï¼‰</p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li><a href=""></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;ï¼ˆæŒ–å‘å¾…å¡«â€¦ï¼‰&lt;/p&gt;
&lt;h1 id=&quot;å‚è€ƒèµ„æ–™&quot;&gt;&lt;a href=&quot;#å‚è€ƒèµ„æ–™&quot; class=&quot;headerlink&quot; title=&quot;å‚è€ƒèµ„æ–™&quot;&gt;&lt;/a&gt;å‚è€ƒèµ„æ–™&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</summary>
      
    
    
    
    <category term="02 äººå·¥æ™ºèƒ½" scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="è‡ªç„¶è¯­è¨€å¤„ç†" scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
    <category term="NLP" scheme="http://example.com/tags/NLP/"/>
    
    <category term="æ–‡æœ¬è¡¨ç¤º" scheme="http://example.com/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA/"/>
    
  </entry>
  
  <entry>
    <title>SQLè¡¨è¿æ¥&amp;èšåˆå‡½æ•°&amp;çª—å£å‡½æ•°</title>
    <link href="http://example.com/SQL%E9%87%8D%E7%82%B9/"/>
    <id>http://example.com/SQL%E9%87%8D%E7%82%B9/</id>
    <published>2021-07-26T19:33:19.000Z</published>
    <updated>2021-09-17T01:53:20.789Z</updated>
    
    <content type="html"><![CDATA[<h1 id="è¡¨è¿æ¥-join"><a href="#è¡¨è¿æ¥-join" class="headerlink" title="è¡¨è¿æ¥ join"></a>è¡¨è¿æ¥ join</h1><p>join: ä»¥å­—æ®µï¼ˆåˆ—ï¼‰ä¸ºå•ä½è¿›è¡Œå¤šè¡¨è¿æ¥ã€‚</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Inner</span> <span class="keyword">join</span> # åªä¿ç•™ä¸¤ä¸ªè¡¨ä¸­åŒæ—¶å­˜åœ¨çš„è®°å½•ã€‚</span><br><span class="line"><span class="keyword">Left</span> <span class="keyword">join</span> # ä¿ç•™å·¦è¡¨æ‰€æœ‰çš„è®°å½•ï¼Œæ— è®ºå…¶æ˜¯å¦èƒ½å¤Ÿåœ¨å³è¡¨ä¸­åŒ¹é…åˆ°å¯¹åº”çš„è®°å½•ã€‚è‹¥æ— åŒ¹é…è®°å½•ï¼Œåˆ™éœ€è¦ç”¨<span class="keyword">NULL</span>å¡«è¡¥ã€‚</span><br><span class="line"><span class="keyword">Right</span> <span class="keyword">join</span> # ä¿ç•™å³è¡¨æ‰€æœ‰çš„è®°å½•ï¼Œæ— è®ºå…¶æ˜¯å¦èƒ½å¤Ÿåœ¨å·¦è¡¨ä¸­åŒ¹é…åˆ°å¯¹åº”çš„è®°å½•ã€‚è‹¥æ— åŒ¹é…è®°å½•ï¼Œåˆ™éœ€è¦ç”¨<span class="keyword">NULL</span>å¡«è¡¥ã€‚</span><br><span class="line"><span class="keyword">Full</span> <span class="keyword">join</span> # å·¦è¡¨å’Œå³è¡¨æ‰€æœ‰çš„è®°å½•éƒ½ä¼šä¿ç•™ï¼Œæ²¡æœ‰åŒ¹é…è®°å½•çš„ç”¨<span class="keyword">NULL</span>å¡«è¡¥ã€‚</span><br></pre></td></tr></table></figure><h1 id="èšåˆå‡½æ•°"><a href="#èšåˆå‡½æ•°" class="headerlink" title="èšåˆå‡½æ•°"></a>èšåˆå‡½æ•°</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sum</span>() # è¿”å›åˆ†ç»„åç»„å†…æ‰€æœ‰è®°å½•çš„å’Œ</span><br><span class="line"><span class="built_in">avg</span>() # è¿”å›åˆ†ç»„åç»„å†…æ‰€æœ‰è®°å½•çš„å‡å€¼</span><br><span class="line"><span class="built_in">count</span>() # è¿”å›åˆ†ç»„åç»„å†…æ‰€æœ‰è®°å½•çš„è®¡æ•°</span><br><span class="line"><span class="built_in">max</span>()<span class="operator">/</span><span class="built_in">min</span>() # è¿”å›åˆ†ç»„åç»„å†…æ‰€æœ‰è®°å½•çš„æœ€å¤§å€¼ã€æœ€å°å€¼</span><br></pre></td></tr></table></figure><h1 id="çª—å£å‡½æ•°"><a href="#çª—å£å‡½æ•°" class="headerlink" title="çª—å£å‡½æ•°"></a>çª—å£å‡½æ•°</h1><p>çª—å£å‡½æ•°å¯¹è®°å½•åˆ†ç»„ä¹‹åè¿›è¡Œèšåˆè®¡ç®—ï¼Œä¸ºåˆ†ç»„ä¸­çš„æ¯æ¡è®°å½•è¿”å›ç‰¹å®šå€¼ã€‚</p><p>çª—å£å‡½æ•°çš„åŸºæœ¬ç»“æ„æ˜¯ï¼š</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&lt;</span>çª—å£å‡½æ•°<span class="operator">&gt;</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> <span class="operator">&lt;</span>col1, col2<span class="operator">&gt;</span> </span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> <span class="operator">&lt;</span>col3 <span class="keyword">desc</span><span class="operator">/</span><span class="keyword">asc</span>, col4 <span class="keyword">asc</span><span class="operator">/</span><span class="keyword">desc</span><span class="operator">&gt;</span>)</span><br></pre></td></tr></table></figure><table><thead><tr><th>çª—å£å‡½æ•°</th><th>ä»‹ç»</th></tr></thead><tbody><tr><td><code>rank() over()</code></td><td>è¿”å›è®°å½•åœ¨åŒä¸€åˆ†ç»„å†…çš„æ’åºï¼Œå¦‚æœæœ‰å¹¶åˆ—åæ¬¡çš„è¡Œï¼Œä¼šå ç”¨ä¸‹ä¸€åæ¬¡çš„ä½ç½®</td></tr><tr><td><code>dense_rank() over()</code></td><td>è¿”å›è®°å½•åœ¨åŒä¸€åˆ†ç»„å†…çš„æ’åºï¼Œå¦‚æœæœ‰å¹¶åˆ—åæ¬¡çš„è¡Œï¼Œä¸å ç”¨ä¸‹ä¸€åæ¬¡çš„ä½ç½®</td></tr><tr><td><code>row_number() over()</code></td><td>è¿”å›è®°å½•åœ¨åŒä¸€åˆ†ç»„å†…çš„æ’åºï¼Œä¸è€ƒè™‘å¹¶åˆ—åæ¬¡çš„æƒ…å†µ</td></tr><tr><td><code>percent_rank() over()</code></td><td>è¿”å›è®°å½•åœ¨åŒä¸€åˆ†ç»„å†…æ’åºçš„åˆ†ä½æ•°ï¼Œä¸º0~1</td></tr><tr><td><code>sum(col) over()</code></td><td>è¿”å›åŒä¸€åˆ†ç»„å†…æ‰€æœ‰è®°å½•colå€¼çš„å’Œï¼ŒåŒä¸€åˆ†ç»„å†…è®°å½•çš„è¿”å›å€¼ç›¸åŒ</td></tr><tr><td><code>avg(col) over()</code></td><td>è¿”å›åŒä¸€åˆ†ç»„å†…æ‰€æœ‰è®°å½•colå€¼çš„å¹³å‡å€¼ï¼ŒåŒä¸€åˆ†ç»„å†…è®°å½•çš„è¿”å›å€¼ç›¸åŒ</td></tr><tr><td><code>max/min(col) over()</code></td><td>è¿”å›åŒä¸€åˆ†ç»„å†…æ‰€æœ‰è®°å½•colå€¼çš„æœ€å¤§å€¼/æœ€å°å€¼ï¼ŒåŒä¸€åˆ†ç»„å†…è®°å½•çš„è¿”å›å€¼ç›¸åŒ</td></tr></tbody></table><p>èšåˆå‡½æ•°åœ¨çª—å£å‡½æ•°ä¸­ï¼Œæ˜¯å¯¹è‡ªèº«è®°å½•ã€åŠä½äºè‡ªèº«è®°å½•ä»¥ä¸Šçš„æ•°æ®è¿›è¡Œè¿ç®—çš„ç»“æœã€‚èšåˆå‡½æ•°ä½œä¸ºçª—å£å‡½æ•°ï¼Œå¯ä»¥åœ¨æ¯ä¸€è¡Œçš„æ•°æ®é‡Œç›´è§‚çš„çœ‹åˆ°ï¼Œæˆªæ­¢åˆ°æœ¬è¡Œæ•°æ®ï¼Œç»Ÿè®¡æ•°æ®æ˜¯å¤šå°‘ï¼ˆæœ€å¤§å€¼ã€æœ€å°å€¼ç­‰ï¼‰ã€‚åŒæ—¶å¯ä»¥çœ‹å‡ºæ¯ä¸€è¡Œæ•°æ®ï¼Œå¯¹æ•´ä½“ç»Ÿè®¡æ•°æ®çš„å½±å“ã€‚</p><h1 id="ç´¢å¼•"><a href="#ç´¢å¼•" class="headerlink" title="ç´¢å¼•"></a>ç´¢å¼•</h1><p>ç´¢å¼•ç”¨æ¥æ’åºæ•°æ®ä»¥åŠ å¿«æœç´¢å’Œæ’åºæ“ä½œçš„é€Ÿåº¦ã€‚å¯ä»¥åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªåˆ—ä¸Šå®šä¹‰ç´¢å¼•ï¼Œä½¿DBMSä¿å­˜å…¶å†…å®¹çš„ä¸€ä¸ªæ’è¿‡åºçš„åˆ—è¡¨ã€‚åœ¨å®šä¹‰äº†ç´¢å¼•åï¼ŒDBMSä»¥ä½¿ç”¨ä¹¦çš„ç´¢å¼•ç±»ä¼¼çš„æ–¹æ³•ä½¿ç”¨å®ƒã€‚DBMS æœç´¢æ’è¿‡åºçš„ç´¢å¼•ï¼Œæ‰¾å‡ºåŒ¹é…çš„ä½ç½®ï¼Œç„¶åæ£€ç´¢è¿™äº›è¡Œã€‚</p><p>ç´¢å¼•æ˜¯å…³ç³»æ•°æ®åº“ä¸­å¯¹æŸä¸€åˆ—æˆ–å¤šä¸ªåˆ—çš„å€¼è¿›è¡Œé¢„æ’åºçš„æ•°æ®ç»“æ„ã€‚é€šè¿‡ä½¿ç”¨ç´¢å¼•ï¼Œå¯ä»¥è®©æ•°æ®åº“ç³»ç»Ÿä¸å¿…æ‰«ææ•´ä¸ªè¡¨ï¼Œè€Œæ˜¯ç›´æ¥å®šä½åˆ°ç¬¦åˆæ¡ä»¶çš„è®°å½•ï¼Œè¿™æ ·å°±å¤§å¤§åŠ å¿«äº†æŸ¥è¯¢é€Ÿåº¦ã€‚</p><p>ç´¢å¼•ç”¨CREATE INDEX è¯­å¥åˆ›å»ºï¼ˆä¸åŒDBMSåˆ›å»ºç´¢å¼•çš„è¯­å¥å˜åŒ–å¾ˆå¤§ï¼‰ã€‚</p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p>[1]é€šä¿—æ˜“æ‡‚çš„å­¦ä¼šï¼šSQLçª—å£å‡½æ•° <a href="https://zhuanlan.zhihu.com/p/92654574">https://zhuanlan.zhihu.com/p/92654574</a><br>[2]ã€Šæ‹¿ä¸‹Offer:æ•°æ®åˆ†æå¸ˆæ±‚èŒé¢è¯•æŒ‡å—ã€‹ <a href="https://item.jd.com/12686131.html">https://item.jd.com/12686131.html</a><br>[3]ã€ŠSQLå¿…çŸ¥å¿…ä¼šã€‹ <a href="https://book.douban.com/subject/24250054/">https://book.douban.com/subject/24250054/</a><br>[4]å»–é›ªå³°çš„å®˜æ–¹ç½‘ç«™-SQLæ•™ç¨‹ <a href="https://www.liaoxuefeng.com/wiki/1177760294764384">https://www.liaoxuefeng.com/wiki/1177760294764384</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;è¡¨è¿æ¥-join&quot;&gt;&lt;a href=&quot;#è¡¨è¿æ¥-join&quot; class=&quot;headerlink&quot; title=&quot;è¡¨è¿æ¥ join&quot;&gt;&lt;/a&gt;è¡¨è¿æ¥ join&lt;/h1&gt;&lt;p&gt;join: ä»¥å­—æ®µï¼ˆåˆ—ï¼‰ä¸ºå•ä½è¿›è¡Œå¤šè¡¨è¿æ¥ã€‚&lt;/p&gt;
&lt;figure class=&quot;high</summary>
      
    
    
    
    <category term="02 äººå·¥æ™ºèƒ½" scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="æ•°æ®åˆ†æ" scheme="http://example.com/categories/02-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="SQL" scheme="http://example.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>5hæ‰“é€šGitå…¨å¥—æ•™ç¨‹</title>
    <link href="http://example.com/git/"/>
    <id>http://example.com/git/</id>
    <published>2021-07-23T13:01:25.000Z</published>
    <updated>2021-09-17T01:53:30.399Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯ä»¥ä¸‹è¯¾ç¨‹çš„ç¬”è®°ï¼š</p><ul><li>ã€å°šç¡…è°·ã€‘5hæ‰“é€šGitå…¨å¥—æ•™ç¨‹ä¸¨2021æœ€æ–°IDEAç‰ˆï¼ˆæ¶µç›–GitHub\Giteeç äº‘\GitLabï¼‰<a href="https://www.bilibili.com/video/BV1vy4y1s7k6?p=41">https://www.bilibili.com/video/BV1vy4y1s7k6?p=41</a></li></ul><h1 id="è¯¾ç¨‹ç»“æ„"><a href="#è¯¾ç¨‹ç»“æ„" class="headerlink" title="è¯¾ç¨‹ç»“æ„"></a>è¯¾ç¨‹ç»“æ„</h1><p>æœ¬å¥—è§†é¢‘ä»åŸºç¡€çš„å¸¸ç”¨å‘½ä»¤å¼€å§‹è®²èµ·ï¼Œåˆ°å¼€å‘å·¥å…·é›†æˆGit ã€GitHubå¦‚ä½•è¿›è¡Œå›¢é˜Ÿåä½œã€å›½å†…ä»£ç æ‰˜ç®¡ä¸­å¿ƒGiteeç äº‘çš„ä½¿ç”¨ã€å±€åŸŸç½‘è‡ªå»ºä»£ç æ‰˜ç®¡å¹³å°GitLabæœåŠ¡å™¨çš„éƒ¨ç½²ã€‚<strong>ï¼ˆæœ¬æ–‡ä¸»è¦æ˜¯P1-P26çš„ç¬”è®°ã€‚ï¼‰</strong></p><ul><li>P1-P2 Git</li><li>P3-P6 Gitæ¦‚è¿°</li><li>P7-P14 Gitå‘½ä»¤</li><li>P15-P18 Gitåˆ†æ”¯</li><li>P19 Gitå›¢é˜Ÿåä½œ</li><li>P20-P26 Git&amp;GitHub</li><li>P27-P37 IDEAé›†æˆGitHub</li><li>P38-P40 Giteeç äº‘</li><li>P41-P44 GitLab</li><li>P45 è¯¾ç¨‹æ€»ç»“</li></ul><h1 id="Gitä»‹ç»"><a href="#Gitä»‹ç»" class="headerlink" title="Gitä»‹ç»"></a>Gitä»‹ç»</h1><h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><p>Gitæ˜¯ä¸€ä¸ª<strong>å…è´¹çš„ã€å¼€æºçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ</strong>ï¼Œå¯ä»¥å¿«é€Ÿé«˜æ•ˆåœ°å¤„ç†ä»å°å‹åˆ°å¤§å‹çš„å„ç§é¡¹ç›®ã€‚</p><h2 id="ç‰ˆæœ¬æ§åˆ¶"><a href="#ç‰ˆæœ¬æ§åˆ¶" class="headerlink" title="ç‰ˆæœ¬æ§åˆ¶"></a>ç‰ˆæœ¬æ§åˆ¶</h2><p>ç‰ˆæœ¬æ§åˆ¶æ˜¯ä¸€ç§è®°å½•æ–‡ä»¶å†…å®¹å˜åŒ–ï¼Œä»¥ä¾¿å°†æ¥æŸ¥é˜…ç‰¹å®šç‰ˆæœ¬ä¿®è®¢æƒ…å†µçš„ç³»ç»Ÿã€‚ç‰ˆæœ¬æ§åˆ¶å…¶å®æœ€é‡è¦çš„æ˜¯å¯ä»¥è®°å½•æ–‡ä»¶ä¿®æ”¹å†å²è®°å½•ï¼Œä»è€Œè®©ç”¨æˆ·èƒ½å¤ŸæŸ¥çœ‹å†å²ç‰ˆæœ¬ï¼Œæ–¹ä¾¿ç‰ˆæœ¬åˆ‡æ¢ã€‚<br><img src="/images/git/v_ctrl.jpg" width = "500" alt="ä¸€ä¸ªç³Ÿç³•çš„ç‰ˆæœ¬æ§åˆ¶" align="center" /></p><h2 id="ç‰ˆæœ¬æ§åˆ¶å·¥å…·"><a href="#ç‰ˆæœ¬æ§åˆ¶å·¥å…·" class="headerlink" title="ç‰ˆæœ¬æ§åˆ¶å·¥å…·"></a>ç‰ˆæœ¬æ§åˆ¶å·¥å…·</h2><ul><li>é›†ä¸­å¼ç‰ˆæœ¬æ§åˆ¶å·¥å…·ï¼šCVSã€SVN(Subversion)ã€VSSâ€¦â€¦</li><li>åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶å·¥å…·ï¼šGitã€ Mercurialã€ Bazaarã€ Darcsâ€¦â€¦</li></ul><h2 id="Gitç®€å²"><a href="#Gitç®€å²" class="headerlink" title="Gitç®€å²"></a>Gitç®€å²</h2><p>Gitæ˜¯Linuså¤§ç¥å†™çš„ï¼Œæ‰€ä»¥å’ŒLinuxä¸€å¥—å‘½ä»¤<br><img src="/images/git/git_history.jpg" width = "800" alt="Gitç®€å²" align="center" /></p><h2 id="Gitæœºåˆ¶"><a href="#Gitæœºåˆ¶" class="headerlink" title="Gitæœºåˆ¶"></a>Gitæœºåˆ¶</h2><p>åœ¨å·¥ä½œåŒºå†™ä»£ç ï¼Œé€šè¿‡git addæ·»åŠ åˆ°æš‚å­˜åŒºï¼Œå†é€šè¿‡git commitæäº¤åˆ°æœ¬åœ°åº“ï¼Œç”Ÿæˆå†å²ç‰ˆæœ¬ã€‚æœ¬åœ°åº“å¯ä»¥pushä»£ç åˆ°è¿œç¨‹åº“ï¼Œä¹Ÿå¯ä»¥ä»è¿œç¨‹åº“pullæ‹‰å–ä»£ç ï¼Œä¸åŒç‰ˆæœ¬çš„ä»£ç å¯ä»¥è¿›è¡Œmergeã€‚<br><img src="/images/git/git_strcture.jpg" width = "300" alt="Gitå·¥ä½œæœºåˆ¶" align="center" /></p><h2 id="ä»£ç æ‰˜ç®¡ä¸­å¿ƒ-è¿œç¨‹åº“"><a href="#ä»£ç æ‰˜ç®¡ä¸­å¿ƒ-è¿œç¨‹åº“" class="headerlink" title="ä»£ç æ‰˜ç®¡ä¸­å¿ƒ-è¿œç¨‹åº“"></a>ä»£ç æ‰˜ç®¡ä¸­å¿ƒ-è¿œç¨‹åº“</h2><p>ä»£ç æ‰˜ç®¡ä¸­å¿ƒæ˜¯åŸºäºç½‘ç»œæœåŠ¡å™¨çš„è¿œç¨‹ä»£ç ä»“åº“ï¼Œä¸€èˆ¬æˆ‘ä»¬ç®€å•ç§°ä¸ºè¿œç¨‹åº“ã€‚</p><ul><li>å±€åŸŸç½‘ï¼šGitLab</li><li>äº’è”ç½‘ï¼šGitHub(å›½å¤–)ï¼ŒGiteeï¼ˆå›½å†…ï¼‰</li></ul><h1 id="Gitå¸¸ç”¨å‘½ä»¤"><a href="#Gitå¸¸ç”¨å‘½ä»¤" class="headerlink" title="Gitå¸¸ç”¨å‘½ä»¤"></a>Gitå¸¸ç”¨å‘½ä»¤</h1><p>ä¸€å›¾ä»¥è”½ä¹‹ï¼Œ<br><img src="/images/git/git_command.jpg" width = "600" alt="Gitå¸¸ç”¨å‘½ä»¤" align="center" /></p><h1 id="Gitåˆ†æ”¯"><a href="#Gitåˆ†æ”¯" class="headerlink" title="Gitåˆ†æ”¯"></a>Gitåˆ†æ”¯</h1><h2 id="åˆ†æ”¯"><a href="#åˆ†æ”¯" class="headerlink" title="åˆ†æ”¯"></a>åˆ†æ”¯</h2><p>åœ¨ç‰ˆæœ¬æ§åˆ¶è¿‡ç¨‹ä¸­ï¼ŒåŒæ—¶æ¨è¿›å¤šä¸ªä»»åŠ¡ï¼Œä¸ºæ¯ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ›å»ºæ¯ä¸ªä»»åŠ¡çš„å•ç‹¬åˆ†æ”¯ã€‚ä½¿ç”¨åˆ†æ”¯æ„å‘³ç€ç¨‹åºå‘˜å¯ä»¥æŠŠè‡ªå·±çš„å·¥ä½œä»å¼€å‘ä¸»çº¿ä¸Šåˆ†ç¦»å¼€æ¥ï¼Œå¼€å‘è‡ªå·±åˆ†æ”¯çš„æ—¶å€™ï¼Œä¸ä¼šå½±å“ä¸»çº¿åˆ†æ”¯çš„è¿è¡Œã€‚å¯¹äºåˆå­¦è€…è€Œè¨€ï¼Œåˆ†æ”¯å¯ä»¥ç®€å•ç†è§£ä¸ºå‰¯æœ¬ï¼Œä¸€ä¸ªåˆ†æ”¯å°±æ˜¯ä¸€ä¸ªå•ç‹¬çš„å‰¯æœ¬ã€‚ï¼ˆåˆ†æ”¯åº•å±‚å…¶å®ä¹Ÿæ˜¯æŒ‡é’ˆçš„å¼•ç”¨ï¼‰</p><p>åŒæ—¶å¹¶è¡Œæ¨è¿›å¤šä¸ªåŠŸèƒ½å¼€å‘ï¼Œå¯ä»¥æé«˜å¼€å‘æ•ˆç‡ã€‚å„ä¸ªåˆ†æ”¯åœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæŸä¸€ä¸ªåˆ†æ”¯å¼€å‘å¤±è´¥ï¼Œä¸ä¼šå¯¹å…¶ä»–åˆ†æ”¯æœ‰ä»»ä½•å½±å“ã€‚å¤±è´¥çš„åˆ†æ”¯åˆ é™¤é‡æ–°å¼€å§‹å³å¯ã€‚</p><img src="/images/git/branch.jpg" width = "600" alt="åˆ†æ”¯ç¤ºæ„å›¾" align="center" /><h2 id="Gitåˆ†æ”¯å‘½ä»¤"><a href="#Gitåˆ†æ”¯å‘½ä»¤" class="headerlink" title="Gitåˆ†æ”¯å‘½ä»¤"></a>Gitåˆ†æ”¯å‘½ä»¤</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git branch -v # æŸ¥çœ‹åˆ†æ”¯</span><br><span class="line">git branch åˆ†æ”¯å # åˆ›å»ºåˆ†æ”¯</span><br><span class="line">git checkout åˆ†æ”¯å # åˆ‡æ¢åˆ†æ”¯</span><br><span class="line">git merge åˆ†æ”¯å # åˆå¹¶åˆ†æ”¯</span><br></pre></td></tr></table></figure><h2 id="åˆå¹¶å†²çª"><a href="#åˆå¹¶å†²çª" class="headerlink" title="åˆå¹¶å†²çª"></a>åˆå¹¶å†²çª</h2><p>åˆå¹¶åˆ†æ”¯æ—¶ï¼Œä¸¤ä¸ªåˆ†æ”¯åœ¨åŒä¸€ä¸ªæ–‡ä»¶çš„åŒä¸€ä¸ªä½ç½®æœ‰ä¸¤å¥—å®Œå…¨ä¸åŒçš„ä¿®æ”¹ã€‚Gitæ— æ³•æ›¿æˆ‘ä»¬å†³å®šä½¿ç”¨å“ªä¸€ä¸ªã€‚å¿…é¡»äººä¸ºå†³å®šæ–°ä»£ç å†…å®¹ã€‚</p><h1 id="Gitå›¢é˜Ÿåˆä½œ"><a href="#Gitå›¢é˜Ÿåˆä½œ" class="headerlink" title="Gitå›¢é˜Ÿåˆä½œ"></a>Gitå›¢é˜Ÿåˆä½œ</h1><p>ä¸¤ä¸ªéå¸¸å½¢è±¡åŒ–çš„å›¾å’Œç”ŸåŠ¨çš„ä¾‹å­ï¼</p><h2 id="å›¢é˜Ÿå†…åˆä½œ"><a href="#å›¢é˜Ÿå†…åˆä½œ" class="headerlink" title="å›¢é˜Ÿå†…åˆä½œ"></a>å›¢é˜Ÿå†…åˆä½œ</h2><img src="/images/git/inside.jpg" width = "600" alt="å›¢é˜Ÿå†…åˆä½œ" align="center" /><h2 id="è·¨å›¢é˜Ÿåˆä½œ"><a href="#è·¨å›¢é˜Ÿåˆä½œ" class="headerlink" title="è·¨å›¢é˜Ÿåˆä½œ"></a>è·¨å›¢é˜Ÿåˆä½œ</h2><img src="/images/git/outside.jpg" width = "600" alt="è·¨å›¢é˜Ÿåˆä½œ" align="center" /><h1 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h1><h2 id="è¿œç¨‹ä»“åº“æ“ä½œ"><a href="#è¿œç¨‹ä»“åº“æ“ä½œ" class="headerlink" title="è¿œç¨‹ä»“åº“æ“ä½œ"></a>è¿œç¨‹ä»“åº“æ“ä½œ</h2><img src="/images/git/github_command.jpg" width = "600" alt="è¿œç¨‹ä»“åº“æ“ä½œ" align="center" /><p>cloneä¼šåšå¦‚ä¸‹æ“ä½œï¼š</p><ol><li>æ‹‰å–ä»£ç ã€‚ </li><li>åˆå§‹åŒ–æœ¬åœ°ä»“åº“ã€‚ </li><li>åˆ›å»ºåˆ«åï¼ˆoriginï¼‰</li></ol><h2 id="é‚€è¯·åˆä½œè€…"><a href="#é‚€è¯·åˆä½œè€…" class="headerlink" title="é‚€è¯·åˆä½œè€…"></a>é‚€è¯·åˆä½œè€…</h2><img src="/images/git/invitation.jpg" width = "600" alt="é‚€è¯·åˆä½œè€…" align="center" /><h2 id="SSHç™»å½•"><a href="#SSHç™»å½•" class="headerlink" title="SSHç™»å½•"></a>SSHç™»å½•</h2><img src="/images/git/ssh.jpg" width = "600" alt="SSHç™»å½•" align="center" /><h1 id="Gitä¸å…¶ä»–ç¯å¢ƒé›†æˆ"><a href="#Gitä¸å…¶ä»–ç¯å¢ƒé›†æˆ" class="headerlink" title="Gitä¸å…¶ä»–ç¯å¢ƒé›†æˆ"></a>Gitä¸å…¶ä»–ç¯å¢ƒé›†æˆ</h1><p>å®˜æ–¹æ–‡æ¡£-Gitä¸å„ç§IDEçš„é›†æˆï¼š<a href="https://git-scm.com/book/en/v2">https://git-scm.com/book/en/v2</a></p><h1 id="ç äº‘Gitee"><a href="#ç äº‘Gitee" class="headerlink" title="ç äº‘Gitee"></a>ç äº‘Gitee</h1><p>ä¼—æ‰€å‘¨çŸ¥ï¼ŒGitHubæœåŠ¡å™¨åœ¨å›½å¤–ï¼Œä½¿ç”¨GitHubä½œä¸ºé¡¹ç›®æ‰˜ç®¡ç½‘ç«™ï¼Œå¦‚æœç½‘é€Ÿä¸å¥½çš„è¯ï¼Œä¸¥é‡å½±å“ä½¿ç”¨ä½“éªŒï¼Œç”šè‡³ä¼šå‡ºç°ç™»å½•ä¸ä¸Šçš„æƒ…å†µã€‚é’ˆå¯¹è¿™ä¸ªæƒ…å†µï¼Œå¤§å®¶ä¹Ÿå¯ä»¥ä½¿ç”¨å›½å†…çš„é¡¹ç›®æ‰˜ç®¡ç½‘ç«™-ç äº‘ <a href="https://gitee.com/">https://gitee.com/</a>ã€‚</p><h1 id="GitLab"><a href="#GitLab" class="headerlink" title="GitLab"></a>GitLab</h1><p>GitLab <a href="https://about.gitlab.com/">https://about.gitlab.com/</a>æ˜¯ç”±GitLabInc.å¼€å‘ï¼Œä½¿ç”¨MITè®¸å¯è¯çš„åŸºäºç½‘ç»œçš„Gitä»“åº“ç®¡ç†å·¥å…·ï¼Œä¸”å…·æœ‰wikiå’Œissueè·Ÿè¸ªåŠŸèƒ½ã€‚ä½¿ç”¨Gitä½œä¸ºä»£ç ç®¡ç†å·¥å…·ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæ­å»ºèµ·æ¥çš„webæœåŠ¡ã€‚<br>GitLabç”±ä¹Œå…‹å…°ç¨‹åºå‘˜DmitriyZaporozhetså’ŒValerySizovå¼€å‘ï¼Œå®ƒä½¿ç”¨Rubyè¯­è¨€å†™æˆã€‚åæ¥,ä¸€äº›éƒ¨åˆ†ç”¨Goè¯­è¨€é‡å†™ã€‚æˆªæ­¢2018å¹´5æœˆï¼Œè¯¥å…¬å¸çº¦æœ‰290åå›¢é˜Ÿæˆå‘˜ï¼Œä»¥åŠ2000å¤šåå¼€æºè´¡çŒ®è€…ã€‚GitLabè¢«IBM, Sony, JuÌˆlichResearchCenter, NASA, Alibaba, Invincea, Oâ€™Reilly Media, Leibniz-Rechenzentrum, CERN, SpaceXç­‰ç»„ç»‡ä½¿ç”¨ã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;æœ¬æ–‡æ˜¯ä»¥ä¸‹è¯¾ç¨‹çš„ç¬”è®°ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã€å°šç¡…è°·ã€‘5hæ‰“é€šGitå…¨å¥—æ•™ç¨‹ä¸¨2021æœ€æ–°IDEAç‰ˆï¼ˆæ¶µç›–GitHub\Giteeç äº‘\GitLabï¼‰&lt;a href=&quot;https://www.bilibili.com/video/BV1vy4y1s7k6?p=41&quot;&gt;</summary>
      
    
    
    
    <category term="03 å·¥å…·ç®±" scheme="http://example.com/categories/03-%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    
    
    <category term="git" scheme="http://example.com/tags/git/"/>
    
    <category term="ç¬”è®°" scheme="http://example.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
